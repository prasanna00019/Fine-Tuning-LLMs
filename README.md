# ğŸ”§ğŸ§  LLM Fine-Tuning 
Welcome to the **LLM Fine-Tuning Repo** â€” a collection of hands-on fine-tuning experiments on large language models (LLMs) like GPT-2.  
Here you'll find mini-projects that explore how fine-tuning transforms general-purpose models into task-specific experts.

---

## ğŸ¯ What This Repo Is For

This repository is dedicated to building, training, and evaluating LLMs fine-tuned on custom datasets for various **text classification** and **language understanding** tasks.

- ğŸš€ Based on HuggingFace Transformers
- ğŸ“š Fine-tuned from GPT-2 (for now) later will be doing on different models
- ğŸ§ª Designed for experimentation, benchmarking, and learning

---

## ğŸ§© Current Projects

| Project | Description |
|--------|-------------|
| ğŸ“˜ [`subject-classifier`](subject-classification-fine-tuning.ipynb) | Fine-tunes GPT-2 to classify academic subjects (Math, Science, History, etc.) based on input sentences |
| ğŸ˜Š [`emotion-classifier`](EMOTION-CLASSIFICATION-FINE-TUNING.ipynb) | Fine-tunes GPT-2 to classify emotional tone in short texts (happy, sad, angry, etc.) |
| ğŸ“° [`news-category-classifier`](news-classifier-fine-tuning.ipynb) | Fine-tunes GPT-2 to categorize news headlines/articles into domains like Business, Sports, Technology, etc. |

Each project has:
- âœ… A preprocessed dataset
- âœ… A training script (with HuggingFace Trainer or LoRA)
- âœ… Evaluation metrics (accuracy)
- âœ… Sample predictions
- âœ… README for reproducibility

---

## ğŸ§  Upcoming Fine-Tuning Projects (Planned)

Hereâ€™s what Iâ€™ll be working on soon:

| Project | Description |
|---------|-------------|
| ğŸ§˜ `spiritual-text-classifier` | Classify spiritual content (e.g., yoga, devotion, Vedanta, karma, bhakti) |
| ğŸ¥ `medical-intent-detector` | Fine-tune a model to detect user intent in medical queries (symptom vs appointment vs emergency) |
| ğŸ“„ `legal-document-tagger` | Fine-tune a legal-specific classifier for document tagging |
| ğŸ’¬ `multi-label tweet classifier` | Handle tweets with multiple tags (sarcasm, hate speech, news, personal) |
| âœï¸ `style-transfer-generator` | Fine-tune an LLM to rewrite content in different tones (e.g., Shakespearean, sarcastic, formal)

---

## ğŸ› ï¸ Tech Stack

- ğŸ¤— HuggingFace Transformers
- ğŸ§¨ GPT-2 as base model(later will experiment with different models)
- ğŸ§ª Datasets: custom + HuggingFace Datasets
- âš™ï¸ Training: full fine-tuning, LoRA (in future), PEFT

---

## ğŸš€ Getting Started

```bash
git clone https://github.com/yourusername/llm-finetuning-lab.git
cd llm-finetuning
pip install -r requirements.txt
