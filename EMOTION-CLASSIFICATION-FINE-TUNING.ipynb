{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Classification with GPT-2 Fine-Tuning\n",
    "\n",
    "This project demonstrates how to fine-tune a pre-trained GPT-2 model for emotion classification using the [Emotion Dataset](https://www.kaggle.com/datasets/parulpandey/emotion-dataset). The workflow covers data preparation, model adaptation, training, evaluation, and inference, providing a practical example of transfer learning in NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Project?\n",
    "\n",
    "- **Transfer Learning**: Leverages the power of large pre-trained language models (GPT-2) for a downstream classification task, reducing the need for massive labeled datasets.\n",
    "- **Practical NLP**: Emotion classification is a common real-world application, useful in chatbots, sentiment analysis, and social media monitoring.\n",
    "- **Hands-On Deep Learning**: Covers all steps from data loading to model evaluation, making it a comprehensive learning resource.\n",
    "- **Custom Model Adaptation**: Shows how to modify the GPT-2 architecture for classification tasks, including freezing and unfreezing layers for efficient fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Workflow\n",
    "\n",
    "### 1. **Setup and Tokenization**\n",
    "- Install and import necessary libraries (`torch`, `tiktoken`, `pandas`, etc.).\n",
    "- Load the GPT-2 tokenizer using `tiktoken` for consistent tokenization with the pre-trained model.\n",
    "\n",
    "### 2. **Model Configuration**\n",
    "- Define the GPT-2 model configuration (embedding size, number of layers/heads, etc.).\n",
    "- Download and load pre-trained GPT-2 weights using helper functions.\n",
    "\n",
    "### 3. **Model Architecture**\n",
    "- Implement the GPT-2 architecture in PyTorch, including:\n",
    "    - Multi-head self-attention\n",
    "    - Layer normalization\n",
    "    - Feed-forward layers\n",
    "    - Positional and token embeddings\n",
    "- Adapt the output head for emotion classification (6 classes).\n",
    "\n",
    "### 4. **Dataset Preparation**\n",
    "- Download the Emotion Dataset from Kaggle.\n",
    "- Load and preprocess the data using pandas.\n",
    "- Implement a custom `EmotionDataset` class for tokenization, padding, and label extraction.\n",
    "- Create PyTorch DataLoaders for training, validation, and testing.\n",
    "\n",
    "### 5. **Fine-Tuning Strategy**\n",
    "- Freeze all model parameters except the last two transformer blocks, final normalization, and the new output head.\n",
    "- Replace the output head with a linear layer for 6-class classification.\n",
    "\n",
    "### 6. **Training and Evaluation**\n",
    "- Define loss and accuracy calculation functions.\n",
    "- Train the model using AdamW optimizer, tracking loss and accuracy on both training and validation sets.\n",
    "- Save and reload the best model weights.\n",
    "\n",
    "### 7. **Visualization**\n",
    "- Plot training and validation loss curves to monitor learning progress.\n",
    "\n",
    "### 8. **Inference**\n",
    "- Implement a function to classify the emotion of new text inputs.\n",
    "- Test the model on various example sentences.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This project provides a complete pipeline for adapting a large language model to a practical NLP task. By fine-tuning GPT-2 for emotion classification, we demonstrate the effectiveness of transfer learning and the flexibility of transformer-based models for a wide range of applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Try it yourself:**  \n",
    "Modify the dataset, experiment with different layers to fine-tune, or apply this workflow to other text classification tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:50:54.994529Z",
     "iopub.status.busy": "2025-06-17T12:50:54.994230Z",
     "iopub.status.idle": "2025-06-17T12:51:03.420972Z",
     "shell.execute_reply": "2025-06-17T12:51:03.415130Z",
     "shell.execute_reply.started": "2025-06-17T12:50:54.994504Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tiktoken\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:03.421943Z",
     "iopub.status.busy": "2025-06-17T12:51:03.421687Z",
     "iopub.status.idle": "2025-06-17T12:51:03.433673Z",
     "shell.execute_reply": "2025-06-17T12:51:03.427463Z",
     "shell.execute_reply.started": "2025-06-17T12:51:03.421913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024) \n",
    "    \"emb_dim\": 768,        # Embedding dimension // later we will use 5 only for 5 classes\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.2,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:05.676453Z",
     "iopub.status.busy": "2025-06-17T12:51:05.676109Z",
     "iopub.status.idle": "2025-06-17T12:51:31.118389Z",
     "shell.execute_reply": "2025-06-17T12:51:31.112966Z",
     "shell.execute_reply.started": "2025-06-17T12:51:05.676423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:31.121062Z",
     "iopub.status.busy": "2025-06-17T12:51:31.120683Z",
     "iopub.status.idle": "2025-06-17T12:51:31.135889Z",
     "shell.execute_reply": "2025-06-17T12:51:31.130974Z",
     "shell.execute_reply.started": "2025-06-17T12:51:31.121035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:31.136949Z",
     "iopub.status.busy": "2025-06-17T12:51:31.136718Z",
     "iopub.status.idle": "2025-06-17T12:51:31.160155Z",
     "shell.execute_reply": "2025-06-17T12:51:31.154167Z",
     "shell.execute_reply.started": "2025-06-17T12:51:31.136927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:31.161186Z",
     "iopub.status.busy": "2025-06-17T12:51:31.160956Z",
     "iopub.status.idle": "2025-06-17T12:51:32.618049Z",
     "shell.execute_reply": "2025-06-17T12:51:32.611645Z",
     "shell.execute_reply.started": "2025-06-17T12:51:31.161164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:38.086904Z",
     "iopub.status.busy": "2025-06-17T12:51:38.086541Z",
     "iopub.status.idle": "2025-06-17T12:51:38.099060Z",
     "shell.execute_reply": "2025-06-17T12:51:38.094530Z",
     "shell.execute_reply.started": "2025-06-17T12:51:38.086871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:51:42.594276Z",
     "iopub.status.busy": "2025-06-17T12:51:42.593895Z",
     "iopub.status.idle": "2025-06-17T12:52:04.767733Z",
     "shell.execute_reply": "2025-06-17T12:52:04.761479Z",
     "shell.execute_reply.started": "2025-06-17T12:51:42.594242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1750164709.390273      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:230\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests  # Make sure requests is installed\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "def download_file(url, destination):\n",
    "    try:\n",
    "        # Send a GET request to download the file, disabling SSL verification\n",
    "        response = requests.get(url, stream=True, verify=False)\n",
    "\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Iterate over the file data in chunks\n",
    "                for chunk in response.iter_content(block_size):\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "                    file.write(chunk)  # Write the chunk to the file\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "        print(f\"Please check the URL: {url}\")\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:04.770589Z",
     "iopub.status.busy": "2025-06-17T12:52:04.770043Z",
     "iopub.status.idle": "2025-06-17T12:52:04.780326Z",
     "shell.execute_reply": "2025-06-17T12:52:04.775257Z",
     "shell.execute_reply.started": "2025-06-17T12:52:04.770556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:14.731993Z",
     "iopub.status.busy": "2025-06-17T12:52:14.731652Z",
     "iopub.status.idle": "2025-06-17T12:52:14.751674Z",
     "shell.execute_reply": "2025-06-17T12:52:14.747860Z",
     "shell.execute_reply.started": "2025-06-17T12:52:14.731964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:21.923841Z",
     "iopub.status.busy": "2025-06-17T12:52:21.923495Z",
     "iopub.status.idle": "2025-06-17T12:52:21.937723Z",
     "shell.execute_reply": "2025-06-17T12:52:21.932635Z",
     "shell.execute_reply.started": "2025-06-17T12:52:21.923812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:24.991091Z",
     "iopub.status.busy": "2025-06-17T12:52:24.990711Z",
     "iopub.status.idle": "2025-06-17T12:52:28.564734Z",
     "shell.execute_reply": "2025-06-17T12:52:28.558050Z",
     "shell.execute_reply.started": "2025-06-17T12:52:24.991057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "# !pip install tiktoken\n",
    "import tiktoken\n",
    "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:38.500165Z",
     "iopub.status.busy": "2025-06-17T12:52:38.499758Z",
     "iopub.status.idle": "2025-06-17T12:52:38.511781Z",
     "shell.execute_reply": "2025-06-17T12:52:38.508001Z",
     "shell.execute_reply.started": "2025-06-17T12:52:38.500133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:52:49.611458Z",
     "iopub.status.busy": "2025-06-17T12:52:49.611044Z",
     "iopub.status.idle": "2025-06-17T12:54:45.340395Z",
     "shell.execute_reply": "2025-06-17T12:54:45.334880Z",
     "shell.execute_reply.started": "2025-06-17T12:52:49.611424Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 100kiB/s]\n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 958kiB/s]\n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 90.3kiB/s]\n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:47<00:00, 4.65MiB/s] \n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.26MiB/s]\n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 643kiB/s] \n",
      "/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 625kiB/s] \n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:54:47.933883Z",
     "iopub.status.busy": "2025-06-17T12:54:47.933567Z",
     "iopub.status.idle": "2025-06-17T12:54:50.241378Z",
     "shell.execute_reply": "2025-06-17T12:54:50.237515Z",
     "shell.execute_reply.started": "2025-06-17T12:54:47.933856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be successful you need to be able to get the job done.\n",
      "\n",
      "The best way to do this is to get a job that is open to all.\n",
      "\n",
      "The best way to do this is to get a job that is open to all. The best way to\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"to be successful you need to\"\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    " ###tensor([[6109, 3626, 6100,  345],\n",
    "        ##[6109, 1110, 6622,  257]])\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:54:54.314510Z",
     "iopub.status.busy": "2025-06-17T12:54:54.313970Z",
     "iopub.status.idle": "2025-06-17T12:54:54.666849Z",
     "shell.execute_reply": "2025-06-17T12:54:54.660826Z",
     "shell.execute_reply.started": "2025-06-17T12:54:54.314449Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/emotion-dataset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"parulpandey/emotion-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "# Path to dataset files: /kaggle/input/emotion-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:54:59.227092Z",
     "iopub.status.busy": "2025-06-17T12:54:59.226791Z",
     "iopub.status.idle": "2025-06-17T12:54:59.264807Z",
     "shell.execute_reply": "2025-06-17T12:54:59.260332Z",
     "shell.execute_reply.started": "2025-06-17T12:54:59.227066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text Label\n",
      "1     im feeling rather rotten so im not very ambiti...     0\n",
      "2             im updating my blog because i feel shitty     0\n",
      "3     i never make her separate from me because i do...     0\n",
      "4     i left with my bouquet of red and yellow tulip...     1\n",
      "5       i was feeling a little vain when i did this one     0\n",
      "...                                                 ...   ...\n",
      "1996  i just keep feeling like someone is being unki...     3\n",
      "1997  im feeling a little cranky negative after this...     3\n",
      "1998  i feel that i am useful to my people and that ...     1\n",
      "1999  im feeling more comfortable with derby i feel ...     1\n",
      "2000  i feel all weird when i have to meet w people ...     4\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(path+\"/test.csv\", header=None,names=['Text','Label'],index_col=False)\n",
    "test_df=test_df.drop(0)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:03.163353Z",
     "iopub.status.busy": "2025-06-17T12:55:03.163017Z",
     "iopub.status.idle": "2025-06-17T12:55:03.233804Z",
     "shell.execute_reply": "2025-06-17T12:55:03.229251Z",
     "shell.execute_reply.started": "2025-06-17T12:55:03.163325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(path+\"/training.csv\", header=None, names=[\"Text\", \"Label\"],index_col=False)\n",
    "validation_df=pd.read_csv(path+\"/validation.csv\", header=None, names=[\"Text\", \"Label\"],index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:07.534988Z",
     "iopub.status.busy": "2025-06-17T12:55:07.534671Z",
     "iopub.status.idle": "2025-06-17T12:55:07.548258Z",
     "shell.execute_reply": "2025-06-17T12:55:07.543679Z",
     "shell.execute_reply.started": "2025-06-17T12:55:07.534960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_df=train_df.drop(0)\n",
    "# validation_df=validation_df.drop(0)   //uncomment this line initially . then run . later uncomment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:15.068794Z",
     "iopub.status.busy": "2025-06-17T12:55:15.068519Z",
     "iopub.status.idle": "2025-06-17T12:55:15.078196Z",
     "shell.execute_reply": "2025-06-17T12:55:15.073750Z",
     "shell.execute_reply.started": "2025-06-17T12:55:15.068770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_df\n",
    "# validation_df\n",
    "labels={\n",
    "    0:\"sadness\",\n",
    "    1:\"joy\",\n",
    "    2:\"love\",\n",
    "    3:\"anger\",\n",
    "    4:\"fear\",\n",
    "    5: \"surprise\"\n",
    "}\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:19.214170Z",
     "iopub.status.busy": "2025-06-17T12:55:19.213849Z",
     "iopub.status.idle": "2025-06-17T12:55:19.229095Z",
     "shell.execute_reply": "2025-06-17T12:55:19.224598Z",
     "shell.execute_reply.started": "2025-06-17T12:55:19.214144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # print(self.data)\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:23.158405Z",
     "iopub.status.busy": "2025-06-17T12:55:23.158093Z",
     "iopub.status.idle": "2025-06-17T12:55:23.876827Z",
     "shell.execute_reply": "2025-06-17T12:55:23.873041Z",
     "shell.execute_reply.started": "2025-06-17T12:55:23.158381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(\n",
    "    csv_file=path+\"/training.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# print(train_dataset.max_length)\n",
    "val_dataset = EmotionDataset(\n",
    "    csv_file=path+\"/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = EmotionDataset(\n",
    "    csv_file=path+\"/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:25.422272Z",
     "iopub.status.busy": "2025-06-17T12:55:25.421956Z",
     "iopub.status.idle": "2025-06-17T12:55:25.438327Z",
     "shell.execute_reply": "2025-06-17T12:55:25.432423Z",
     "shell.execute_reply.started": "2025-06-17T12:55:25.422247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:28.222586Z",
     "iopub.status.busy": "2025-06-17T12:55:28.222308Z",
     "iopub.status.idle": "2025-06-17T12:55:28.232423Z",
     "shell.execute_reply": "2025-06-17T12:55:28.228353Z",
     "shell.execute_reply.started": "2025-06-17T12:55:28.222563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:55:29.781508Z",
     "iopub.status.busy": "2025-06-17T12:55:29.781237Z",
     "iopub.status.idle": "2025-06-17T12:55:29.793681Z",
     "shell.execute_reply": "2025-06-17T12:55:29.789666Z",
     "shell.execute_reply.started": "2025-06-17T12:55:29.781484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 6\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:25.617796Z",
     "iopub.status.busy": "2025-06-17T12:56:25.617494Z",
     "iopub.status.idle": "2025-06-17T12:56:25.628908Z",
     "shell.execute_reply": "2025-06-17T12:56:25.623778Z",
     "shell.execute_reply.started": "2025-06-17T12:56:25.617772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.trf_blocks[-2].parameters():\n",
    "    param.requires_grad= True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:28.135809Z",
     "iopub.status.busy": "2025-06-17T12:56:28.135527Z",
     "iopub.status.idle": "2025-06-17T12:56:28.153042Z",
     "shell.execute_reply": "2025-06-17T12:56:28.148498Z",
     "shell.execute_reply.started": "2025-06-17T12:56:28.135786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:30.732422Z",
     "iopub.status.busy": "2025-06-17T12:56:30.732090Z",
     "iopub.status.idle": "2025-06-17T12:56:30.774414Z",
     "shell.execute_reply": "2025-06-17T12:56:30.767462Z",
     "shell.execute_reply.started": "2025-06-17T12:56:30.732394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5866e+00,  9.8504e-01, -9.2044e-04, -4.1590e-01, -8.9661e-02,\n",
      "          -1.0322e+00],\n",
      "         [-3.7246e+00,  7.4495e+00,  2.2074e+00,  4.1226e-02,  2.2660e+00,\n",
      "          -3.3682e+00],\n",
      "         [-2.2672e+00,  6.5996e+00,  2.7556e+00, -7.6406e-01,  2.3255e+00,\n",
      "          -3.3597e+00],\n",
      "         [-3.5995e+00,  3.9848e+00,  2.2525e+00, -1.2470e+00,  9.3418e-02,\n",
      "          -4.7644e+00]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:36.181315Z",
     "iopub.status.busy": "2025-06-17T12:56:36.180983Z",
     "iopub.status.idle": "2025-06-17T12:56:36.194758Z",
     "shell.execute_reply": "2025-06-17T12:56:36.189629Z",
     "shell.execute_reply.started": "2025-06-17T12:56:36.181287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:38.189419Z",
     "iopub.status.busy": "2025-06-17T12:56:38.189132Z",
     "iopub.status.idle": "2025-06-17T12:56:38.202620Z",
     "shell.execute_reply": "2025-06-17T12:56:38.196873Z",
     "shell.execute_reply.started": "2025-06-17T12:56:38.189394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5995,  3.9848,  2.2525, -1.2470,  0.0934, -4.7644]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:56:41.426864Z",
     "iopub.status.busy": "2025-06-17T12:56:41.426573Z",
     "iopub.status.idle": "2025-06-17T12:56:47.333453Z",
     "shell.execute_reply": "2025-06-17T12:56:47.326113Z",
     "shell.execute_reply.started": "2025-06-17T12:56:41.426839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Training accuracy: 36.25%\n",
      "Validation accuracy: 30.00%\n",
      "Test accuracy: 31.25%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device) \n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:57:17.510604Z",
     "iopub.status.busy": "2025-06-17T12:57:17.510310Z",
     "iopub.status.idle": "2025-06-17T12:57:17.522155Z",
     "shell.execute_reply": "2025-06-17T12:57:17.516182Z",
     "shell.execute_reply.started": "2025-06-17T12:57:17.510579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:57:23.591601Z",
     "iopub.status.busy": "2025-06-17T12:57:23.591313Z",
     "iopub.status.idle": "2025-06-17T12:57:23.604945Z",
     "shell.execute_reply": "2025-06-17T12:57:23.599248Z",
     "shell.execute_reply.started": "2025-06-17T12:57:23.591576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:57:26.057020Z",
     "iopub.status.busy": "2025-06-17T12:57:26.056703Z",
     "iopub.status.idle": "2025-06-17T12:57:28.819716Z",
     "shell.execute_reply": "2025-06-17T12:57:28.811451Z",
     "shell.execute_reply.started": "2025-06-17T12:57:26.056992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.732\n",
      "Validation loss: 3.225\n",
      "Test loss: 3.169\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:57:34.400235Z",
     "iopub.status.busy": "2025-06-17T12:57:34.399929Z",
     "iopub.status.idle": "2025-06-17T12:57:34.414927Z",
     "shell.execute_reply": "2025-06-17T12:57:34.409579Z",
     "shell.execute_reply.started": "2025-06-17T12:57:34.400208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:57:39.736123Z",
     "iopub.status.busy": "2025-06-17T12:57:39.735815Z",
     "iopub.status.idle": "2025-06-17T12:57:39.746257Z",
     "shell.execute_reply": "2025-06-17T12:57:39.742150Z",
     "shell.execute_reply.started": "2025-06-17T12:57:39.736080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:58:01.521716Z",
     "iopub.status.busy": "2025-06-17T12:58:01.521414Z",
     "iopub.status.idle": "2025-06-17T13:33:28.022769Z",
     "shell.execute_reply": "2025-06-17T13:33:28.018455Z",
     "shell.execute_reply.started": "2025-06-17T12:58:01.521690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.243, Val loss 2.513\n",
      "Ep 1 (Step 000050): Train loss 1.550, Val loss 1.486\n",
      "Ep 1 (Step 000100): Train loss 1.590, Val loss 1.383\n",
      "Ep 1 (Step 000150): Train loss 1.554, Val loss 1.443\n",
      "Ep 1 (Step 000200): Train loss 1.463, Val loss 1.385\n",
      "Ep 1 (Step 000250): Train loss 1.596, Val loss 1.372\n",
      "Ep 1 (Step 000300): Train loss 1.691, Val loss 1.421\n",
      "Ep 1 (Step 000350): Train loss 1.642, Val loss 1.322\n",
      "Ep 1 (Step 000400): Train loss 1.560, Val loss 1.390\n",
      "Ep 1 (Step 000450): Train loss 1.546, Val loss 1.383\n",
      "Ep 1 (Step 000500): Train loss 1.513, Val loss 1.390\n",
      "Ep 1 (Step 000550): Train loss 1.718, Val loss 1.342\n",
      "Ep 1 (Step 000600): Train loss 1.525, Val loss 1.388\n",
      "Ep 1 (Step 000650): Train loss 1.768, Val loss 1.345\n",
      "Ep 1 (Step 000700): Train loss 1.879, Val loss 1.372\n",
      "Ep 1 (Step 000750): Train loss 1.501, Val loss 1.356\n",
      "Ep 1 (Step 000800): Train loss 1.841, Val loss 1.361\n",
      "Ep 1 (Step 000850): Train loss 1.535, Val loss 1.368\n",
      "Ep 1 (Step 000900): Train loss 1.594, Val loss 1.329\n",
      "Ep 1 (Step 000950): Train loss 1.566, Val loss 1.244\n",
      "Ep 1 (Step 001000): Train loss 1.351, Val loss 1.080\n",
      "Ep 1 (Step 001050): Train loss 1.183, Val loss 0.914\n",
      "Ep 1 (Step 001100): Train loss 1.437, Val loss 0.861\n",
      "Ep 1 (Step 001150): Train loss 1.002, Val loss 0.938\n",
      "Ep 1 (Step 001200): Train loss 1.185, Val loss 0.891\n",
      "Ep 1 (Step 001250): Train loss 0.993, Val loss 0.744\n",
      "Ep 1 (Step 001300): Train loss 0.727, Val loss 0.645\n",
      "Ep 1 (Step 001350): Train loss 1.123, Val loss 0.836\n",
      "Ep 1 (Step 001400): Train loss 0.366, Val loss 0.529\n",
      "Ep 1 (Step 001450): Train loss 0.416, Val loss 0.498\n",
      "Ep 1 (Step 001500): Train loss 0.672, Val loss 0.531\n",
      "Ep 1 (Step 001550): Train loss 0.411, Val loss 0.500\n",
      "Ep 1 (Step 001600): Train loss 0.445, Val loss 0.488\n",
      "Ep 1 (Step 001650): Train loss 0.594, Val loss 0.395\n",
      "Ep 1 (Step 001700): Train loss 0.447, Val loss 0.446\n",
      "Ep 1 (Step 001750): Train loss 0.313, Val loss 0.413\n",
      "Ep 1 (Step 001800): Train loss 0.408, Val loss 0.421\n",
      "Ep 1 (Step 001850): Train loss 0.261, Val loss 0.412\n",
      "Ep 1 (Step 001900): Train loss 0.181, Val loss 0.350\n",
      "Ep 1 (Step 001950): Train loss 1.094, Val loss 0.367\n",
      "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
      "Ep 2 (Step 002000): Train loss 0.352, Val loss 0.347\n",
      "Ep 2 (Step 002050): Train loss 0.653, Val loss 0.359\n",
      "Ep 2 (Step 002100): Train loss 0.291, Val loss 0.436\n",
      "Ep 2 (Step 002150): Train loss 0.253, Val loss 0.298\n",
      "Ep 2 (Step 002200): Train loss 0.130, Val loss 0.279\n",
      "Ep 2 (Step 002250): Train loss 0.418, Val loss 0.344\n",
      "Ep 2 (Step 002300): Train loss 0.515, Val loss 0.307\n",
      "Ep 2 (Step 002350): Train loss 0.353, Val loss 0.332\n",
      "Ep 2 (Step 002400): Train loss 0.277, Val loss 0.320\n",
      "Ep 2 (Step 002450): Train loss 0.413, Val loss 0.314\n",
      "Ep 2 (Step 002500): Train loss 0.215, Val loss 0.312\n",
      "Ep 2 (Step 002550): Train loss 0.295, Val loss 0.317\n",
      "Ep 2 (Step 002600): Train loss 0.207, Val loss 0.310\n",
      "Ep 2 (Step 002650): Train loss 0.334, Val loss 0.286\n",
      "Ep 2 (Step 002700): Train loss 0.036, Val loss 0.282\n",
      "Ep 2 (Step 002750): Train loss 0.464, Val loss 0.290\n",
      "Ep 2 (Step 002800): Train loss 0.139, Val loss 0.206\n",
      "Ep 2 (Step 002850): Train loss 0.177, Val loss 0.297\n",
      "Ep 2 (Step 002900): Train loss 0.153, Val loss 0.238\n",
      "Ep 2 (Step 002950): Train loss 0.422, Val loss 0.230\n",
      "Ep 2 (Step 003000): Train loss 0.153, Val loss 0.218\n",
      "Ep 2 (Step 003050): Train loss 0.236, Val loss 0.228\n",
      "Ep 2 (Step 003100): Train loss 0.236, Val loss 0.231\n",
      "Ep 2 (Step 003150): Train loss 0.185, Val loss 0.231\n",
      "Ep 2 (Step 003200): Train loss 0.193, Val loss 0.237\n",
      "Ep 2 (Step 003250): Train loss 0.316, Val loss 0.237\n",
      "Ep 2 (Step 003300): Train loss 0.203, Val loss 0.243\n",
      "Ep 2 (Step 003350): Train loss 0.190, Val loss 0.194\n",
      "Ep 2 (Step 003400): Train loss 0.146, Val loss 0.304\n",
      "Ep 2 (Step 003450): Train loss 0.167, Val loss 0.214\n",
      "Ep 2 (Step 003500): Train loss 0.179, Val loss 0.217\n",
      "Ep 2 (Step 003550): Train loss 0.171, Val loss 0.225\n",
      "Ep 2 (Step 003600): Train loss 0.127, Val loss 0.204\n",
      "Ep 2 (Step 003650): Train loss 0.211, Val loss 0.221\n",
      "Ep 2 (Step 003700): Train loss 0.301, Val loss 0.220\n",
      "Ep 2 (Step 003750): Train loss 0.198, Val loss 0.259\n",
      "Ep 2 (Step 003800): Train loss 0.207, Val loss 0.216\n",
      "Ep 2 (Step 003850): Train loss 0.170, Val loss 0.235\n",
      "Ep 2 (Step 003900): Train loss 0.090, Val loss 0.206\n",
      "Ep 2 (Step 003950): Train loss 0.266, Val loss 0.186\n",
      "Training accuracy: 97.50% | Validation accuracy: 90.00%\n",
      "Ep 3 (Step 004000): Train loss 0.165, Val loss 0.244\n",
      "Ep 3 (Step 004050): Train loss 0.030, Val loss 0.184\n",
      "Ep 3 (Step 004100): Train loss 0.155, Val loss 0.202\n",
      "Ep 3 (Step 004150): Train loss 0.087, Val loss 0.195\n",
      "Ep 3 (Step 004200): Train loss 0.125, Val loss 0.146\n",
      "Ep 3 (Step 004250): Train loss 0.200, Val loss 0.184\n",
      "Ep 3 (Step 004300): Train loss 0.070, Val loss 0.187\n",
      "Ep 3 (Step 004350): Train loss 0.142, Val loss 0.177\n",
      "Ep 3 (Step 004400): Train loss 0.179, Val loss 0.225\n",
      "Ep 3 (Step 004450): Train loss 0.030, Val loss 0.157\n",
      "Ep 3 (Step 004500): Train loss 0.045, Val loss 0.163\n",
      "Ep 3 (Step 004550): Train loss 0.134, Val loss 0.154\n",
      "Ep 3 (Step 004600): Train loss 0.103, Val loss 0.148\n",
      "Ep 3 (Step 004650): Train loss 0.032, Val loss 0.167\n",
      "Ep 3 (Step 004700): Train loss 0.182, Val loss 0.144\n",
      "Ep 3 (Step 004750): Train loss 0.178, Val loss 0.119\n",
      "Ep 3 (Step 004800): Train loss 0.252, Val loss 0.145\n",
      "Ep 3 (Step 004850): Train loss 0.173, Val loss 0.163\n",
      "Ep 3 (Step 004900): Train loss 0.404, Val loss 0.131\n",
      "Ep 3 (Step 004950): Train loss 0.112, Val loss 0.146\n",
      "Ep 3 (Step 005000): Train loss 0.117, Val loss 0.182\n",
      "Ep 3 (Step 005050): Train loss 0.095, Val loss 0.158\n",
      "Ep 3 (Step 005100): Train loss 0.143, Val loss 0.180\n",
      "Ep 3 (Step 005150): Train loss 0.095, Val loss 0.179\n",
      "Ep 3 (Step 005200): Train loss 0.090, Val loss 0.231\n",
      "Ep 3 (Step 005250): Train loss 0.117, Val loss 0.187\n",
      "Ep 3 (Step 005300): Train loss 0.231, Val loss 0.181\n",
      "Ep 3 (Step 005350): Train loss 0.103, Val loss 0.188\n",
      "Ep 3 (Step 005400): Train loss 0.049, Val loss 0.151\n",
      "Ep 3 (Step 005450): Train loss 0.185, Val loss 0.233\n",
      "Ep 3 (Step 005500): Train loss 0.109, Val loss 0.209\n",
      "Ep 3 (Step 005550): Train loss 0.139, Val loss 0.262\n",
      "Ep 3 (Step 005600): Train loss 0.093, Val loss 0.278\n",
      "Ep 3 (Step 005650): Train loss 0.157, Val loss 0.310\n",
      "Ep 3 (Step 005700): Train loss 0.164, Val loss 0.282\n",
      "Ep 3 (Step 005750): Train loss 0.353, Val loss 0.278\n",
      "Ep 3 (Step 005800): Train loss 0.247, Val loss 0.239\n",
      "Ep 3 (Step 005850): Train loss 0.201, Val loss 0.208\n",
      "Ep 3 (Step 005900): Train loss 0.109, Val loss 0.268\n",
      "Ep 3 (Step 005950): Train loss 0.165, Val loss 0.256\n",
      "Training accuracy: 92.50% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 006000): Train loss 0.178, Val loss 0.220\n",
      "Ep 4 (Step 006050): Train loss 0.088, Val loss 0.237\n",
      "Ep 4 (Step 006100): Train loss 0.055, Val loss 0.212\n",
      "Ep 4 (Step 006150): Train loss 0.201, Val loss 0.178\n",
      "Ep 4 (Step 006200): Train loss 0.152, Val loss 0.190\n",
      "Ep 4 (Step 006250): Train loss 0.063, Val loss 0.149\n",
      "Ep 4 (Step 006300): Train loss 0.085, Val loss 0.140\n",
      "Ep 4 (Step 006350): Train loss 0.058, Val loss 0.162\n",
      "Ep 4 (Step 006400): Train loss 0.058, Val loss 0.144\n",
      "Ep 4 (Step 006450): Train loss 0.071, Val loss 0.219\n",
      "Ep 4 (Step 006500): Train loss 0.003, Val loss 0.261\n",
      "Ep 4 (Step 006550): Train loss 0.043, Val loss 0.243\n",
      "Ep 4 (Step 006600): Train loss 0.040, Val loss 0.198\n",
      "Ep 4 (Step 006650): Train loss 0.072, Val loss 0.192\n",
      "Ep 4 (Step 006700): Train loss 0.104, Val loss 0.195\n",
      "Ep 4 (Step 006750): Train loss 0.214, Val loss 0.213\n",
      "Ep 4 (Step 006800): Train loss 0.141, Val loss 0.173\n",
      "Ep 4 (Step 006850): Train loss 0.097, Val loss 0.172\n",
      "Ep 4 (Step 006900): Train loss 0.034, Val loss 0.156\n",
      "Ep 4 (Step 006950): Train loss 0.061, Val loss 0.116\n",
      "Ep 4 (Step 007000): Train loss 0.072, Val loss 0.124\n",
      "Ep 4 (Step 007050): Train loss 0.142, Val loss 0.193\n",
      "Ep 4 (Step 007100): Train loss 0.342, Val loss 0.137\n",
      "Ep 4 (Step 007150): Train loss 0.018, Val loss 0.116\n",
      "Ep 4 (Step 007200): Train loss 0.044, Val loss 0.151\n",
      "Ep 4 (Step 007250): Train loss 0.089, Val loss 0.164\n",
      "Ep 4 (Step 007300): Train loss 0.248, Val loss 0.113\n",
      "Ep 4 (Step 007350): Train loss 0.133, Val loss 0.149\n",
      "Ep 4 (Step 007400): Train loss 0.215, Val loss 0.141\n",
      "Ep 4 (Step 007450): Train loss 0.093, Val loss 0.187\n",
      "Ep 4 (Step 007500): Train loss 0.142, Val loss 0.148\n",
      "Ep 4 (Step 007550): Train loss 0.133, Val loss 0.167\n",
      "Ep 4 (Step 007600): Train loss 0.114, Val loss 0.199\n",
      "Ep 4 (Step 007650): Train loss 0.115, Val loss 0.180\n",
      "Ep 4 (Step 007700): Train loss 0.154, Val loss 0.168\n",
      "Ep 4 (Step 007750): Train loss 0.065, Val loss 0.190\n",
      "Ep 4 (Step 007800): Train loss 0.054, Val loss 0.259\n",
      "Ep 4 (Step 007850): Train loss 0.078, Val loss 0.232\n",
      "Ep 4 (Step 007900): Train loss 0.109, Val loss 0.136\n",
      "Ep 4 (Step 007950): Train loss 0.100, Val loss 0.191\n",
      "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
      "Ep 5 (Step 008000): Train loss 0.096, Val loss 0.227\n",
      "Ep 5 (Step 008050): Train loss 0.101, Val loss 0.241\n",
      "Ep 5 (Step 008100): Train loss 0.093, Val loss 0.308\n",
      "Ep 5 (Step 008150): Train loss 0.118, Val loss 0.163\n",
      "Ep 5 (Step 008200): Train loss 0.054, Val loss 0.166\n",
      "Ep 5 (Step 008250): Train loss 0.060, Val loss 0.250\n",
      "Ep 5 (Step 008300): Train loss 0.152, Val loss 0.270\n",
      "Ep 5 (Step 008350): Train loss 0.013, Val loss 0.268\n",
      "Ep 5 (Step 008400): Train loss 0.044, Val loss 0.328\n",
      "Ep 5 (Step 008450): Train loss 0.073, Val loss 0.288\n",
      "Ep 5 (Step 008500): Train loss 0.112, Val loss 0.255\n",
      "Ep 5 (Step 008550): Train loss 0.088, Val loss 0.321\n",
      "Ep 5 (Step 008600): Train loss 0.002, Val loss 0.210\n",
      "Ep 5 (Step 008650): Train loss 0.043, Val loss 0.258\n",
      "Ep 5 (Step 008700): Train loss 0.146, Val loss 0.243\n",
      "Ep 5 (Step 008750): Train loss 0.104, Val loss 0.147\n",
      "Ep 5 (Step 008800): Train loss 0.011, Val loss 0.135\n",
      "Ep 5 (Step 008850): Train loss 0.006, Val loss 0.174\n",
      "Ep 5 (Step 008900): Train loss 0.067, Val loss 0.280\n",
      "Ep 5 (Step 008950): Train loss 0.020, Val loss 0.265\n",
      "Ep 5 (Step 009000): Train loss 0.042, Val loss 0.191\n",
      "Ep 5 (Step 009050): Train loss 0.080, Val loss 0.268\n",
      "Ep 5 (Step 009100): Train loss 0.157, Val loss 0.205\n",
      "Ep 5 (Step 009150): Train loss 0.140, Val loss 0.197\n",
      "Ep 5 (Step 009200): Train loss 0.109, Val loss 0.248\n",
      "Ep 5 (Step 009250): Train loss 0.025, Val loss 0.220\n",
      "Ep 5 (Step 009300): Train loss 0.042, Val loss 0.338\n",
      "Ep 5 (Step 009350): Train loss 0.076, Val loss 0.229\n",
      "Ep 5 (Step 009400): Train loss 0.072, Val loss 0.232\n",
      "Ep 5 (Step 009450): Train loss 0.071, Val loss 0.168\n",
      "Ep 5 (Step 009500): Train loss 0.030, Val loss 0.173\n",
      "Ep 5 (Step 009550): Train loss 0.119, Val loss 0.118\n",
      "Ep 5 (Step 009600): Train loss 0.019, Val loss 0.178\n",
      "Ep 5 (Step 009650): Train loss 0.124, Val loss 0.161\n",
      "Ep 5 (Step 009700): Train loss 0.187, Val loss 0.265\n",
      "Ep 5 (Step 009750): Train loss 0.024, Val loss 0.125\n",
      "Ep 5 (Step 009800): Train loss 0.010, Val loss 0.119\n",
      "Ep 5 (Step 009850): Train loss 0.040, Val loss 0.153\n",
      "Ep 5 (Step 009900): Train loss 0.104, Val loss 0.156\n",
      "Ep 5 (Step 009950): Train loss 0.049, Val loss 0.099\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Training completed in 35.44 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=6e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:33:28.025543Z",
     "iopub.status.busy": "2025-06-17T13:33:28.024992Z",
     "iopub.status.idle": "2025-06-17T13:33:28.797534Z",
     "shell.execute_reply": "2025-06-17T13:33:28.793329Z",
     "shell.execute_reply.started": "2025-06-17T13:33:28.025517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Emotion_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:33:28.799817Z",
     "iopub.status.busy": "2025-06-17T13:33:28.799575Z",
     "iopub.status.idle": "2025-06-17T13:33:29.184210Z",
     "shell.execute_reply": "2025-06-17T13:33:29.177793Z",
     "shell.execute_reply.started": "2025-06-17T13:33:28.799793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"Emotion_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:33:29.186245Z",
     "iopub.status.busy": "2025-06-17T13:33:29.185805Z",
     "iopub.status.idle": "2025-06-17T13:33:29.197231Z",
     "shell.execute_reply": "2025-06-17T13:33:29.192077Z",
     "shell.execute_reply.started": "2025-06-17T13:33:29.186223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:33:29.199459Z",
     "iopub.status.busy": "2025-06-17T13:33:29.199235Z",
     "iopub.status.idle": "2025-06-17T13:33:30.301924Z",
     "shell.execute_reply": "2025-06-17T13:33:30.298429Z",
     "shell.execute_reply.started": "2025-06-17T13:33:29.199436Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:51:44.287606Z",
     "iopub.status.busy": "2025-06-17T13:51:44.287297Z",
     "iopub.status.idle": "2025-06-17T13:51:44.298965Z",
     "shell.execute_reply": "2025-06-17T13:51:44.294505Z",
     "shell.execute_reply.started": "2025-06-17T13:51:44.287580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_emotion(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    # print(predicted_label)\n",
    "    # Return the classified result\n",
    "    return labels[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:51:46.310065Z",
     "iopub.status.busy": "2025-06-17T13:51:46.309736Z",
     "iopub.status.idle": "2025-06-17T13:51:46.386353Z",
     "shell.execute_reply": "2025-06-17T13:51:46.379139Z",
     "shell.execute_reply.started": "2025-06-17T13:51:46.310037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"I feel happy to announce that my finetuning is completed and it works\"\n",
    ")\n",
    "\n",
    "print(classify_emotion(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:53:25.516313Z",
     "iopub.status.busy": "2025-06-17T13:53:25.515945Z",
     "iopub.status.idle": "2025-06-17T13:53:25.839478Z",
     "shell.execute_reply": "2025-06-17T13:53:25.832539Z",
     "shell.execute_reply.started": "2025-06-17T13:53:25.516281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of text_1  :  fear\n",
      "Classification of text_2  :  joy\n",
      "Classification of text_3  :  sadness\n",
      "Classification of text_4  :  anger\n",
      "Classification of text_5  :  surprise\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"i feel a little fear to go to the swimming pool\"\n",
    ")\n",
    "text_3=(\n",
    "    \"i just feel extremely comfortable with the group of people that i dont even need to hide myself\"\n",
    ")\n",
    "text_4=(\n",
    "    \"A plane tragedy happened near the ahmedabad airport. people were sad to hear this\"\n",
    ")\n",
    "text_5=(\n",
    "    \"who the hell do you think you are ? I am warning you not to be rude again\"\n",
    ")\n",
    "text_6=(\n",
    "    \"Aww that was such a great gift. I was awestruck when I opened it\"\n",
    ")\n",
    "print(\"Classification of text_1  : \",classify_emotion(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(\"Classification of text_2  : \",classify_emotion(\n",
    "    text_3, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(\"Classification of text_3  : \",classify_emotion(\n",
    "    text_4, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(\"Classification of text_4  : \",classify_emotion(\n",
    "    text_5, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(\"Classification of text_5  : \",classify_emotion(\n",
    "    text_6, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T13:33:30.469820Z",
     "iopub.status.busy": "2025-06-17T13:33:30.469538Z",
     "iopub.status.idle": "2025-06-17T13:42:34.595401Z",
     "shell.execute_reply": "2025-06-17T13:42:34.590975Z",
     "shell.execute_reply.started": "2025-06-17T13:33:30.469791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 96.89%\n",
      "Validation accuracy: 91.05%\n",
      "Test accuracy: 90.45%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 12700569,
     "datasetId": 7661477,
     "sourceId": 12164626,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 2660858,
     "datasetId": 1590810,
     "sourceId": 2617192,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 12706231,
     "datasetId": 7664729,
     "sourceId": 12169781,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31042,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
