{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT-2 for Subject Classification\n",
    "\n",
    "This project demonstrates how to fine-tune a pre-trained GPT-2 model for the task of classifying student questions into four subjects: **Maths, Chemistry, Physics, and Biology**. The workflow covers data preparation, model adaptation, training, evaluation, and inference.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Workflow\n",
    "\n",
    "### 1. **Data Preparation**\n",
    "- **Dataset:** Student questions dataset from Kaggle, containing questions labeled by subject.\n",
    "- **Balancing:** The dataset is imbalanced (Biology has more entries). We balance it by random sampling so each subject has an equal number of examples.\n",
    "- **Label Encoding:** Subject names are mapped to numerical labels:  \n",
    "    `Maths: 0, Chemistry: 1, Physics: 2, Biology: 3`\n",
    "- **Splitting:** The data is split into training (70%), validation (10%), and test (20%) sets.\n",
    "- **Saving:** Each split is saved as a CSV file for reproducibility.\n",
    "\n",
    "### 2. **Tokenization & Dataset Class**\n",
    "- **Tokenizer:** Uses GPT-2's `tiktoken` tokenizer to encode questions.\n",
    "- **Custom Dataset:** Implements a PyTorch `Dataset` class to handle tokenization, padding, and loading of data for training.\n",
    "\n",
    "### 3. **Model Preparation**\n",
    "- **Model Loading:** Downloads and loads the pre-trained GPT-2 model weights.\n",
    "- **Model Modification:**  \n",
    "    - The output head is replaced with a linear layer for 4-class classification.\n",
    "    - All model parameters are frozen except the output head and the last transformer block (and optionally the final normalization layer) to allow efficient fine-tuning.\n",
    "\n",
    "### 4. **Training**\n",
    "- **Loss & Accuracy Functions:** Custom functions for calculating cross-entropy loss and accuracy.\n",
    "- **Training Loop:**  \n",
    "    - Uses AdamW optimizer.\n",
    "    - Tracks and prints training/validation loss and accuracy.\n",
    "    - Evaluates model performance at regular intervals.\n",
    "- **Saving:** The trained model is saved for later inference.\n",
    "\n",
    "### 5. **Evaluation & Visualization**\n",
    "- **Accuracy:** Evaluates the model on training, validation, and test sets.\n",
    "- **Visualization:** Plots loss and accuracy curves over epochs and examples seen.\n",
    "\n",
    "### 6. **Inference**\n",
    "- **Classification Function:** Provides a function to classify new questions into one of the four subjects.\n",
    "- **Testing:** Demonstrates the classifier on sample questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "- **Training Accuracy:** ~91%\n",
    "- **Validation Accuracy:** ~90%\n",
    "- **Test Accuracy:** ~90%\n",
    "\n",
    "The fine-tuned GPT-2 model achieves high accuracy in classifying student questions by subject, demonstrating the effectiveness of transfer learning and transformer-based models for text classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Transfer Learning:** Leveraging pre-trained language models like GPT-2 enables efficient adaptation to downstream tasks with limited labeled data.\n",
    "- **Balanced Data:** Addressing class imbalance is crucial for fair and robust classification.\n",
    "- **Layer Freezing:** Fine-tuning only the output head and last transformer block preserves pre-trained knowledge while adapting to new tasks.\n",
    "- **Reproducibility:** Saving splits and model weights ensures results can be reproduced and extended.\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook provides a complete, reproducible pipeline for fine-tuning GPT-2 on a real-world text classification problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:42.806204Z",
     "iopub.status.busy": "2025-06-18T10:21:42.805970Z",
     "iopub.status.idle": "2025-06-18T10:21:50.844951Z",
     "shell.execute_reply": "2025-06-18T10:21:50.844129Z",
     "shell.execute_reply.started": "2025-06-18T10:21:42.806179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:50.849871Z",
     "iopub.status.busy": "2025-06-18T10:21:50.849594Z",
     "iopub.status.idle": "2025-06-18T10:21:50.854356Z",
     "shell.execute_reply": "2025-06-18T10:21:50.853530Z",
     "shell.execute_reply.started": "2025-06-18T10:21:50.849841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024) // you can increase this if you have more memory\n",
    "    \"emb_dim\": 768,        # Embedding dimension // we change this later to 4 for classification of 4 classes\n",
    "    \"n_heads\": 12,         # Number of attention heads \n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.2,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:50.855697Z",
     "iopub.status.busy": "2025-06-18T10:21:50.855462Z",
     "iopub.status.idle": "2025-06-18T10:21:54.111090Z",
     "shell.execute_reply": "2025-06-18T10:21:54.110195Z",
     "shell.execute_reply.started": "2025-06-18T10:21:50.855673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:54.112540Z",
     "iopub.status.busy": "2025-06-18T10:21:54.112169Z",
     "iopub.status.idle": "2025-06-18T10:21:54.121101Z",
     "shell.execute_reply": "2025-06-18T10:21:54.120243Z",
     "shell.execute_reply.started": "2025-06-18T10:21:54.112513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:54.123227Z",
     "iopub.status.busy": "2025-06-18T10:21:54.122551Z",
     "iopub.status.idle": "2025-06-18T10:21:54.137481Z",
     "shell.execute_reply": "2025-06-18T10:21:54.136704Z",
     "shell.execute_reply.started": "2025-06-18T10:21:54.123198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:54.139164Z",
     "iopub.status.busy": "2025-06-18T10:21:54.138544Z",
     "iopub.status.idle": "2025-06-18T10:21:55.655193Z",
     "shell.execute_reply": "2025-06-18T10:21:55.654503Z",
     "shell.execute_reply.started": "2025-06-18T10:21:54.139118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:55.656395Z",
     "iopub.status.busy": "2025-06-18T10:21:55.656147Z",
     "iopub.status.idle": "2025-06-18T10:21:55.662316Z",
     "shell.execute_reply": "2025-06-18T10:21:55.661462Z",
     "shell.execute_reply.started": "2025-06-18T10:21:55.656370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:21:55.665221Z",
     "iopub.status.busy": "2025-06-18T10:21:55.664963Z",
     "iopub.status.idle": "2025-06-18T10:22:07.085359Z",
     "shell.execute_reply": "2025-06-18T10:22:07.084612Z",
     "shell.execute_reply.started": "2025-06-18T10:21:55.665197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests  # Make sure requests is installed\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "def download_file(url, destination):\n",
    "    try:\n",
    "        # Send a GET request to download the file, disabling SSL verification\n",
    "        response = requests.get(url, stream=True, verify=False)\n",
    "\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Iterate over the file data in chunks\n",
    "                for chunk in response.iter_content(block_size):\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "                    file.write(chunk)  # Write the chunk to the file\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "        print(f\"Please check the URL: {url}\")\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:07.086906Z",
     "iopub.status.busy": "2025-06-18T10:22:07.086413Z",
     "iopub.status.idle": "2025-06-18T10:22:07.091524Z",
     "shell.execute_reply": "2025-06-18T10:22:07.090530Z",
     "shell.execute_reply.started": "2025-06-18T10:22:07.086874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:07.093380Z",
     "iopub.status.busy": "2025-06-18T10:22:07.093028Z",
     "iopub.status.idle": "2025-06-18T10:22:07.117853Z",
     "shell.execute_reply": "2025-06-18T10:22:07.117069Z",
     "shell.execute_reply.started": "2025-06-18T10:22:07.093344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:07.118978Z",
     "iopub.status.busy": "2025-06-18T10:22:07.118700Z",
     "iopub.status.idle": "2025-06-18T10:22:07.137437Z",
     "shell.execute_reply": "2025-06-18T10:22:07.136673Z",
     "shell.execute_reply.started": "2025-06-18T10:22:07.118954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "# !pip install tiktoken\n",
    "import tiktoken\n",
    "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:07.138909Z",
     "iopub.status.busy": "2025-06-18T10:22:07.138570Z",
     "iopub.status.idle": "2025-06-18T10:22:07.147092Z",
     "shell.execute_reply": "2025-06-18T10:22:07.146339Z",
     "shell.execute_reply.started": "2025-06-18T10:22:07.138873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\" \n",
    "# You can change this to \"gpt2-medium (355M)\", \"gpt2-large (774M)\", or \"gpt2-xl (1558M)\" to use a different model   \n",
    "INPUT_PROMPT = \"Every effort moves\" \n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:07.148145Z",
     "iopub.status.busy": "2025-06-18T10:22:07.147910Z",
     "iopub.status.idle": "2025-06-18T10:22:49.621542Z",
     "shell.execute_reply": "2025-06-18T10:22:49.620759Z",
     "shell.execute_reply.started": "2025-06-18T10:22:07.148116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 148kiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.44MiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 150kiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:37<00:00, 13.3MiB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 7.71MiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.68MiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.61MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:49.623107Z",
     "iopub.status.busy": "2025-06-18T10:22:49.622756Z",
     "iopub.status.idle": "2025-06-18T10:22:57.787229Z",
     "shell.execute_reply": "2025-06-18T10:22:57.786215Z",
     "shell.execute_reply.started": "2025-06-18T10:22:49.623072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to be happy?\n",
      "\n",
      "The answer is simple: you can't be happy.\n",
      "\n",
      "The good news is that you can be happy.\n",
      "\n",
      "The bad news is that you can't be happy.\n",
      "\n",
      "The good news is that you can't be happy.\n",
      "\n",
      "The good news is that you can't be happy.\n",
      "\n",
      "The good news is\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"How to be happy?\"\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    " ###tensor([[6109, 3626, 6100,  345],\n",
    "        ##[6109, 1110, 6622,  257]])\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "\n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=70,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:57.789121Z",
     "iopub.status.busy": "2025-06-18T10:22:57.788120Z",
     "iopub.status.idle": "2025-06-18T10:22:58.026335Z",
     "shell.execute_reply": "2025-06-18T10:22:58.025509Z",
     "shell.execute_reply.started": "2025-06-18T10:22:57.789083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/iitjee-neet-aims-students-questions-data\n"
     ]
    }
   ],
   "source": [
    "import kagglehub #run this command to install kagglehub, try running this on kaggle\n",
    "# Download latest version . this dataset is used for fine-tuning the model , its a dataset of questions asked by students preparing for IIT JEE, NEET, and AIMS exams\n",
    "path = kagglehub.dataset_download(\"mrutyunjaybiswal/iitjee-neet-aims-students-questions-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.027892Z",
     "iopub.status.busy": "2025-06-18T10:22:58.027542Z",
     "iopub.status.idle": "2025-06-18T10:22:58.777562Z",
     "shell.execute_reply": "2025-06-18T10:22:58.776557Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.027852Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Biology' 'Chemistry' 'Maths' 'Physics']\n",
      "eng        122519\n",
      "Subject    122519\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "data=pd.read_csv(\"/kaggle/input/iitjee-neet-aims-students-questions-data/subjects-questions.csv\")\n",
    "# Display unique subjects and count of entries\n",
    "print(data[\"Subject\"].unique())\n",
    "# Display the count of entries in the dataset\n",
    "# This will show how many questions are available for each subject\n",
    "print(data.count())\n",
    "# print(data[\"eng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.778867Z",
     "iopub.status.busy": "2025-06-18T10:22:58.778592Z",
     "iopub.status.idle": "2025-06-18T10:22:58.794353Z",
     "shell.execute_reply": "2025-06-18T10:22:58.793472Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.778841Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "Physics      38438\n",
      "Chemistry    37767\n",
      "Maths        33190\n",
      "Biology      13124\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(data[\"Subject\"])\n",
    "print(data[\"Subject\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.795666Z",
     "iopub.status.busy": "2025-06-18T10:22:58.795419Z",
     "iopub.status.idle": "2025-06-18T10:22:58.867838Z",
     "shell.execute_reply": "2025-06-18T10:22:58.867010Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.795641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "Maths        13124\n",
      "Chemistry    13124\n",
      "Physics      13124\n",
      "Biology      13124\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#This dataset is imbalanced, with \"Biology\" having significantly more entries than the other subjects.\n",
    "# To address this, we will create a balanced dataset by randomly sampling the other subjects to match the number of entries in \"Biology\".\n",
    "def create_balanced_dataset(df):\n",
    "    # Count the instances of \"Biology\" subject\n",
    "    num_spam = df[df[\"Subject\"] == \"Biology\"].shape[0]\n",
    "    #random sampling using .sample() function\n",
    "    Maths_subset=df[df[\"Subject\"]==\"Maths\"].sample(num_spam,random_state=123)\n",
    "    Chemistry_subset=df[df[\"Subject\"]==\"Chemistry\"].sample(num_spam,random_state=123)\n",
    "    Physics_subset=df[df[\"Subject\"]==\"Physics\"].sample(num_spam,random_state=123)\n",
    "    \n",
    "    #lastly concatenate all of them . now we will get 13124 of all of them\n",
    "    balanced_df = pd.concat([Maths_subset,Chemistry_subset,Physics_subset, df[df[\"Subject\"] == \"Biology\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(data)\n",
    "print(balanced_df[\"Subject\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.869098Z",
     "iopub.status.busy": "2025-06-18T10:22:58.868814Z",
     "iopub.status.idle": "2025-06-18T10:22:58.877643Z",
     "shell.execute_reply": "2025-06-18T10:22:58.876870Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.869073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the subject names to numerical labels for classification\n",
    "# This is a common practice in machine learning to convert categorical variables into numerical format.\n",
    "balanced_df[\"Subject\"] = balanced_df[\"Subject\"].map({\"Maths\": 0, \"Chemistry\": 1,\"Physics\":2,\"Biology\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.879135Z",
     "iopub.status.busy": "2025-06-18T10:22:58.878789Z",
     "iopub.status.idle": "2025-06-18T10:22:58.900330Z",
     "shell.execute_reply": "2025-06-18T10:22:58.899428Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.879098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#70% for training , 20% for testing , 10% for validation \n",
    "## We will use a random split to create the train, validation, and test sets.\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is to be 0.2 as the remainder\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.901633Z",
     "iopub.status.busy": "2025-06-18T10:22:58.901383Z",
     "iopub.status.idle": "2025-06-18T10:22:58.906038Z",
     "shell.execute_reply": "2025-06-18T10:22:58.905208Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.901609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36747\n",
      "5249\n",
      "10500\n"
     ]
    }
   ],
   "source": [
    "# print the number of entries in each dataset\n",
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:58.907299Z",
     "iopub.status.busy": "2025-06-18T10:22:58.907061Z",
     "iopub.status.idle": "2025-06-18T10:22:59.228413Z",
     "shell.execute_reply": "2025-06-18T10:22:59.227737Z",
     "shell.execute_reply.started": "2025-06-18T10:22:58.907276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#save these data to the csv files to load them later\n",
    "train_df.to_csv(\"subjects_train.csv\", index=None)\n",
    "validation_df.to_csv(\"subjects_validation.csv\", index=None)\n",
    "test_df.to_csv(\"subjects_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:59.229570Z",
     "iopub.status.busy": "2025-06-18T10:22:59.229342Z",
     "iopub.status.idle": "2025-06-18T10:22:59.237060Z",
     "shell.execute_reply": "2025-06-18T10:22:59.236187Z",
     "shell.execute_reply.started": "2025-06-18T10:22:59.229547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define a custom dataset class for the subjects dataset\n",
    "#The functions in this class will help us to load the data from the csv files and convert them into tensors that can be used for training the model.\n",
    "#basically it will help tokenize the text and convert it into tensors\n",
    "class SubjectsDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"eng\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Subject\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:22:59.238330Z",
     "iopub.status.busy": "2025-06-18T10:22:59.238055Z",
     "iopub.status.idle": "2025-06-18T10:23:02.455214Z",
     "shell.execute_reply": "2025-06-18T10:23:02.454480Z",
     "shell.execute_reply.started": "2025-06-18T10:22:59.238306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = SubjectsDataset(\n",
    "    csv_file=\"subjects_train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# print(train_dataset.max_length)\n",
    "val_dataset = SubjectsDataset(\n",
    "    csv_file=\"subjects_validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SubjectsDataset(\n",
    "    csv_file=\"subjects_test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.457068Z",
     "iopub.status.busy": "2025-06-18T10:23:02.456800Z",
     "iopub.status.idle": "2025-06-18T10:23:02.463883Z",
     "shell.execute_reply": "2025-06-18T10:23:02.463015Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.457041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Create DataLoaders for training, validation, and test datasets\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.468409Z",
     "iopub.status.busy": "2025-06-18T10:23:02.468060Z",
     "iopub.status.idle": "2025-06-18T10:23:02.481203Z",
     "shell.execute_reply": "2025-06-18T10:23:02.480428Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.468366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#In this step we freeze the model parameters so that they are not updated during training.\n",
    "# This is useful when we want to fine-tune the model on a specific task without changing\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.482635Z",
     "iopub.status.busy": "2025-06-18T10:23:02.482367Z",
     "iopub.status.idle": "2025-06-18T10:23:02.494934Z",
     "shell.execute_reply": "2025-06-18T10:23:02.494015Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.482608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the output head for classification\n",
    "# We will change the output head to have 4 classes for classification\n",
    "torch.manual_seed(123)\n",
    "num_classes = 4\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.496352Z",
     "iopub.status.busy": "2025-06-18T10:23:02.496039Z",
     "iopub.status.idle": "2025-06-18T10:23:02.519141Z",
     "shell.execute_reply": "2025-06-18T10:23:02.518344Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.496323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Freeze all parameters except the output head and the last transformer block\n",
    "# This allows the model to retain its pre-trained knowledge while adapting to the new classification task.\n",
    "#you can also try experimenting with freezing more layers, but this is a good starting point\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "# for param in model.trf_blocks[-2].parameters():\n",
    "#     param.requires_grad= True\n",
    "# for param in model.trf_blocks[-3].parameters():\n",
    "#     param.requires_grad=True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.520329Z",
     "iopub.status.busy": "2025-06-18T10:23:02.520084Z",
     "iopub.status.idle": "2025-06-18T10:23:02.528316Z",
     "shell.execute_reply": "2025-06-18T10:23:02.527516Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.520305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[10919,   318, 27140,    44]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Print the model architecture to verify the changes\n",
    "inputs = tokenizer.encode(\"what is LLM\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.529895Z",
     "iopub.status.busy": "2025-06-18T10:23:02.529331Z",
     "iopub.status.idle": "2025-06-18T10:23:02.595164Z",
     "shell.execute_reply": "2025-06-18T10:23:02.594299Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.529868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.6141,  1.2282,  0.3008, -0.5369],\n",
      "         [-1.8646,  5.9696,  2.7381, -0.5265],\n",
      "         [-3.6957,  3.4373,  0.6597, -1.2068],\n",
      "         [-3.2174,  4.3485,  2.2180, -0.3779]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.596632Z",
     "iopub.status.busy": "2025-06-18T10:23:02.596293Z",
     "iopub.status.idle": "2025-06-18T10:23:02.603525Z",
     "shell.execute_reply": "2025-06-18T10:23:02.602696Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.596593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate accuracy for a single batch\n",
    "\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.605261Z",
     "iopub.status.busy": "2025-06-18T10:23:02.604746Z",
     "iopub.status.idle": "2025-06-18T10:23:02.620624Z",
     "shell.execute_reply": "2025-06-18T10:23:02.619883Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.605224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.2174,  4.3485,  2.2180, -0.3779]])\n"
     ]
    }
   ],
   "source": [
    "# Print the last output token, we take the probabilities of the last output token with the softmax function\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:02.621867Z",
     "iopub.status.busy": "2025-06-18T10:23:02.621595Z",
     "iopub.status.idle": "2025-06-18T10:23:12.871420Z",
     "shell.execute_reply": "2025-06-18T10:23:12.870411Z",
     "shell.execute_reply.started": "2025-06-18T10:23:02.621839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training accuracy: 20.00%\n",
      "Validation accuracy: 23.75%\n",
      "Test accuracy: 38.75%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model without training\n",
    "# This will give us the accuracy of the model on the training, validation, and test datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device) \n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:12.872742Z",
     "iopub.status.busy": "2025-06-18T10:23:12.872467Z",
     "iopub.status.idle": "2025-06-18T10:23:12.877693Z",
     "shell.execute_reply": "2025-06-18T10:23:12.876678Z",
     "shell.execute_reply.started": "2025-06-18T10:23:12.872699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:12.879479Z",
     "iopub.status.busy": "2025-06-18T10:23:12.878929Z",
     "iopub.status.idle": "2025-06-18T10:23:12.891611Z",
     "shell.execute_reply": "2025-06-18T10:23:12.890858Z",
     "shell.execute_reply.started": "2025-06-18T10:23:12.879440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:12.893070Z",
     "iopub.status.busy": "2025-06-18T10:23:12.892699Z",
     "iopub.status.idle": "2025-06-18T10:23:17.625618Z",
     "shell.execute_reply": "2025-06-18T10:23:17.624770Z",
     "shell.execute_reply.started": "2025-06-18T10:23:12.893031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.230\n",
      "Validation loss: 3.758\n",
      "Test loss: 3.539\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:17.627006Z",
     "iopub.status.busy": "2025-06-18T10:23:17.626704Z",
     "iopub.status.idle": "2025-06-18T10:23:17.634161Z",
     "shell.execute_reply": "2025-06-18T10:23:17.633247Z",
     "shell.execute_reply.started": "2025-06-18T10:23:17.626980Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:17.635446Z",
     "iopub.status.busy": "2025-06-18T10:23:17.635166Z",
     "iopub.status.idle": "2025-06-18T10:23:17.649534Z",
     "shell.execute_reply": "2025-06-18T10:23:17.648486Z",
     "shell.execute_reply.started": "2025-06-18T10:23:17.635421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T10:23:17.651072Z",
     "iopub.status.busy": "2025-06-18T10:23:17.650704Z",
     "iopub.status.idle": "2025-06-18T13:06:58.840478Z",
     "shell.execute_reply": "2025-06-18T13:06:58.839503Z",
     "shell.execute_reply.started": "2025-06-18T10:23:17.651045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.696, Val loss 3.499\n",
      "Ep 1 (Step 000050): Train loss 1.390, Val loss 1.331\n",
      "Ep 1 (Step 000100): Train loss 1.345, Val loss 1.307\n",
      "Ep 1 (Step 000150): Train loss 1.320, Val loss 1.280\n",
      "Ep 1 (Step 000200): Train loss 1.316, Val loss 1.257\n",
      "Ep 1 (Step 000250): Train loss 1.310, Val loss 1.266\n",
      "Ep 1 (Step 000300): Train loss 1.266, Val loss 1.236\n",
      "Ep 1 (Step 000350): Train loss 1.344, Val loss 1.284\n",
      "Ep 1 (Step 000400): Train loss 1.393, Val loss 1.292\n",
      "Ep 1 (Step 000450): Train loss 1.234, Val loss 1.273\n",
      "Ep 1 (Step 000500): Train loss 1.366, Val loss 1.262\n",
      "Ep 1 (Step 000550): Train loss 1.334, Val loss 1.258\n",
      "Ep 1 (Step 000600): Train loss 1.230, Val loss 1.261\n",
      "Ep 1 (Step 000650): Train loss 1.366, Val loss 1.223\n",
      "Ep 1 (Step 000700): Train loss 1.208, Val loss 1.213\n",
      "Ep 1 (Step 000750): Train loss 1.295, Val loss 1.236\n",
      "Ep 1 (Step 000800): Train loss 1.249, Val loss 1.232\n",
      "Ep 1 (Step 000850): Train loss 1.264, Val loss 1.254\n",
      "Ep 1 (Step 000900): Train loss 1.192, Val loss 1.247\n",
      "Ep 1 (Step 000950): Train loss 1.328, Val loss 1.227\n",
      "Ep 1 (Step 001000): Train loss 1.321, Val loss 1.246\n",
      "Ep 1 (Step 001050): Train loss 1.364, Val loss 1.208\n",
      "Ep 1 (Step 001100): Train loss 1.278, Val loss 1.226\n",
      "Ep 1 (Step 001150): Train loss 1.299, Val loss 1.221\n",
      "Ep 1 (Step 001200): Train loss 1.304, Val loss 1.232\n",
      "Ep 1 (Step 001250): Train loss 1.309, Val loss 1.235\n",
      "Ep 1 (Step 001300): Train loss 1.325, Val loss 1.270\n",
      "Ep 1 (Step 001350): Train loss 1.335, Val loss 1.242\n",
      "Ep 1 (Step 001400): Train loss 1.309, Val loss 1.248\n",
      "Ep 1 (Step 001450): Train loss 1.325, Val loss 1.211\n",
      "Ep 1 (Step 001500): Train loss 1.264, Val loss 1.211\n",
      "Ep 1 (Step 001550): Train loss 1.276, Val loss 1.203\n",
      "Ep 1 (Step 001600): Train loss 1.227, Val loss 1.188\n",
      "Ep 1 (Step 001650): Train loss 1.321, Val loss 1.208\n",
      "Ep 1 (Step 001700): Train loss 1.296, Val loss 1.185\n",
      "Ep 1 (Step 001750): Train loss 1.256, Val loss 1.176\n",
      "Ep 1 (Step 001800): Train loss 1.297, Val loss 1.212\n",
      "Ep 1 (Step 001850): Train loss 1.290, Val loss 1.175\n",
      "Ep 1 (Step 001900): Train loss 1.376, Val loss 1.180\n",
      "Ep 1 (Step 001950): Train loss 1.302, Val loss 1.210\n",
      "Ep 1 (Step 002000): Train loss 1.259, Val loss 1.186\n",
      "Ep 1 (Step 002050): Train loss 1.317, Val loss 1.233\n",
      "Ep 1 (Step 002100): Train loss 1.225, Val loss 1.225\n",
      "Ep 1 (Step 002150): Train loss 1.325, Val loss 1.202\n",
      "Ep 1 (Step 002200): Train loss 1.299, Val loss 1.222\n",
      "Ep 1 (Step 002250): Train loss 1.301, Val loss 1.231\n",
      "Ep 1 (Step 002300): Train loss 1.341, Val loss 1.225\n",
      "Ep 1 (Step 002350): Train loss 1.209, Val loss 1.197\n",
      "Ep 1 (Step 002400): Train loss 1.332, Val loss 1.231\n",
      "Ep 1 (Step 002450): Train loss 1.172, Val loss 1.198\n",
      "Ep 1 (Step 002500): Train loss 1.376, Val loss 1.252\n",
      "Ep 1 (Step 002550): Train loss 1.295, Val loss 1.214\n",
      "Ep 1 (Step 002600): Train loss 1.345, Val loss 1.211\n",
      "Ep 1 (Step 002650): Train loss 1.323, Val loss 1.206\n",
      "Ep 1 (Step 002700): Train loss 1.197, Val loss 1.214\n",
      "Ep 1 (Step 002750): Train loss 1.126, Val loss 1.216\n",
      "Ep 1 (Step 002800): Train loss 1.227, Val loss 1.210\n",
      "Ep 1 (Step 002850): Train loss 1.277, Val loss 1.217\n",
      "Ep 1 (Step 002900): Train loss 1.256, Val loss 1.215\n",
      "Ep 1 (Step 002950): Train loss 1.217, Val loss 1.231\n",
      "Ep 1 (Step 003000): Train loss 1.272, Val loss 1.224\n",
      "Ep 1 (Step 003050): Train loss 1.253, Val loss 1.145\n",
      "Ep 1 (Step 003100): Train loss 1.189, Val loss 1.294\n",
      "Ep 1 (Step 003150): Train loss 1.286, Val loss 1.138\n",
      "Ep 1 (Step 003200): Train loss 1.144, Val loss 1.206\n",
      "Ep 1 (Step 003250): Train loss 1.218, Val loss 1.249\n",
      "Ep 1 (Step 003300): Train loss 1.099, Val loss 1.199\n",
      "Ep 1 (Step 003350): Train loss 1.258, Val loss 1.192\n",
      "Ep 1 (Step 003400): Train loss 1.144, Val loss 1.145\n",
      "Ep 1 (Step 003450): Train loss 1.217, Val loss 1.189\n",
      "Ep 1 (Step 003500): Train loss 1.394, Val loss 1.198\n",
      "Ep 1 (Step 003550): Train loss 1.184, Val loss 1.194\n",
      "Ep 1 (Step 003600): Train loss 1.210, Val loss 1.182\n",
      "Ep 1 (Step 003650): Train loss 1.234, Val loss 1.261\n",
      "Ep 1 (Step 003700): Train loss 1.209, Val loss 1.199\n",
      "Ep 1 (Step 003750): Train loss 1.150, Val loss 1.081\n",
      "Ep 1 (Step 003800): Train loss 1.265, Val loss 1.159\n",
      "Ep 1 (Step 003850): Train loss 1.080, Val loss 1.195\n",
      "Ep 1 (Step 003900): Train loss 1.003, Val loss 1.147\n",
      "Ep 1 (Step 003950): Train loss 1.202, Val loss 1.246\n",
      "Ep 1 (Step 004000): Train loss 1.142, Val loss 1.158\n",
      "Ep 1 (Step 004050): Train loss 1.193, Val loss 1.230\n",
      "Ep 1 (Step 004100): Train loss 1.147, Val loss 1.138\n",
      "Ep 1 (Step 004150): Train loss 1.123, Val loss 1.128\n",
      "Ep 1 (Step 004200): Train loss 1.186, Val loss 1.095\n",
      "Ep 1 (Step 004250): Train loss 0.902, Val loss 1.075\n",
      "Ep 1 (Step 004300): Train loss 1.067, Val loss 1.167\n",
      "Ep 1 (Step 004350): Train loss 0.945, Val loss 1.070\n",
      "Ep 1 (Step 004400): Train loss 0.967, Val loss 1.014\n",
      "Ep 1 (Step 004450): Train loss 1.016, Val loss 0.987\n",
      "Ep 1 (Step 004500): Train loss 0.658, Val loss 1.026\n",
      "Ep 1 (Step 004550): Train loss 1.130, Val loss 1.004\n",
      "Training accuracy: 72.50% | Validation accuracy: 67.50%\n",
      "Ep 2 (Step 004600): Train loss 0.770, Val loss 1.049\n",
      "Ep 2 (Step 004650): Train loss 0.789, Val loss 0.877\n",
      "Ep 2 (Step 004700): Train loss 0.756, Val loss 0.890\n",
      "Ep 2 (Step 004750): Train loss 0.588, Val loss 0.774\n",
      "Ep 2 (Step 004800): Train loss 0.774, Val loss 0.892\n",
      "Ep 2 (Step 004850): Train loss 0.772, Val loss 0.882\n",
      "Ep 2 (Step 004900): Train loss 0.689, Val loss 1.006\n",
      "Ep 2 (Step 004950): Train loss 0.533, Val loss 0.803\n",
      "Ep 2 (Step 005000): Train loss 0.547, Val loss 1.142\n",
      "Ep 2 (Step 005050): Train loss 0.484, Val loss 0.929\n",
      "Ep 2 (Step 005100): Train loss 0.503, Val loss 0.761\n",
      "Ep 2 (Step 005150): Train loss 0.521, Val loss 0.632\n",
      "Ep 2 (Step 005200): Train loss 0.615, Val loss 0.661\n",
      "Ep 2 (Step 005250): Train loss 0.806, Val loss 0.754\n",
      "Ep 2 (Step 005300): Train loss 0.461, Val loss 0.655\n",
      "Ep 2 (Step 005350): Train loss 0.691, Val loss 0.700\n",
      "Ep 2 (Step 005400): Train loss 0.553, Val loss 0.703\n",
      "Ep 2 (Step 005450): Train loss 0.597, Val loss 0.632\n",
      "Ep 2 (Step 005500): Train loss 0.324, Val loss 0.589\n",
      "Ep 2 (Step 005550): Train loss 0.372, Val loss 0.650\n",
      "Ep 2 (Step 005600): Train loss 0.478, Val loss 0.676\n",
      "Ep 2 (Step 005650): Train loss 0.606, Val loss 0.666\n",
      "Ep 2 (Step 005700): Train loss 0.727, Val loss 0.641\n",
      "Ep 2 (Step 005750): Train loss 0.443, Val loss 0.571\n",
      "Ep 2 (Step 005800): Train loss 0.490, Val loss 0.699\n",
      "Ep 2 (Step 005850): Train loss 0.383, Val loss 0.580\n",
      "Ep 2 (Step 005900): Train loss 0.441, Val loss 0.549\n",
      "Ep 2 (Step 005950): Train loss 0.450, Val loss 0.536\n",
      "Ep 2 (Step 006000): Train loss 0.369, Val loss 0.570\n",
      "Ep 2 (Step 006050): Train loss 0.382, Val loss 0.579\n",
      "Ep 2 (Step 006100): Train loss 0.406, Val loss 0.530\n",
      "Ep 2 (Step 006150): Train loss 0.453, Val loss 0.484\n",
      "Ep 2 (Step 006200): Train loss 0.729, Val loss 0.760\n",
      "Ep 2 (Step 006250): Train loss 0.274, Val loss 0.391\n",
      "Ep 2 (Step 006300): Train loss 1.240, Val loss 0.404\n",
      "Ep 2 (Step 006350): Train loss 0.581, Val loss 0.562\n",
      "Ep 2 (Step 006400): Train loss 0.520, Val loss 0.601\n",
      "Ep 2 (Step 006450): Train loss 0.361, Val loss 0.560\n",
      "Ep 2 (Step 006500): Train loss 0.531, Val loss 0.475\n",
      "Ep 2 (Step 006550): Train loss 0.423, Val loss 0.446\n",
      "Ep 2 (Step 006600): Train loss 0.107, Val loss 0.472\n",
      "Ep 2 (Step 006650): Train loss 0.536, Val loss 0.486\n",
      "Ep 2 (Step 006700): Train loss 0.346, Val loss 0.465\n",
      "Ep 2 (Step 006750): Train loss 0.224, Val loss 0.467\n",
      "Ep 2 (Step 006800): Train loss 0.302, Val loss 0.442\n",
      "Ep 2 (Step 006850): Train loss 0.221, Val loss 0.674\n",
      "Ep 2 (Step 006900): Train loss 0.350, Val loss 0.427\n",
      "Ep 2 (Step 006950): Train loss 0.368, Val loss 0.463\n",
      "Ep 2 (Step 007000): Train loss 0.272, Val loss 0.532\n",
      "Ep 2 (Step 007050): Train loss 0.399, Val loss 0.433\n",
      "Ep 2 (Step 007100): Train loss 0.407, Val loss 0.436\n",
      "Ep 2 (Step 007150): Train loss 0.450, Val loss 0.409\n",
      "Ep 2 (Step 007200): Train loss 0.300, Val loss 0.433\n",
      "Ep 2 (Step 007250): Train loss 0.444, Val loss 0.410\n",
      "Ep 2 (Step 007300): Train loss 0.366, Val loss 0.460\n",
      "Ep 2 (Step 007350): Train loss 0.198, Val loss 0.407\n",
      "Ep 2 (Step 007400): Train loss 0.579, Val loss 0.525\n",
      "Ep 2 (Step 007450): Train loss 0.514, Val loss 0.425\n",
      "Ep 2 (Step 007500): Train loss 0.417, Val loss 0.507\n",
      "Ep 2 (Step 007550): Train loss 0.371, Val loss 0.440\n",
      "Ep 2 (Step 007600): Train loss 0.464, Val loss 0.485\n",
      "Ep 2 (Step 007650): Train loss 0.226, Val loss 0.529\n",
      "Ep 2 (Step 007700): Train loss 0.347, Val loss 0.417\n",
      "Ep 2 (Step 007750): Train loss 0.304, Val loss 0.406\n",
      "Ep 2 (Step 007800): Train loss 0.406, Val loss 0.498\n",
      "Ep 2 (Step 007850): Train loss 0.390, Val loss 0.502\n",
      "Ep 2 (Step 007900): Train loss 0.403, Val loss 0.387\n",
      "Ep 2 (Step 007950): Train loss 0.294, Val loss 0.667\n",
      "Ep 2 (Step 008000): Train loss 0.418, Val loss 0.505\n",
      "Ep 2 (Step 008050): Train loss 0.293, Val loss 0.578\n",
      "Ep 2 (Step 008100): Train loss 0.325, Val loss 0.494\n",
      "Ep 2 (Step 008150): Train loss 0.449, Val loss 0.455\n",
      "Ep 2 (Step 008200): Train loss 0.520, Val loss 0.445\n",
      "Ep 2 (Step 008250): Train loss 0.355, Val loss 0.392\n",
      "Ep 2 (Step 008300): Train loss 0.480, Val loss 0.408\n",
      "Ep 2 (Step 008350): Train loss 0.296, Val loss 0.475\n",
      "Ep 2 (Step 008400): Train loss 0.358, Val loss 0.374\n",
      "Ep 2 (Step 008450): Train loss 0.284, Val loss 0.429\n",
      "Ep 2 (Step 008500): Train loss 0.465, Val loss 0.496\n",
      "Ep 2 (Step 008550): Train loss 0.253, Val loss 0.475\n",
      "Ep 2 (Step 008600): Train loss 0.283, Val loss 0.410\n",
      "Ep 2 (Step 008650): Train loss 0.299, Val loss 0.427\n",
      "Ep 2 (Step 008700): Train loss 0.420, Val loss 0.388\n",
      "Ep 2 (Step 008750): Train loss 0.467, Val loss 0.431\n",
      "Ep 2 (Step 008800): Train loss 0.538, Val loss 0.430\n",
      "Ep 2 (Step 008850): Train loss 0.290, Val loss 0.501\n",
      "Ep 2 (Step 008900): Train loss 0.290, Val loss 0.408\n",
      "Ep 2 (Step 008950): Train loss 0.248, Val loss 0.457\n",
      "Ep 2 (Step 009000): Train loss 0.207, Val loss 0.361\n",
      "Ep 2 (Step 009050): Train loss 0.215, Val loss 0.363\n",
      "Ep 2 (Step 009100): Train loss 0.369, Val loss 0.463\n",
      "Ep 2 (Step 009150): Train loss 0.315, Val loss 0.362\n",
      "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 009200): Train loss 0.257, Val loss 0.352\n",
      "Ep 3 (Step 009250): Train loss 0.316, Val loss 0.376\n",
      "Ep 3 (Step 009300): Train loss 0.336, Val loss 0.364\n",
      "Ep 3 (Step 009350): Train loss 0.347, Val loss 0.397\n",
      "Ep 3 (Step 009400): Train loss 0.162, Val loss 0.370\n",
      "Ep 3 (Step 009450): Train loss 0.339, Val loss 0.365\n",
      "Ep 3 (Step 009500): Train loss 0.270, Val loss 0.471\n",
      "Ep 3 (Step 009550): Train loss 0.400, Val loss 0.442\n",
      "Ep 3 (Step 009600): Train loss 0.403, Val loss 0.432\n",
      "Ep 3 (Step 009650): Train loss 0.348, Val loss 0.511\n",
      "Ep 3 (Step 009700): Train loss 0.318, Val loss 0.466\n",
      "Ep 3 (Step 009750): Train loss 0.301, Val loss 0.409\n",
      "Ep 3 (Step 009800): Train loss 0.536, Val loss 0.388\n",
      "Ep 3 (Step 009850): Train loss 0.330, Val loss 0.567\n",
      "Ep 3 (Step 009900): Train loss 0.177, Val loss 0.460\n",
      "Ep 3 (Step 009950): Train loss 0.218, Val loss 0.370\n",
      "Ep 3 (Step 010000): Train loss 0.257, Val loss 0.357\n",
      "Ep 3 (Step 010050): Train loss 0.334, Val loss 0.401\n",
      "Ep 3 (Step 010100): Train loss 0.560, Val loss 0.410\n",
      "Ep 3 (Step 010150): Train loss 0.124, Val loss 0.403\n",
      "Ep 3 (Step 010200): Train loss 0.372, Val loss 0.401\n",
      "Ep 3 (Step 010250): Train loss 0.186, Val loss 0.442\n",
      "Ep 3 (Step 010300): Train loss 0.408, Val loss 0.367\n",
      "Ep 3 (Step 010350): Train loss 0.456, Val loss 0.427\n",
      "Ep 3 (Step 010400): Train loss 0.399, Val loss 0.341\n",
      "Ep 3 (Step 010450): Train loss 0.275, Val loss 0.473\n",
      "Ep 3 (Step 010500): Train loss 0.322, Val loss 0.419\n",
      "Ep 3 (Step 010550): Train loss 0.327, Val loss 0.367\n",
      "Ep 3 (Step 010600): Train loss 0.246, Val loss 0.371\n",
      "Ep 3 (Step 010650): Train loss 0.664, Val loss 0.388\n",
      "Ep 3 (Step 010700): Train loss 0.246, Val loss 0.388\n",
      "Ep 3 (Step 010750): Train loss 0.271, Val loss 0.488\n",
      "Ep 3 (Step 010800): Train loss 0.321, Val loss 0.350\n",
      "Ep 3 (Step 010850): Train loss 0.268, Val loss 0.350\n",
      "Ep 3 (Step 010900): Train loss 0.381, Val loss 0.379\n",
      "Ep 3 (Step 010950): Train loss 0.106, Val loss 0.362\n",
      "Ep 3 (Step 011000): Train loss 0.314, Val loss 0.456\n",
      "Ep 3 (Step 011050): Train loss 0.442, Val loss 0.410\n",
      "Ep 3 (Step 011100): Train loss 0.398, Val loss 0.439\n",
      "Ep 3 (Step 011150): Train loss 0.250, Val loss 0.517\n",
      "Ep 3 (Step 011200): Train loss 0.323, Val loss 0.396\n",
      "Ep 3 (Step 011250): Train loss 0.236, Val loss 0.336\n",
      "Ep 3 (Step 011300): Train loss 0.337, Val loss 0.387\n",
      "Ep 3 (Step 011350): Train loss 0.307, Val loss 0.317\n",
      "Ep 3 (Step 011400): Train loss 0.262, Val loss 0.341\n",
      "Ep 3 (Step 011450): Train loss 0.287, Val loss 0.381\n",
      "Ep 3 (Step 011500): Train loss 0.127, Val loss 0.392\n",
      "Ep 3 (Step 011550): Train loss 0.189, Val loss 0.391\n",
      "Ep 3 (Step 011600): Train loss 0.315, Val loss 0.352\n",
      "Ep 3 (Step 011650): Train loss 0.232, Val loss 0.376\n",
      "Ep 3 (Step 011700): Train loss 0.382, Val loss 0.404\n",
      "Ep 3 (Step 011750): Train loss 0.275, Val loss 0.423\n",
      "Ep 3 (Step 011800): Train loss 0.359, Val loss 0.336\n",
      "Ep 3 (Step 011850): Train loss 0.440, Val loss 0.370\n",
      "Ep 3 (Step 011900): Train loss 0.294, Val loss 0.361\n",
      "Ep 3 (Step 011950): Train loss 0.388, Val loss 0.333\n",
      "Ep 3 (Step 012000): Train loss 0.472, Val loss 0.360\n",
      "Ep 3 (Step 012050): Train loss 0.339, Val loss 0.347\n",
      "Ep 3 (Step 012100): Train loss 0.186, Val loss 0.386\n",
      "Ep 3 (Step 012150): Train loss 0.233, Val loss 0.488\n",
      "Ep 3 (Step 012200): Train loss 0.381, Val loss 0.410\n",
      "Ep 3 (Step 012250): Train loss 0.440, Val loss 0.406\n",
      "Ep 3 (Step 012300): Train loss 0.333, Val loss 0.377\n",
      "Ep 3 (Step 012350): Train loss 0.286, Val loss 0.336\n",
      "Ep 3 (Step 012400): Train loss 0.430, Val loss 0.355\n",
      "Ep 3 (Step 012450): Train loss 0.297, Val loss 0.401\n",
      "Ep 3 (Step 012500): Train loss 0.231, Val loss 0.344\n",
      "Ep 3 (Step 012550): Train loss 0.198, Val loss 0.354\n",
      "Ep 3 (Step 012600): Train loss 0.280, Val loss 0.310\n",
      "Ep 3 (Step 012650): Train loss 0.174, Val loss 0.374\n",
      "Ep 3 (Step 012700): Train loss 0.453, Val loss 0.355\n",
      "Ep 3 (Step 012750): Train loss 0.542, Val loss 0.324\n",
      "Ep 3 (Step 012800): Train loss 0.144, Val loss 0.450\n",
      "Ep 3 (Step 012850): Train loss 0.446, Val loss 0.339\n",
      "Ep 3 (Step 012900): Train loss 0.388, Val loss 0.346\n",
      "Ep 3 (Step 012950): Train loss 0.379, Val loss 0.464\n",
      "Ep 3 (Step 013000): Train loss 0.213, Val loss 0.368\n",
      "Ep 3 (Step 013050): Train loss 0.513, Val loss 0.368\n",
      "Ep 3 (Step 013100): Train loss 0.344, Val loss 0.307\n",
      "Ep 3 (Step 013150): Train loss 0.215, Val loss 0.372\n",
      "Ep 3 (Step 013200): Train loss 0.312, Val loss 0.442\n",
      "Ep 3 (Step 013250): Train loss 0.450, Val loss 0.413\n",
      "Ep 3 (Step 013300): Train loss 0.236, Val loss 0.383\n",
      "Ep 3 (Step 013350): Train loss 0.161, Val loss 0.422\n",
      "Ep 3 (Step 013400): Train loss 0.283, Val loss 0.401\n",
      "Ep 3 (Step 013450): Train loss 0.344, Val loss 0.387\n",
      "Ep 3 (Step 013500): Train loss 0.355, Val loss 0.355\n",
      "Ep 3 (Step 013550): Train loss 0.427, Val loss 0.381\n",
      "Ep 3 (Step 013600): Train loss 0.390, Val loss 0.336\n",
      "Ep 3 (Step 013650): Train loss 0.253, Val loss 0.354\n",
      "Ep 3 (Step 013700): Train loss 0.526, Val loss 0.457\n",
      "Ep 3 (Step 013750): Train loss 0.234, Val loss 0.333\n",
      "Training accuracy: 97.50% | Validation accuracy: 85.00%\n",
      "Ep 4 (Step 013800): Train loss 0.332, Val loss 0.405\n",
      "Ep 4 (Step 013850): Train loss 0.184, Val loss 0.352\n",
      "Ep 4 (Step 013900): Train loss 0.213, Val loss 0.314\n",
      "Ep 4 (Step 013950): Train loss 0.105, Val loss 0.289\n",
      "Ep 4 (Step 014000): Train loss 0.402, Val loss 0.417\n",
      "Ep 4 (Step 014050): Train loss 0.419, Val loss 0.338\n",
      "Ep 4 (Step 014100): Train loss 0.334, Val loss 0.301\n",
      "Ep 4 (Step 014150): Train loss 0.391, Val loss 0.372\n",
      "Ep 4 (Step 014200): Train loss 0.276, Val loss 0.323\n",
      "Ep 4 (Step 014250): Train loss 0.311, Val loss 0.281\n",
      "Ep 4 (Step 014300): Train loss 0.288, Val loss 0.297\n",
      "Ep 4 (Step 014350): Train loss 0.217, Val loss 0.263\n",
      "Ep 4 (Step 014400): Train loss 0.319, Val loss 0.273\n",
      "Ep 4 (Step 014450): Train loss 0.288, Val loss 0.310\n",
      "Ep 4 (Step 014500): Train loss 0.252, Val loss 0.350\n",
      "Ep 4 (Step 014550): Train loss 0.571, Val loss 0.394\n",
      "Ep 4 (Step 014600): Train loss 0.278, Val loss 0.310\n",
      "Ep 4 (Step 014650): Train loss 0.487, Val loss 0.344\n",
      "Ep 4 (Step 014700): Train loss 0.172, Val loss 0.319\n",
      "Ep 4 (Step 014750): Train loss 0.428, Val loss 0.330\n",
      "Ep 4 (Step 014800): Train loss 0.278, Val loss 0.324\n",
      "Ep 4 (Step 014850): Train loss 0.358, Val loss 0.369\n",
      "Ep 4 (Step 014900): Train loss 0.351, Val loss 0.322\n",
      "Ep 4 (Step 014950): Train loss 0.218, Val loss 0.329\n",
      "Ep 4 (Step 015000): Train loss 0.188, Val loss 0.319\n",
      "Ep 4 (Step 015050): Train loss 0.303, Val loss 0.305\n",
      "Ep 4 (Step 015100): Train loss 0.409, Val loss 0.321\n",
      "Ep 4 (Step 015150): Train loss 0.117, Val loss 0.326\n",
      "Ep 4 (Step 015200): Train loss 0.281, Val loss 0.338\n",
      "Ep 4 (Step 015250): Train loss 0.394, Val loss 0.407\n",
      "Ep 4 (Step 015300): Train loss 0.380, Val loss 0.319\n",
      "Ep 4 (Step 015350): Train loss 0.241, Val loss 0.354\n",
      "Ep 4 (Step 015400): Train loss 0.296, Val loss 0.354\n",
      "Ep 4 (Step 015450): Train loss 0.488, Val loss 0.308\n",
      "Ep 4 (Step 015500): Train loss 0.191, Val loss 0.364\n",
      "Ep 4 (Step 015550): Train loss 0.149, Val loss 0.291\n",
      "Ep 4 (Step 015600): Train loss 0.253, Val loss 0.303\n",
      "Ep 4 (Step 015650): Train loss 0.267, Val loss 0.358\n",
      "Ep 4 (Step 015700): Train loss 0.136, Val loss 0.346\n",
      "Ep 4 (Step 015750): Train loss 0.446, Val loss 0.412\n",
      "Ep 4 (Step 015800): Train loss 0.227, Val loss 0.336\n",
      "Ep 4 (Step 015850): Train loss 0.347, Val loss 0.371\n",
      "Ep 4 (Step 015900): Train loss 0.178, Val loss 0.311\n",
      "Ep 4 (Step 015950): Train loss 0.176, Val loss 0.373\n",
      "Ep 4 (Step 016000): Train loss 0.214, Val loss 0.336\n",
      "Ep 4 (Step 016050): Train loss 0.171, Val loss 0.358\n",
      "Ep 4 (Step 016100): Train loss 0.292, Val loss 0.299\n",
      "Ep 4 (Step 016150): Train loss 0.193, Val loss 0.378\n",
      "Ep 4 (Step 016200): Train loss 0.208, Val loss 0.308\n",
      "Ep 4 (Step 016250): Train loss 0.216, Val loss 0.316\n",
      "Ep 4 (Step 016300): Train loss 0.178, Val loss 0.338\n",
      "Ep 4 (Step 016350): Train loss 0.177, Val loss 0.384\n",
      "Ep 4 (Step 016400): Train loss 0.366, Val loss 0.329\n",
      "Ep 4 (Step 016450): Train loss 0.249, Val loss 0.336\n",
      "Ep 4 (Step 016500): Train loss 0.310, Val loss 0.298\n",
      "Ep 4 (Step 016550): Train loss 0.391, Val loss 0.286\n",
      "Ep 4 (Step 016600): Train loss 0.326, Val loss 0.345\n",
      "Ep 4 (Step 016650): Train loss 0.293, Val loss 0.278\n",
      "Ep 4 (Step 016700): Train loss 0.200, Val loss 0.319\n",
      "Ep 4 (Step 016750): Train loss 0.227, Val loss 0.286\n",
      "Ep 4 (Step 016800): Train loss 0.347, Val loss 0.344\n",
      "Ep 4 (Step 016850): Train loss 0.187, Val loss 0.316\n",
      "Ep 4 (Step 016900): Train loss 0.361, Val loss 0.285\n",
      "Ep 4 (Step 016950): Train loss 0.230, Val loss 0.293\n",
      "Ep 4 (Step 017000): Train loss 0.154, Val loss 0.296\n",
      "Ep 4 (Step 017050): Train loss 0.145, Val loss 0.321\n",
      "Ep 4 (Step 017100): Train loss 0.375, Val loss 0.352\n",
      "Ep 4 (Step 017150): Train loss 0.500, Val loss 0.379\n",
      "Ep 4 (Step 017200): Train loss 0.450, Val loss 0.271\n",
      "Ep 4 (Step 017250): Train loss 0.344, Val loss 0.349\n",
      "Ep 4 (Step 017300): Train loss 0.387, Val loss 0.369\n",
      "Ep 4 (Step 017350): Train loss 0.359, Val loss 0.305\n",
      "Ep 4 (Step 017400): Train loss 0.167, Val loss 0.268\n",
      "Ep 4 (Step 017450): Train loss 0.065, Val loss 0.296\n",
      "Ep 4 (Step 017500): Train loss 0.404, Val loss 0.278\n",
      "Ep 4 (Step 017550): Train loss 0.210, Val loss 0.283\n",
      "Ep 4 (Step 017600): Train loss 0.068, Val loss 0.300\n",
      "Ep 4 (Step 017650): Train loss 0.264, Val loss 0.287\n",
      "Ep 4 (Step 017700): Train loss 0.378, Val loss 0.289\n",
      "Ep 4 (Step 017750): Train loss 0.149, Val loss 0.326\n",
      "Ep 4 (Step 017800): Train loss 0.480, Val loss 0.349\n",
      "Ep 4 (Step 017850): Train loss 0.254, Val loss 0.304\n",
      "Ep 4 (Step 017900): Train loss 0.337, Val loss 0.282\n",
      "Ep 4 (Step 017950): Train loss 0.353, Val loss 0.244\n",
      "Ep 4 (Step 018000): Train loss 0.411, Val loss 0.269\n",
      "Ep 4 (Step 018050): Train loss 0.227, Val loss 0.304\n",
      "Ep 4 (Step 018100): Train loss 0.219, Val loss 0.274\n",
      "Ep 4 (Step 018150): Train loss 0.224, Val loss 0.365\n",
      "Ep 4 (Step 018200): Train loss 0.225, Val loss 0.326\n",
      "Ep 4 (Step 018250): Train loss 0.226, Val loss 0.380\n",
      "Ep 4 (Step 018300): Train loss 0.346, Val loss 0.323\n",
      "Ep 4 (Step 018350): Train loss 0.091, Val loss 0.275\n",
      "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
      "Ep 5 (Step 018400): Train loss 0.346, Val loss 0.255\n",
      "Ep 5 (Step 018450): Train loss 0.293, Val loss 0.320\n",
      "Ep 5 (Step 018500): Train loss 0.235, Val loss 0.264\n",
      "Ep 5 (Step 018550): Train loss 0.092, Val loss 0.293\n",
      "Ep 5 (Step 018600): Train loss 0.298, Val loss 0.299\n",
      "Ep 5 (Step 018650): Train loss 0.139, Val loss 0.301\n",
      "Ep 5 (Step 018700): Train loss 0.156, Val loss 0.244\n",
      "Ep 5 (Step 018750): Train loss 0.286, Val loss 0.264\n",
      "Ep 5 (Step 018800): Train loss 0.344, Val loss 0.323\n",
      "Ep 5 (Step 018850): Train loss 0.282, Val loss 0.286\n",
      "Ep 5 (Step 018900): Train loss 0.242, Val loss 0.274\n",
      "Ep 5 (Step 018950): Train loss 0.135, Val loss 0.231\n",
      "Ep 5 (Step 019000): Train loss 0.339, Val loss 0.262\n",
      "Ep 5 (Step 019050): Train loss 0.254, Val loss 0.381\n",
      "Ep 5 (Step 019100): Train loss 0.166, Val loss 0.272\n",
      "Ep 5 (Step 019150): Train loss 0.281, Val loss 0.271\n",
      "Ep 5 (Step 019200): Train loss 0.190, Val loss 0.364\n",
      "Ep 5 (Step 019250): Train loss 0.248, Val loss 0.306\n",
      "Ep 5 (Step 019300): Train loss 0.257, Val loss 0.335\n",
      "Ep 5 (Step 019350): Train loss 0.205, Val loss 0.291\n",
      "Ep 5 (Step 019400): Train loss 0.195, Val loss 0.280\n",
      "Ep 5 (Step 019450): Train loss 0.386, Val loss 0.353\n",
      "Ep 5 (Step 019500): Train loss 0.362, Val loss 0.240\n",
      "Ep 5 (Step 019550): Train loss 0.327, Val loss 0.309\n",
      "Ep 5 (Step 019600): Train loss 0.134, Val loss 0.284\n",
      "Ep 5 (Step 019650): Train loss 0.262, Val loss 0.264\n",
      "Ep 5 (Step 019700): Train loss 0.286, Val loss 0.284\n",
      "Ep 5 (Step 019750): Train loss 0.200, Val loss 0.284\n",
      "Ep 5 (Step 019800): Train loss 0.339, Val loss 0.276\n",
      "Ep 5 (Step 019850): Train loss 0.377, Val loss 0.250\n",
      "Ep 5 (Step 019900): Train loss 0.368, Val loss 0.343\n",
      "Ep 5 (Step 019950): Train loss 0.225, Val loss 0.328\n",
      "Ep 5 (Step 020000): Train loss 0.210, Val loss 0.409\n",
      "Ep 5 (Step 020050): Train loss 0.038, Val loss 0.333\n",
      "Ep 5 (Step 020100): Train loss 0.421, Val loss 0.286\n",
      "Ep 5 (Step 020150): Train loss 0.179, Val loss 0.280\n",
      "Ep 5 (Step 020200): Train loss 0.182, Val loss 0.301\n",
      "Ep 5 (Step 020250): Train loss 0.261, Val loss 0.317\n",
      "Ep 5 (Step 020300): Train loss 0.231, Val loss 0.360\n",
      "Ep 5 (Step 020350): Train loss 0.157, Val loss 0.308\n",
      "Ep 5 (Step 020400): Train loss 0.176, Val loss 0.335\n",
      "Ep 5 (Step 020450): Train loss 0.242, Val loss 0.357\n",
      "Ep 5 (Step 020500): Train loss 0.315, Val loss 0.252\n",
      "Ep 5 (Step 020550): Train loss 0.146, Val loss 0.266\n",
      "Ep 5 (Step 020600): Train loss 0.154, Val loss 0.270\n",
      "Ep 5 (Step 020650): Train loss 0.180, Val loss 0.323\n",
      "Ep 5 (Step 020700): Train loss 0.124, Val loss 0.248\n",
      "Ep 5 (Step 020750): Train loss 0.357, Val loss 0.274\n",
      "Ep 5 (Step 020800): Train loss 0.541, Val loss 0.274\n",
      "Ep 5 (Step 020850): Train loss 0.275, Val loss 0.229\n",
      "Ep 5 (Step 020900): Train loss 0.177, Val loss 0.271\n",
      "Ep 5 (Step 020950): Train loss 0.181, Val loss 0.282\n",
      "Ep 5 (Step 021000): Train loss 0.038, Val loss 0.262\n",
      "Ep 5 (Step 021050): Train loss 0.273, Val loss 0.202\n",
      "Ep 5 (Step 021100): Train loss 0.261, Val loss 0.286\n",
      "Ep 5 (Step 021150): Train loss 0.182, Val loss 0.250\n",
      "Ep 5 (Step 021200): Train loss 0.275, Val loss 0.345\n",
      "Ep 5 (Step 021250): Train loss 0.288, Val loss 0.283\n",
      "Ep 5 (Step 021300): Train loss 0.161, Val loss 0.261\n",
      "Ep 5 (Step 021350): Train loss 0.054, Val loss 0.233\n",
      "Ep 5 (Step 021400): Train loss 0.220, Val loss 0.245\n",
      "Ep 5 (Step 021450): Train loss 0.536, Val loss 0.219\n",
      "Ep 5 (Step 021500): Train loss 0.404, Val loss 0.242\n",
      "Ep 5 (Step 021550): Train loss 0.364, Val loss 0.253\n",
      "Ep 5 (Step 021600): Train loss 0.184, Val loss 0.346\n",
      "Ep 5 (Step 021650): Train loss 0.324, Val loss 0.310\n",
      "Ep 5 (Step 021700): Train loss 0.362, Val loss 0.334\n",
      "Ep 5 (Step 021750): Train loss 0.125, Val loss 0.266\n",
      "Ep 5 (Step 021800): Train loss 0.113, Val loss 0.309\n",
      "Ep 5 (Step 021850): Train loss 0.231, Val loss 0.339\n",
      "Ep 5 (Step 021900): Train loss 0.287, Val loss 0.253\n",
      "Ep 5 (Step 021950): Train loss 0.331, Val loss 0.275\n",
      "Ep 5 (Step 022000): Train loss 0.335, Val loss 0.227\n",
      "Ep 5 (Step 022050): Train loss 0.245, Val loss 0.289\n",
      "Ep 5 (Step 022100): Train loss 0.183, Val loss 0.290\n",
      "Ep 5 (Step 022150): Train loss 0.110, Val loss 0.336\n",
      "Ep 5 (Step 022200): Train loss 0.128, Val loss 0.264\n",
      "Ep 5 (Step 022250): Train loss 0.224, Val loss 0.236\n",
      "Ep 5 (Step 022300): Train loss 0.159, Val loss 0.318\n",
      "Ep 5 (Step 022350): Train loss 0.287, Val loss 0.270\n",
      "Ep 5 (Step 022400): Train loss 0.118, Val loss 0.332\n",
      "Ep 5 (Step 022450): Train loss 0.292, Val loss 0.291\n",
      "Ep 5 (Step 022500): Train loss 0.303, Val loss 0.332\n",
      "Ep 5 (Step 022550): Train loss 0.217, Val loss 0.268\n",
      "Ep 5 (Step 022600): Train loss 0.223, Val loss 0.249\n",
      "Ep 5 (Step 022650): Train loss 0.260, Val loss 0.297\n",
      "Ep 5 (Step 022700): Train loss 0.275, Val loss 0.251\n",
      "Ep 5 (Step 022750): Train loss 0.223, Val loss 0.234\n",
      "Ep 5 (Step 022800): Train loss 0.380, Val loss 0.270\n",
      "Ep 5 (Step 022850): Train loss 0.105, Val loss 0.248\n",
      "Ep 5 (Step 022900): Train loss 0.527, Val loss 0.318\n",
      "Ep 5 (Step 022950): Train loss 0.126, Val loss 0.207\n",
      "Training accuracy: 87.50% | Validation accuracy: 90.00%\n",
      "Training completed in 163.69 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model, we will use the AdamW optimizer with a learning rate of 5e-5 and weight decay of 0.1\n",
    "#experiment with different learning rates and weight decay values to see how it affects the training\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:06:58.842034Z",
     "iopub.status.busy": "2025-06-18T13:06:58.841509Z",
     "iopub.status.idle": "2025-06-18T13:06:59.654494Z",
     "shell.execute_reply": "2025-06-18T13:06:59.653548Z",
     "shell.execute_reply.started": "2025-06-18T13:06:58.842006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#the most important part is to save the model after training so that we can use it later for inference\n",
    "# Save the model state dictionary to a file\n",
    "torch.save(model.state_dict(), \"Subject_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:06:59.656040Z",
     "iopub.status.busy": "2025-06-18T13:06:59.655746Z",
     "iopub.status.idle": "2025-06-18T13:07:00.016401Z",
     "shell.execute_reply": "2025-06-18T13:07:00.015527Z",
     "shell.execute_reply.started": "2025-06-18T13:06:59.656013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3757124446.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"Subject_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model state dictionary from the file\n",
    "model_state_dict = torch.load(\"Subject_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:07:00.017992Z",
     "iopub.status.busy": "2025-06-18T13:07:00.017607Z",
     "iopub.status.idle": "2025-06-18T13:07:00.024309Z",
     "shell.execute_reply": "2025-06-18T13:07:00.023376Z",
     "shell.execute_reply.started": "2025-06-18T13:07:00.017955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:07:00.025555Z",
     "iopub.status.busy": "2025-06-18T13:07:00.025277Z",
     "iopub.status.idle": "2025-06-18T13:07:01.550626Z",
     "shell.execute_reply": "2025-06-18T13:07:01.549405Z",
     "shell.execute_reply.started": "2025-06-18T13:07:00.025531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3uElEQVR4nO3dd3hTZRvA4V9Gk+4JdFBaVtmlbGQjFCgqshRFVFAEURAQUT4cLAcobkUcIKgsAQEXe8ueZVNWoYwuoHs3Od8fadOEllUKaeG5rytXkzPfc9L2Oe9WKYqiIIQQQohSSW3rBAghhBDi+iRQCyGEEKWYBGohhBCiFJNALYQQQpRiEqiFEEKIUkwCtRBCCFGKSaAWQgghSjEJ1EIIIUQpJoFaCCGEKMUkUAshrLRv356RI0faOhlCiDwSqIUoYQMGDEClUhV6hYWF2TppQogySGvrBAhxPwoLC2PWrFlWy/R6vY1SI4QoyyRHLcRdoNfr8fHxsXp5eHgAsHHjRnQ6Hf/99595+08++YQKFSoQGxsLwMqVK2ndujXu7u54eXnx2GOPcfr0afP2Z8+eRaVSsXDhQtq0aYODgwNNmzblxIkT7N69myZNmuDs7EzXrl2Jj4837zdgwAB69OjBxIkTKV++PK6urgwZMoTs7OzrXktWVhajR4+mYsWKODk50bx5czZu3Ghef+7cObp164aHhwdOTk7UrVuX5cuXX/d43333HUFBQdjb2+Pt7c0TTzxhXmc0Gpk8eTJVqlTBwcGBkJAQFi9ebLX/4cOH6dq1K87Oznh7e/Pcc89x+fJl8/r27dszfPhw3nrrLTw9PfHx8WHChAnXTY8QpZ0EaiHusfw64Oeee46kpCT279/Pe++9x4wZM/D29gYgLS2NUaNGsWfPHtatW4daraZnz54YjUarY40fP553332Xffv2odVqeeaZZ3jrrbf46quv+O+//zh16hTjxo2z2mfdunUcO3aMjRs3Mn/+fJYsWcLEiROvm95hw4axfft2FixYwMGDB3nyyScJCwvj5MmTAAwdOpSsrCw2b97MoUOH+Pjjj3F2di7yWHv27GH48OFMmjSJiIgIVq5cSdu2bc3rJ0+ezK+//sr333/PkSNHeP3113n22WfZtGkTAImJiXTo0IGGDRuyZ88eVq5cSWxsLH369LE6zy+//IKTkxM7d+7kk08+YdKkSaxZs+YWvyEhShlFCFGi+vfvr2g0GsXJycnq9eGHH5q3ycrKUho0aKD06dNHqVOnjjJo0KAbHjM+Pl4BlEOHDimKoiiRkZEKoMyYMcO8zfz58xVAWbdunXnZ5MmTlZo1a1qlzdPTU0lLSzMvmz59uuLs7KwYDAZFURSlXbt2yogRIxRFUZRz584pGo1GuXjxolV6OnbsqIwdO1ZRFEUJDg5WJkyYcEv35o8//lBcXV2V5OTkQusyMzMVR0dHZdu2bVbLBw4cqPTt21dRFEV5//33lc6dO1utP3/+vAIoERER5vS3bt3aapumTZsqY8aMuaU0ClHaSB21EHfBww8/zPTp062WeXp6mt/rdDrmzp1L/fr1CQwM5IsvvrDa9uTJk4wbN46dO3dy+fJlc046KiqKevXqmberX7+++X1+bjw4ONhqWVxcnNWxQ0JCcHR0NH9u0aIFqampnD9/nsDAQKttDx06hMFgoEaNGlbLs7Ky8PLyAmD48OG88sorrF69mtDQUHr37m2VLkudOnUiMDCQqlWrEhYWRlhYGD179sTR0ZFTp06Rnp5Op06drPbJzs6mYcOGABw4cIANGzYUmWM/ffq0OZ3Xnt/X17fQfRCirJBALcRd4OTkRPXq1W+4zbZt2wC4evUqV69excnJybyuW7duBAYG8tNPP+Hn54fRaKRevXqF6pLt7OzM71UqVZHLri0uvx2pqaloNBr27t2LRqOxWpcfLF966SW6dOnCv//+y+rVq5k8eTKfffYZr732WqHjubi4sG/fPjZu3Mjq1asZN24cEyZMYPfu3aSmpgLw77//UrFiRav98hvipaam0q1bNz7++ONCx/b19TW/t7wHcOf3QQhbkkAthA2cPn2a119/nZ9++onff/+d/v37s3btWtRqNVeuXCEiIoKffvqJNm3aALBly5YSO/eBAwfIyMjAwcEBgB07duDs7EylSpUKbduwYUMMBgNxcXHmtBSlUqVKDBkyhCFDhjB27Fh++umnIgM1gFarJTQ0lNDQUMaPH4+7uzvr16+nU6dO6PV6oqKiaNeuXZH7NmrUiD/++IPKlSuj1cq/L/FgkN90Ie6CrKwsYmJirJZptVrKlSuHwWDg2WefpUuXLrzwwguEhYURHBzMZ599xptvvomHhwdeXl78+OOP+Pr6EhUVxf/+978SS1t2djYDBw7k3Xff5ezZs4wfP55hw4ahVhduW1qjRg369evH888/z2effUbDhg2Jj49n3bp11K9fn0cffZSRI0fStWtXatSoQUJCAhs2bKB27dpFnvuff/7hzJkztG3bFg8PD5YvX47RaKRmzZq4uLgwevRoXn/9dYxGI61btyYpKYmtW7fi6upK//79GTp0KD/99BN9+/Y1t+o+deoUCxYsYMaMGYVy/ULcDyRQC3EXrFy50qooFqBmzZocP36cDz/8kHPnzvHPP/8ApiLbH3/8kb59+9K5c2dCQkJYsGABw4cPp169etSsWZOvv/6a9u3bl0jaOnbsSFBQEG3btiUrK4u+ffvesPvSrFmz+OCDD3jjjTe4ePEi5cqV46GHHuKxxx4DwGAwMHToUC5cuICrqythYWGF6tzzubu7s2TJEiZMmEBmZiZBQUHMnz+funXrAvD+++9Tvnx5Jk+ezJkzZ3B3d6dRo0a8/fbbAPj5+bF161bGjBlD586dycrKIjAwkLCwsCIfNIS4H6gURVFsnQghxL0xYMAAEhMTWbZsma2TIoS4RfIIKoQQQpRiEqiFEEKIUkyKvoUQQohSTHLUQgghRCkmgVoIIYQoxSRQCyGEEKWYBOo806ZNo3Llytjb29O8eXN27dplk3RMnjyZpk2b4uLiQoUKFejRowcRERFW27Rv3x6VSmX1GjJkiNU2UVFRPProozg6OlKhQgXefPNNcnNzrbbZuHEjjRo1Qq/XU716dWbPnl0oPSV1XyZMmFAozbVq1TKvz8zMZOjQoXh5eeHs7Ezv3r3NUz6W1muqXLlyoWtSqVQMHToUKDvf0+bNm+nWrRt+fn6oVKpCXbcURWHcuHH4+vri4OBAaGioeeasfFevXqVfv364urri7u7OwIEDzUOC5jt48CBt2rTB3t6eSpUq8cknnxRKy6JFi6hVqxb29vYEBwcXmi7zVtJys2vKyclhzJgxBAcH4+TkhJ+fH88//zyXLl2yOkZR3++UKVNsdk03uy4wdb+7Ns1hYWFW25Sl7woo8m9MpVIxdepU8zal8bsqUTabDqQUWbBggaLT6ZSff/5ZOXLkiDJo0CDF3d1diY2Nvedp6dKlizJr1izl8OHDSnh4uPLII48oAQEBSmpqqnmbdu3aKYMGDVKio6PNr6SkJPP63NxcpV69ekpoaKiyf/9+Zfny5Uq5cuXMsx0piqKcOXNGcXR0VEaNGqUcPXpU+eabbxSNRqOsXLnSvE1J3pfx48crdevWtUpzfHy8ef2QIUOUSpUqKevWrVP27NmjPPTQQ0rLli1L9TXFxcVZXc+aNWsUQNmwYYOiKGXne1q+fLnyzjvvKEuWLFEAZenSpVbrp0yZori5uSnLli1TDhw4oDz++ONKlSpVlIyMDPM2YWFhSkhIiLJjxw7lv//+U6pXr26e8UpRFCUpKUnx9vZW+vXrpxw+fFiZP3++4uDgoPzwww/mbbZu3apoNBrlk08+UY4ePaq8++67ip2dnXnGsFtNy82uKTExUQkNDVV+//135fjx48r27duVZs2aKY0bN7Y6RmBgoDJp0iSr78/y7/BeX9OtfFf9+/dXwsLCrNJ89epVq23K0nelKIrVtURHRys///yzolKplNOnT5fq76okSaBWFKVZs2bK0KFDzZ8NBoPi5+enTJ482YapMomLi1MAZdOmTeZlltMQFmX58uWKWq1WYmJizMumT5+uuLq6KllZWYqiKMpbb72l1K1b12q/p556SunSpYv5c0nel/HjxyshISFFrktMTFTs7OyURYsWmZcdO3ZMAZTt27eX2mu61ogRI5Rq1aopRqNRUZSy+T1d+4/SaDQqPj4+ytSpU83LEhMTFb1er8yfP19RFEU5evSoAii7d+82b7NixQpFpVKZp8f87rvvFA8PD/N1KYqijBkzxmoKzj59+iiPPvqoVXqaN2+uvPzyy7ecllu5pqLs2rVLAZRz586ZlwUGBipffPHFdfex5TVd77r69++vdO/e/br73A/fVffu3ZUOHTpYLSvt39WdeuCLvrOzs9m7dy+hoaHmZWq1mtDQULZv327DlJkkJSUB1lMkAsydO5dy5cpRr149xo4dS3p6unnd9u3bCQ4ONk97CNClSxeSk5M5cuSIeRvLa87fJv+a78Z9OXnyJH5+flStWpV+/foRFRUFwN69e8nJybE6V61atQgICDCfq7ReU77s7GzmzJnDiy++aJ7FCsrm92QpMjKSmJgYq+O7ubnRvHlzq+/G3d2dJk2amLcJDQ1FrVazc+dO8zZt27ZFp9NZXUdERAQJCQm3dK23kpbiSkpKQqVS4e7ubrV8ypQpeHl50bBhQ6ZOnWpVLVFar2njxo1UqFCBmjVr8sorr3DlyhWrNJfl7yo2NpZ///2XgQMHFlpXFr+rW/XAj/V9+fJlDAaD1T9LMM3je/z4cRulysRoNDJy5EhatWplNQfxM888Q2BgIH5+fhw8eJAxY8YQERHBkiVLAIiJiSnyevLX3Wib5ORkMjIySEhIKNH70rx5c2bPnk3NmjWJjo5m4sSJtGnThsOHDxMTE4NOpyv0T9Lb2/um6bXlNVlatmwZiYmJDBgwwLysLH5P18pPR1HHt0xjhQoVrNZrtVo8PT2ttqlSpUqhY+Sv8/DwuO61Wh7jZmkpjszMTMaMGUPfvn1xdXU1Lx8+fDiNGjXC09OTbdu2MXbsWKKjo/n8889L7TWFhYXRq1cvqlSpwunTp3n77bfp2rUr27dvR6PRlPnv6pdffsHFxYVevXpZLS+L39XteOADdWk2dOhQDh8+XGiKw8GDB5vfBwcH4+vrS8eOHTl9+jTVqlW718m8JV27djW/r1+/Ps2bNycwMJCFCxeap1ssy2bOnEnXrl3x8/MzLyuL39ODJicnhz59+qAoCtOnT7daN2rUKPP7+vXro9PpePnll5k8ebJ5fuzS5umnnza/Dw4Opn79+lSrVo2NGzfSsWNHG6asZPz888/069cPe3t7q+Vl8bu6HQ980Xe5cuXQaDSFWhjHxsbi4+Njo1TBsGHD+Oeff9iwYQP+/v433LZ58+YAnDp1CgAfH58iryd/3Y22cXV1xcHB4a7fF3d3d2rUqMGpU6fw8fEhOzubxMTE656rNF/TuXPnWLt2LS+99NINtyuL31P+MW50fB8fH+Li4qzW5+bmcvXq1RL5/izX3ywttyM/SJ87d441a9ZY5aaL0rx5c3Jzczl79mypvaZrVa1alXLlyln9zpXF7wrgv//+IyIi4qZ/Z1A2v6sbeeADtU6no3Hjxqxbt868zGg0sm7dOlq0aHHP06MoCsOGDWPp0qWsX7++UHFNUcLDwwHM0yq2aNGCQ4cOWf1B5v8jqlOnjnkby2vO3yb/mu/2fUlNTeX06dP4+vrSuHFj7OzsrM4VERFBVFSU+Vyl+ZpmzZpFhQoVePTRR2+4XVn8nqpUqYKPj4/V8ZOTk9m5c6fVd5OYmMjevXvN26xfvx6j0Wh+OGnRogWbN28mJyfH6jpq1qyJh4fHLV3rraTlVuUH6ZMnT7J27Vq8vLxuuk94eDhqtdpcdFzarqkoFy5c4MqVK1a/c2Xtu8o3c+ZMGjduTEhIyE23LYvf1Q3d1aZqZcSCBQsUvV6vzJ49Wzl69KgyePBgxd3d3ao17r3yyiuvKG5ubsrGjRutuhqkp6criqIop06dUiZNmqTs2bNHiYyMVP7880+latWqStu2bc3HyO/207lzZyU8PFxZuXKlUr58+SK7/bz55pvKsWPHlGnTphXZ7aek7ssbb7yhbNy4UYmMjFS2bt2qhIaGKuXKlVPi4uIURTF1zwoICFDWr1+v7NmzR2nRooXSokWLUn1NimJqYR0QEKCMGTPGanlZ+p5SUlKU/fv3K/v371cA5fPPP1f2799vbgE9ZcoUxd3dXfnzzz+VgwcPKt27dy+ye1bDhg2VnTt3Klu2bFGCgoKsuvwkJiYq3t7eynPPPaccPnxYWbBggeLo6Fioe4xWq1U+/fRT5dixY8r48eOL7B5zs7Tc7Jqys7OVxx9/XPH391fCw8Ot/s7yWwVv27ZN+eKLL5Tw8HDl9OnTypw5c5Ty5csrzz//vM2u6WbXlZKSoowePVrZvn27EhkZqaxdu1Zp1KiREhQUpGRmZpbJ7ypfUlKS4ujoqEyfPr3QPSmt31VJkkCd55tvvlECAgIUnU6nNGvWTNmxY4dN0gEU+Zo1a5aiKIoSFRWltG3bVvH09FT0er1SvXp15c0337Tqn6soinL27Fmla9euioODg1KuXDnljTfeUHJycqy22bBhg9KgQQNFp9MpVatWNZ/DUkndl6eeekrx9fVVdDqdUrFiReWpp55STp06ZV6fkZGhvPrqq4qHh4fi6Oio9OzZU4mOji7V16QoirJq1SoFUCIiIqyWl6XvacOGDUX+zvXv319RFFO3lPfee0/x9vZW9Hq90rFjx0LXe+XKFaVv376Ks7Oz4urqqrzwwgtKSkqK1TYHDhxQWrdurej1eqVixYrKlClTCqVl4cKFSo0aNRSdTqfUrVtX+ffff63W30pabnZNkZGR1/07y+8Dv3fvXqV58+aKm5ubYm9vr9SuXVv56KOPrALevb6mm11Xenq60rlzZ6V8+fKKnZ2dEhgYqAwaNKjQA1tZ+q7y/fDDD4qDg4OSmJhYaP/S+l2VJJk9SwghhCjFHvg6aiGEEKI0k0AthBBClGISqIUQQohSTAK1EEIIUYpJoBZCCCFKMQnUQgghRCkmgdpCVlYWEyZMICsry9ZJKTH34zXB/Xldck1lx/14XffjNcH9cV3Sj9pCcnIybm5uJCUl3XTc37LifrwmuD+vS66p7Lgfr+t+vCa4P65LctRCCCFEKSaBWgghhCjFyvR81Lm5uezfvx9vb2/U6jt/5khJSQHg4sWLJCcn3/HxSoP78Zrg/rwuuaay4368rvvxmqD0XpfRaCQ2NpaGDRui1d44FJfpOurdu3fTrFkzWydDCCGEKJZdu3bRtGnTG25TpnPU3t7egOlC8+dbFUIIIUq76OhomjVrZo5jN1KmA3V+cbevry/+/v42To0QQghxe26l2lYakwkhhBClmARqIYQQohSTQC2EEEKUYmW6jloIIUqawWAgJyfH1skQZZydnR0ajaZEjiWBOs/VtGwOnE/EUaeheVUvWydHCHGPKYpCTEwMiYmJtk6KuE+4u7vj4+ODSqW6o+NIoM5z9FIyL8zeTS0fF1aObGvr5Agh7rH8IF2hQgUcHR3v+J+reHApikJ6ejpxcXEAd9x9WAJ1HnXe36Sx7I7/IoQoJoPBYA7SXl5SoibunIODAwBxcXFUqFDhjorBpTFZnvynZ6PEaSEeOPl10o6OjjZOibif5P8+3WmbBwnUeSRHLYSQ4m5Rkkrq90kCdR51XqSWOC2EEKI0kUCdR3LUQghhUrlyZb788stb3n7jxo2oVKq73mJ+9uzZuLu739VzlEYSqPMU1FFLoBZClA0qleqGrwkTJhTruLt372bw4MG3vH3Lli2Jjo7Gzc2tWOcTNyatvvOo8wO10cYJEUKIWxQdHW1+//vvvzNu3DgiIiLMy5ydnc3vFUXBYDDcdO5jgPLly99WOnQ6HT4+Pre1j7h1kqPOo1Hl11FLjloIUTb4+PiYX25ubqhUKvPn48eP4+LiwooVK2jcuDF6vZ4tW7Zw+vRpunfvjre3N87OzjRt2pS1a9daHffaom+VSsWMGTPo2bMnjo6OBAUF8ddff5nXX1v0nV9EvWrVKmrXro2zszNhYWFWDxa5ubkMHz4cd3d3vLy8GDNmDP3796dHjx63dQ+mT59OtWrV0Ol01KxZk99++828TlEUJkyYQEBAAHq9Hj8/P4YPH25e/9133xEUFIS9vT3e3t488cQTt3Xue0UCdR61MQsfruBuvGrrpAghSgFFUUjPzrXJqyQzDP/73/+YMmUKx44do379+qSmpvLII4+wbt069u/fT1hYGN26dSMqKuqGx5k4cSJ9+vTh4MGDPPLII/Tr14+rV6///zI9PZ1PP/2U3377jc2bNxMVFcXo0aPN6z/++GPmzp3LrFmz2Lp1K8nJySxbtuy2rm3p0qWMGDGCN954g8OHD/Pyyy/zwgsvsGHDBgD++OMPvvjiC3744QdOnjzJsmXLCA4OBmDPnj0MHz6cSZMmERERwcqVK2nbtnQOdiVF33mc4vaxw/41TudUAp60dXKEEDaWkWOgzrhVNjn30UldcNSVzL/nSZMm0alTJ/NnT09PQkJCzJ/ff/99li5dyl9//cWwYcOue5wBAwbQt29fAD766CO+/vprdu3aRVhYWJHb5+Tk8P3331OtWjUAhg0bxqRJk8zrv/nmG8aOHUvPnj0B+Pbbb1m+fPltXdunn37KgAEDePXVVwEYNWoUO3bs4NNPP+Xhhx8mKioKHx8fQkNDsbOzIyAggGbNmgEQFRWFk5MTjz32GC4uLgQGBtKwYcPbOv+9IjnqPKq8Zt8qpOhbCHH/aNKkidXn1NRURo8eTe3atXF3d8fZ2Zljx47dNEddv35983snJydcXV3NQ2QWxdHR0RykwTSMZv72SUlJxMbGmoMmgEajoXHjxrd1bceOHaNVq1ZWy1q1asWxY8cAePLJJ8nIyKBq1aoMGjSIpUuXkpubC0CnTp0IDAykatWqPPfcc8ydO5f09PTbOv+9IjnqPGqVaXg3FdKaTAgBDnYajk7qYrNzlxQnJyerz6NHj2bNmjV8+umnVK9eHQcHB5544gmys7NveBw7OzurzyqVCuMNWt8Wtf29bgNUqVIlIiIiWLt2LWvWrOHVV19l6tSpbNq0CRcXF/bt28fGjRtZvXo148aNY8KECezevbvUdQGTHHUeldp0K9SSoxZCYAosjjqtTV53c4S0rVu3MmDAAHr27ElwcDA+Pj6cPXv2rp2vKG5ubnh7e7N7927zMoPBwL59+27rOLVr12br1q1Wy7Zu3UqdOnXMnx0cHOjWrRtff/01GzduZPv27Rw6dAgArVZLaGgon3zyCQcPHuTs2bOsX7/+Dq7s7pAcdT5zoJYctRDi/hUUFMSSJUvo1q0bKpWK995774Y547vltddeY/LkyVSvXp1atWrxzTffkJCQcFsPKW+++SZ9+vShYcOGhIaG8vfff7NkyRJzK/bZs2djMBho3rw5jo6OzJkzBwcHBwIDA/nnn384c+YMbdu2xcPDg+XLl2M0GqlZs+bduuRik0CdR6U23QqVIoFaCHH/+vzzz3nxxRdp2bIl5cqVY8yYMSQnJ9/zdIwZM4aYmBief/55NBoNgwcPpkuXLrc1y1SPHj346quv+PTTTxkxYgRVqlRh1qxZtG/fHjDNBz1lyhRGjRqFwWAgODiYv//+Gy8vL9zd3VmyZAkTJkwgMzOToKAg5s+fT926de/SFRefSinDHYcvXLhApUqVOH/+PP7+/nd0rOij2/Bd2JVLSjn8Jp4uoRQKIcqCzMxMIiMjqVKlCvb29rZOzgPJaDRSu3Zt+vTpw/vvv2/r5JSIG/1e3U78khx1nvw6amn1LYQQd9+5c+dYvXo17dq1Iysri2+//ZbIyEieeeYZWyet1JHGZHlUUkcthBD3jFqtZvbs2TRt2pRWrVpx6NAh1q5dS+3atW2dtFJHctR5VHndsyRQCyHE3VepUqVCLbZF0SRHnUct3bOEEEKUQhKo86jUMuCJEEKI0kcCdZ78QC05aiGEEKWJ1FHnUVwr0itrArlo+FNR7urIQEIIIcStkkCdR61zZJ9SAwCjAhqJ00IIIUoBKfrOo1YXRGZj2R0DRgghxH1GAnUedXYKAzXLeVGzQgK1EOKB0r59e0aOHGn+XLlyZb788ssb7qNSqVi2bNkdn7ukjnMjEyZMoEGDBnf1HHeTBOo8muwU3rObwxjtfCROCyHKgm7duhEWFlbkuv/++w+VSsXBgwdv+7i7d+9m8ODBd5o8K9cLltHR0XTt2rVEz3W/sWmgnj59OvXr18fV1RVXV1datGjBihUrbJIWlc6JpYZW/G1sKTlqIUSZMHDgQNasWcOFCxcKrZs1axZNmjShfv36t33c8uXL4+joWBJJvCkfHx/0ev09OVdZZdNA7e/vz5QpU9i7dy979uyhQ4cOdO/enSNHjtzztKgcPXg9Zyijc4ZglDgthCgDHnvsMcqXL8/s2bOtlqemprJo0SIGDhzIlStX6Nu3LxUrVsTR0ZHg4GDmz59/w+NeW/R98uRJ2rZti729PXXq1GHNmjWF9hkzZgw1atTA0dGRqlWr8t5775GTkwOYppucOHEiBw4cQKVSoVKpzGm+tuj70KFDdOjQAQcHB7y8vBg8eDCpqanm9QMGDKBHjx58+umn+Pr64uXlxdChQ83nuhVGo5FJkybh7++PXq+nQYMGrFy50rw+OzubYcOG4evri729PYGBgUyePBkARVGYMGECAQEB6PV6/Pz8GD58+C2fuzhs2uq7W7duVp8//PBDpk+fzo4dO+75VGNqlTQmE0IUITvt9vfR6EGT9+/VkAuGLFCpwc7h5sfVOd3yabRaLc8//zyzZ8/mnXfeMXcrXbRoEQaDgb59+5Kamkrjxo0ZM2YMrq6u/Pvvvzz33HNUq1aNZs2a3fQcRqORXr164e3tzc6dO0lKSrKqz87n4uLC7Nmz8fPz49ChQwwaNAgXFxfeeustnnrqKQ4fPszKlSvNc0W7ubkVOkZaWhpdunShRYsW7N69m7i4OF566SWGDRtm9TCyYcMGfH192bBhA6dOneKpp56iQYMGDBo06Jbu21dffcVnn33GDz/8QMOGDfn55595/PHHOXLkCEFBQXz99df89ddfLFy4kICAAM6fP8/58+cB+OOPP/jiiy9YsGABdevWJSYmhgMHDtzSeYur1HTPMhgMLFq0iLS0NFq0aHHPz69GwY5c1BhRDBKohRB5PvK7/X2enA11e5reH/8bFg2AwNbwwr8F23wZDOlXCu87Iem2TvXiiy8ydepUNm3aZJ6HedasWfTu3Rs3Nzfc3NwYPXq0efvXXnuNVatWsXDhwlsK1GvXruX48eOsWrUKPz/Tvfjoo48K1Su/++675veVK1dm9OjRLFiwgLfeegsHBwecnZ3RarX4+Phc91zz5s0jMzOTX3/9FScn0wPLt99+S7du3fj444/x9vYGwMPDg2+//RaNRkOtWrV49NFHWbdu3S0H6k8//ZQxY8bw9NNPA/Dxxx+zYcMGvvzyS6ZNm0ZUVBRBQUG0bt0alUpFYGCged+oqCh8fHwIDQ3Fzs6OgICAW7qPd8LmjckOHTqEs7Mzer2eIUOGsHTpUurUqVPktllZWSQnJ5tfKSkpJZYOdVYyJ+2fJ8J+AAZjbokdVwgh7qZatWrRsmVLfv75ZwBOnTrFf//9x8CBAwFTJuj9998nODgYT09PnJ2dWbVqFVFRUbd0/GPHjlGpUiVzkAaKzEz9/vvvtGrVCh8fH5ydnXn33Xdv+RyW5woJCTEHaYBWrVphNBqJiIgwL6tbty4ajcb82dfXl7i4uFs6R3JyMpcuXaJVq1ZWy1u1asWxY8cAU/F6eHg4NWvWZPjw4axevdq83ZNPPklGRgZVq1Zl0KBBLF26lNzcuxszbJ6jrlmzJuHh4SQlJbF48WL69+/Ppk2bigzWkydPZuLEiXclHSrLftRGw105hxCiDHr70u3vo7FoHFWrm+kYqmvyRSMP3Vm6LAwcOJDXXnuNadOmMWvWLKpVq0a7du0AmDp1Kl999RVffvklwcHBODk5MXLkSLKzs0vs/Nu3b6dfv35MnDiRLl264ObmxoIFC/jss89K7ByW7OzsrD6rVCqMxpKbp6FRo0ZERkayYsUK1q5dS58+fQgNDWXx4sVUqlSJiIgI1q5dy5o1a3j11VfNJRrXpquk2DxHrdPpqF69Oo0bN2by5MmEhITw1VdfFbnt2LFjSUpKMr+OHj1aYunIH+sbJFALISzonG7/pbHIA2m0pmWW9dM3Om4x9OnTB7Vazbx58/j111958cUXzfXVW7dupXv37jz77LOEhIRQtWpVTpw4ccvHrl27NufPnyc6Otq8bMeOHVbbbNu2jcDAQN555x2aNGlCUFAQ586ds75cnQ6D4cb/W2vXrs2BAwdISyuov9+6dStqtZqaNWvecppvxNXVFT8/v0JTbG7dutUqg+jq6spTTz3FTz/9xO+//84ff/zB1atXAXBwcKBbt258/fXXbNy4ke3bt3PoUMk9eF3L5jnqaxmNRrKysopcp9frrZrxJycnl9yJLZ52lRJ8MhNCiLvN2dmZp556irFjx5KcnMyAAQPM64KCgli8eDHbtm3Dw8ODzz//nNjY2OtWMV4rNDSUGjVq0L9/f6ZOnUpycjLvvPOO1TZBQUFERUWxYMECmjZtyr///svSpUuttqlcuTKRkZGEh4fj7++Pi4tLoW5Z/fr1Y/z48fTv358JEyYQHx/Pa6+9xnPPPWeuny4Jb775JuPHj6datWo0aNCAWbNmER4ezty5cwH4/PPP8fX1pWHDhqjVahYtWoSPjw/u7u7Mnj0bg8FA8+bNcXR0ZM6cOTg4OFjVY5c0m+aox44dy+bNmzl79iyHDh1i7NixbNy4kX79+t37xEigFkKUYQMHDiQhIYEuXbpY1Se/++67NGrUiC5dutC+fXt8fHzo0aPHLR9XrVazdOlSMjIyaNasGS+99BIffvih1TaPP/44r7/+OsOGDaNBgwZs27aN9957z2qb3r17ExYWxsMPP0z58uWL7CLm6OjIqlWruHr1Kk2bNuWJJ56gY8eOfPvtt7d3M25i+PDhjBo1ijfeeIPg4GBWrlzJX3/9RVBQEGBqwf7JJ5/QpEkTmjZtytmzZ1m+fDlqtRp3d3d++uknWrVqRf369Vm7di1///03Xl5eJZpGSypFsV1fpIEDB7Ju3Tqio6Nxc3Ojfv36jBkzhk6dOt3S/hcuXKBSpUqcP38ef3//O0tMbhZ8UAGAS6+cwK8En96EEKVbZmYmkZGRVKlSBXt7e1snR9wnbvR7dTvxy6ZF3zNnzrTl6a2pLOqob1KPIoQQQtwrNm9MVmpYtsiUom8hhBClhATqfFYjk0mgFkIIUTpIoM6nUmHEFKwV6Z4lhBCilJBAbSE/UEs/aiGEEKWFBGoLSv7tkEAtxAOpJEe3EqKkfp9K3YAntmRAjR1glHkuhXig6HQ61Go1ly5donz58uh0OvPIXkLcLkVRyM7OJj4+HrVajU6nu6PjSaC28LZmFEkZObyp97B1UoQQ95BaraZKlSpER0dz6VIxxvYWogiOjo4EBASgVt9Z4bUEagtbNU2JNWYxSisDHgjxoNHpdAQEBJCbm3vTMamFuBmNRoNWqy2RkhkJ1BbUeTfUdmO1CSFsSaVSYWdnd9dmQRKiOCRQW+ho3EaaOg2yggE3WydHCCGEkEBt6c2c73HTpXIsrTcQYOvkCCGEEBKoLe3T1EednYqXRuqohRBClA4SqC1MtH+Ls2np/OFU0dZJEUIIIQAZ8MRKfmMy6UYthBCitJBAbSG/Fb0MeCKEEKK0kEBtYUbaaxzWv4jD5cO2TooQQggBSKC24qBk4qzKRDHm2jopQgghBCCB2opRZbodiiKjEgkhhCgdJFBbUMzzUUsdtRBCiNJBArWF/GkuJUcthBCitJBAbUEpaPZt24QIIYQQeSRQWzDnqI2SoxZCCFE6SKC2YDQHaslRCyGEKB0kUFtQzK2+JVALIYQoHSRQW8hv9Y0UfQshhCglJFBbKMhRS/csIYQQpYMEagsF/ahlZDIhhBClgwRqS3k5aqSOWgghRCkh81Fb+Mu1LzHRF+joWtPWSRFCCCEACdRWwh1bstkQz0MOfrZOihBCCAFI0bcVdX6jb2lLJoQQopSQHLWFqtknUNRR6DJ8AH9bJ0cIIYSQQG3pyYQZ1NbtZ/tlT6CxrZMjhBBCSKC2FGdXEUN6AllaF1snRQghhAAkUFuZV+F1VsXH8mH5erZOihBCCAEUszHZ+fPnuXDhgvnzrl27GDlyJD/++GOJJcwW1HnTXEpjMiGEEKVFsQL1M888w4YNGwCIiYmhU6dO7Nq1i3feeYdJkybd8nEmT55M06ZNcXFxoUKFCvTo0YOIiIjiJKlE5AdqGUJUCCFEaVGsQH348GGaNWsGwMKFC6lXrx7btm1j7ty5zJ49+5aPs2nTJoYOHcqOHTtYs2YNOTk5dO7cmbS0tOIk6471jfuczboRBFxaaZPzCyGEENcqVh11Tk4Oer0egLVr1/L4448DUKtWLaKjo2/5OCtXWgfE2bNnU6FCBfbu3Uvbtm2Lk7Q74mq4SoA6nvM5Kff83EIIIURRipWjrlu3Lt9//z3//fcfa9asISwsDIBLly7h5eVV7MQkJSUB4OnpWeT6rKwskpOTza+UlJINqIpKY/opY30LIYQoJYoVqD/++GN++OEH2rdvT9++fQkJCQHgr7/+MheJ3y6j0cjIkSNp1aoV9eoV3ep68uTJuLm5mV916tQp1rmuxzwftQRqIYQQpUSxir7bt2/P5cuXSU5OxsPDw7x88ODBODo6FishQ4cO5fDhw2zZsuW624wdO5ZRo0aZP1+8eLFkg7V5PmoJ1EIIIUqHYgXqjIwMFEUxB+lz586xdOlSateuTZcuXW77eMOGDeOff/5h8+bN+Ptff+hOvV5vrhsHSE5Ovv3E34hMcymEEKKUKVbRd/fu3fn1118BSExMpHnz5nz22Wf06NGD6dOn3/JxFEVh2LBhLF26lPXr11OlSpXiJKfEKPm3Q7pnCSGEKCWKFaj37dtHmzZtAFi8eDHe3t6cO3eOX3/9la+//vqWjzN06FDmzJnDvHnzcHFxISYmhpiYGDIyMoqTrDuXl6NWGQ22Ob8QQghxjWIF6vT0dFxcTONhr169ml69eqFWq3nooYc4d+7cLR9n+vTpJCUl0b59e3x9fc2v33//vTjJumOK1FELIYQoZYpVR129enWWLVtGz549WbVqFa+//joAcXFxuLq63vJxStsIYIrUUQshhChlipWjHjduHKNHj6Zy5co0a9aMFi1aAKbcdcOGDUs0gfeUSrpnCSGEKF2KlaN+4oknaN26NdHR0eY+1AAdO3akZ8+eJZa4e09y1EIIIUqXYk9z6ePjg4+Pj3kWLX9//2IPdlJaSNG3EEKI0qZYRd9Go5FJkybh5uZGYGAggYGBuLu78/7772M0lt0gd8KjLR/nPM0518a2TooQQggBFDNH/c477zBz5kymTJlCq1atANiyZQsTJkwgMzOTDz/8sEQTea+c9WjJjwYfXnauauukCCGEEEAxA/Uvv/zCjBkzzLNmAdSvX5+KFSvy6quvltlAnd+WzFjKWqMLIYR4cBWr6Pvq1avUqlWr0PJatWpx9erVO06Urbhlx1FPdQanrDhbJ0UIIYQAihmoQ0JC+Pbbbwst//bbb6lfv/4dJ8pWmsYs4B/9uzSNXWjrpAghhBBAMYu+P/nkEx599FHWrl1r7kO9fft2zp8/z/Lly0s0gfdSltaFS4onmWonWydFCCGEAIqZo27Xrh0nTpygZ8+eJCYmkpiYSK9evThy5Ai//fZbSafxntkd8BIts75lk09/WydFCCGEAO6gH7Wfn1+hRmMHDhxg5syZ/Pjjj3ecMFtQ57Umk8ZkQgghSoti5ajvV2pzq2/bpkMIIYTIJ4HaQr3YpSzVjaN17FxbJ0UIIYQAJFBbcc6Kp6H6FO7ZMbZOihBCCAHcZh11r169brg+MTHxTtJie3ljfasUg40TIoQQQpjcVqB2c3O76frnn3/+jhJkU+r8STmkkloIIUTpcFuBetasWXcrHaWDOUdddicWEUIIcX+ROmpLKk3eGwnUQgghSgcJ1Jby+lFLjloIIURpIYHaUl6OWgK1EEKI0kICtSVV/u2wDtQZ2QambTjF2ctp9z5Nd0lKZg6Tlx/j8MUkWydFCCHEDUigtqDWmHLUOTm5VstHLzrA1FURDPp1DwfOJwJw+GIS56+mF3mcS4kZZObcfhevlYdjGDpvH8mZOTfc7lRcKgNn72Z/VMJtnyPfp6si+GHzGR77ZkuxjyGEEOLuk0BtoUo5FwAS0rLMuWeDUeHfQ9EAnIxLpfu0rbz/z1Ee+2YLbT7ZUOgYu89epc0nG3hj0YHbPv+QOXv592A0X609WWhdRrbBHMDH/XmYdcfj6PndNrafvoJSjO5ku88WP8gLIYS4dyRQW/B0sQdAjZFJ/xwlK9fA7rNXC203c0uk+X1aVkHue92xWJ78frspuB+MxpA3aPh/J+N5+sftjF1yiL8OXCIxPRuAhLRsrqaZ3idlFOSi84ujs3INrDgUTXJmDn1+2M5DH61j4OzdbDt9xbxt35928N3G07d9rQYZ0FwIIcqEYs+edV9yLAfAQ+qjjD4eRfCEy2Tn3rhh2aXEDIK8XcjMMfDKnH1W677fdJoLCenM33UegB1nrjJ/VxRPNPbno57BhH21mcwcI38Na8Wx6GTzfrvOXqXd1A2cu1K4aH3d8bhCy6auiqB3I3983Oxv+VJzjAXXpSgKqrwW70IIIUoXCdSWaj0KdXsS7tYT/Q4H0tMLcrlf233DHmMNfjV0sdql0xebGfdYHdoElSPbYB3Up66KKPI0y/ZfpEeDisQmZwHQbupGq/WKQpFB+kaOxyTj7arnQkIG/h4OpsCbkYDxx47s0TXFodsnBPsXjCxnmaNOycrF1d7uts4nhBDi3pBAbUljB0/OpgOwL9TIimkjOR6TxreGHuw11mCS3S+EqE+zz1iDSMWHbcZ6AEz65wh1PAFU1PF1pVV1L376z1Q83q95AJ3r+tA2qBz/nYjn+Vm7yTUqPDtzZ4kk2dNJx9W0bCIvp3ExMYN3lh6mdyN/sg1G6p37jZczT9OM01T7rjunP3qE6KQMUjNzSbR4CLmckoWrvR25BiNTVhynZXUvOtTyLpH0CSGEuDMSqK9DpVbT2jOJR64sI92+PPrMDAB6a7bQW7MFo6LikezJeKqSGa1dSKP0U2y2C+Zv94k8+1Agx2NSeO6hQDrX9YG0KzCnN21Pr+OrqqMYcaZJkedcPKQFarWKXt9ts1q+591Qlh+8xLi/jqIll1bqI3xr9zU5nafwY/JDfL/pNJGX09h0Ih6AP/ZdAKCyJgnyMspPqtbBtxN4MXogxwz+Vsc/n5CBTqtmY0Q8M7ZEMmNLJGenPFqSt7PEJWfmsGz/RbrW86W8i97WyRFCiLtGAvUNuHpVJPNyTV7o9jxhv5xnW1ZdntGs40ntZtQqhZX6/1lt31ZzCIeM3wk0VOQ3w/9gtxPU/hPObobT6wDofulzLjeYwfvhDgC83bUWOyMTeLKagSYB7gC806UaH64yNRBrpDpBuV8/4Nn4EwTrKlNDdR4nlanInDUjCArbDcD5gxupnRFPHPXJwFRX7aLKMKdtit0MuAzjNbN42vCeVbqH/7yeUG04nvYqoJX1TZj3FKTFwwsrQFt6AuLbSw7xz8Fo5u2MYuXItrZOjhBC3DXS6vtGOn+A/fCdVKxah9kvNsUusDm1hsxhlNd0cpWCW2fQ2PNZzhNEK57UTVgHLj7gWRXO/gd7Z0GdHvDkL+btBx5/iV1OoziiH8gLx15iZvWthK3rAusmwN5ZDNrTjX/7VkBPNkv0EyDuKGoll4bqUwVBGqB6KJXdTc9aTbN28r3uS9702Q9AbdU5Bmv/BWBCzvP0ypoAwEPqY9RVnaWSKpbhmiVM0s7iY7uf+Ez7Hf1zfkeFkU7qPVyaN5R5M78g4+oFuLgXLu2/m3f6tq0+EgvA8ZgUG6dECCHuLslR34i6IBg3DvRk4ZAWAHw2rC/xB8txeun7JPp3IPSF8Xzzzgp+NDzGVz1CCHNwh4ffhsAWpiCtUkHdHuCyGhb1h5QYKhhiQQXE7De9AC7ugxpdIS2OunveYWenrvAfENgaY+3HUa98y5yew8bK1Hv2DwJTs4BjHDMGEKe408Q+mnkvNaf8v99DXlfpi0o59ilBnDL6UV19iX/1bxd5uWsMjRmpXcII7RI4Ac9YrIsI38ILc9MYGVqdPg19bJ67lkbqQogHhQTqYlCpVFQI6YxXcCc0alPEmNwrmH3nEgitX9m0kVc108tSQHN44zikxMK/o+D4PwXr9G7w3FLISACPypCRgHvbV6BWW/Cpj1pjh6J3Zkl4NPtOXWSrsS4bgXLOeip7OfL3lZb8ndWSH9s0pnP1ctAkFNZsBiBG8QRUvJTzBgt171NBlQhAktqN5FwdldTxLKo+hc8Ol+Ow/UtFXvPBXZu4lFub6D/Hw/K/4KW1ULFRSd3S26aWSC2EeEBIoL4D+UEaoG+zAPo2C7i1HV284em5pvfJl+DoX1Ctg6nVuXMFGLob1BrTq2Jj826qhv0IrZXD5j8PM7FRQYOwppU9OZvXnau2r6tpoV9BEP1b/y4AlTPnMTmnL1/opgOQ0e0HnKu2guxo/BI9aXf060JJ/SCnH+/azaWbZjuf5D7NCO1SUIDki1CxEdm5RtYdi6V5VS88nXSFr3Xnj7BjGjy3DDyr3Nr9uQVqidNCiAeEBGpbc/WDh4ZYL9MWEfDyuDnY8dXTDa2W1fVzZdFe03t/D1MjNQIegiptIfYIpF9hlbEZAMuNzXnOuAa1oychIV1QqdWAKy28FNz8TsFlU7E6wLicAZxVfBihXYKLKoOl+nEFJw0wVQNM23CKr9adpLavKytGtCmc4J3TIeGsqZ67JAO1RGohxANCAvV94KmmAeyMvEqTyp4FI4xp7KD/36b38RF0cQ+A99aThY51rebyZpdaVsdQH/+LepeXA/Bd7uMsNz4EwPH3w4g56oey5Cn8VZdNG7tVAifTKG5/HbgEYDWymhWdk+mng3vJXGwejQRqIcQDwqatvjdv3ky3bt3w8/NDpVKxbNkyWyanzHLQaZj+bGMGtr5OjrV8TbBz4InG/tjbqXm6aRFF9G4FRel7jDUB8HLSYW+noXJIOwzt3ynYNuk8ueunQPrVmxdBZ+W1yta73sYV3ZzUUQshHhQ2DdRpaWmEhIQwbdo0WybjgTH1ifrsf68zlTwdC6/0CYHqnbhU5Qni8ABMDdXyqZsPZlFuQX9l7ebJcPY/NGoVvlzhf9p5kFp4HHISzpp+nlhVkpciddRCiAeGTYu+u3btSteuXW2ZhAeKSqXCQacpeqVGC88uxik9Byatztu+YLWLvY63DC/zZW5vemv+o77TFdo7efN01lxetP/VtNF6T3j8m6KPf/gP6Phe0euKeS1CCPEgkDpqYcXNsWByjrNX0szv1WoVLno7LmaW52tDLzxy7Xh+zmJez/m1YOfYIwXv0y7DukkFn+t0L9F0So5aCPGgKFOBOisri6ysgpG5UlJkVKq7oWGAO/ujEulY23piDp22oKYkIT0HJ+0l698gO4si9X9GwrG/Cz53tGgxXgKkjloI8aAoU0OITp48GTc3N/OrTp06tk7SfenH55rwVlhNJnSra7U8Lctg9fmj3H48kvURaw2m7mJK8qWClSfXFry3czL1CS9BEqiFEA+KMhWox44dS1JSkvl19OhRWyfpvlTeRc+r7asXmpUqI8dQaNujSmXez33O9CH5kmkybYDcgglBsHMwNTQz5BTav7jUZeo3Vwghiq9M/bvT6/W4urqaXy4uLrZO0gPLsh+zaYhSUOVmQGZi4Y3TL8OnQRAfUWLnlxy1EOJBYdNAnZqaSnh4OOHh4QBERkYSHh5OVFSULZMlbsHmtx42d9/KQkeC4mxakRwNJ1YXvVNqTImdX2MRqHMNxhI7rhBClDY2DdR79uyhYcOGNGxoquMcNWoUDRs2ZNy4km14JErGW2GmgVDefqQWFd0dcNYX1DvHK25kO3rDxT0w78miD2BZh32HLDPU2RKohRD3MZu2+m7fvj1Kfp2mKPVeaVeNbvX9zOOJO+kLfn1OKJVw9g/CT3OD6S+TLpZYWiyLvrNzjThef3h0IYQo08pUHbWwLZVKRSVPR/NgI5aBekJOf2K8mhcUbwe2Bs+qpvd2eeN9J5dcoLZ8vMvOlRy1EOL+JYFaFJuLRaC+jBuZObmwJq/aomp78Mybj9u3vuln8iVyDEY2RsSRmpV7R+e2rJfOkkAthLiPlakBT0TpYn/NcKSLDlymJUD52tDuTUiNBzt7OL8L5vSC5Et8u940LWaHWhX4eUDTYp87x1CQp5Y6aiHE/Uxy1KLYNNd0kVqbUpmfa3zHCPsPCP18E4sjskDvUjAzV/IlZvx3BoD1x4uYwONWJV1Ea0g3f8zKkUAthLh/SaAWxXbtnNApODLpoDt/nsziVFwqX6w5YVrhWtH0MysJdc4dDvuacBa+qMO8nNfNiyRHLYS4n0mgFsVmGajnDWpOlXJOVusvJmYQl5wJemdw9AKgEjfOSa87FsvIBftJzix6FLOc8/sAqGhxHGlMJoS4n0mgFsVmWfTdslq5QoEaYF9UgulNXgvwh9TH+MnuUw7qX8KwZiJs+bJg2FHgq3UnWRZ+iYPbV5vqtq+xNyoJgD3GGuZlEqiFEPczCdSi2NTXFH37uNkX2mbvufxAbWoBPs7uNzpp9uGqSkez9XNYOx7ObgFAURSi46/gSCatNz0DMztBdprV8bLTrgKQpBQ8FGQbCo9BLoQQ9wsJ1KLYNNf89vhZBOr84UVPx+cF2vw+1UWJ3ARAwqkdrONl+mrWF6y7ctpqU22WKUfdUn0EPdmA5KhvRFEU3ll6iI9XHrd1UoQQxSSBWhRbg0oeVp993BzM7xsFuANwKTFvFq2Qp4l9ajldsyYXPtAZU6DO2f0rrqoM3rObU7Du8gmrTe2ykwFwUGXjhen9Pe1HXcZG0ou6ms7cnVFM33iaHGl0J0SZJP2oRbH1aliRjOxcGgeaZs/ytchRNwzwYPXRWC7mB2qPQC6muHJMSaRd1uc8p1nDX4aW/KV/Dy7uhdR4Nld5nQtHstCoDAzXLjPtd/mk1TntcpLM71V545NdN1Cnxplm7QIYcQA8Khf/YtOuwIyOkHYZ/neuxOfXvlssSxvSsw24OcizuRBljfzVimJTq1U816IydfxcAes66gaV3AFIycw1t+C+mGAK2ucUHz7IfY6DSjXCjdVAMcDMTpy9nMZXht74kFBwkivWgVqbbQrUE3Oe4yLlGaBZSbutz0NKETNzXdhT8D79yp1d7PkdkBAJ2SmmB4AywnJgmIxsqcsXoiySQC1KjGWO2t/DAXdHO6Cg+PtodHKhfeYbOpjeJERy7koqAJXVFkE37pjp57Zv4ZdueKSfA0yNycqTwAS7X/FO2Ff0zFxaiwlC0q9eN92rjsTQ87utnL2cdt1tiDlk+unsA38OhTgb1PlmJBTZEv6Gu+QUDNWann1nw7aWdTkGIwv3nOf81fSbbyxEKSKBWpQYR52W10Nr8FLrKlTydKSiu6nOetaWsxiNCocvJhXa5w9DG2blduHKw59w/KqpmFaPRR/quKNwap0p1x25mYpZpwBIwolknPggpx/7XTuAX8PCCareEaq0M72/QaB++be97I9K5KVf91x3GzISTT9TY+D0Olj43PW3vVvmPmlqCR+xAoA9Z6/Sasp6Vh6+/jzfaVkFuej0UpKjzsg22KS+fNbWSN5afJCuX/13z88tbl9mTun4fS0NJFCLEjUiNIh3H6sDQAUXU4729z3n+fdQdJGBOhctE3P7E1WlD+eumHK0H+X0Y7JuKLQbAx3ehcBW4BUEfo3M+83UfUYX9R5mGB5lYNqrzN52lkV7znP4YhI9v9vKjjN5Rd2OpvpzMq4fqPOdikvNS1QWbJ9m3eI885q0Xz5BrsGI0XjzxmWztkby8KcbzddXHJtPxMOF3aYPu2cAMGDWbi4mZjBkzt7r7mcZnEtDoE5Iy6bZR2t5dsbOYh/jZGyK6X7cpk15+9zphDDi7tty8jL1xq9i1tbIm24bl5JJj2lbmb8r6q6lJzkzh993R5GUXvRATHebBGpx19T3dze//3rdSRLSc9Be0/c639HoZHN96k6lNgty2sPDb0PbN00Te9R6BAZvIEnlYt7HXZWCi72Wq2lZzPhnIz/+sZz+P+9if1QiT/+4w7SRQ16gvkGOuqVHEi6k00J9hKu7F5oGYVn1tmkmMEMuZCZDZmKh/Z7/bg0Pf7aRrNxrAqBFy3BFUZj491EiL6fx2/Zz101DkYxGWP0e7J/L8z9bBLa83P2tBJxbKvo+uwW+CIbT64teX4KW7r9ISmYuOyOtv48P/jnKuD8P39IxOn2xmed/3sXxmMJVKTeioujfvdIsM8fA1bRsWyfjnntt/j5yjaa/nZv5cdMZws8nMnbJobuWnjcXHWDMH4cYvmD/XTvHjUigFnfN0Ier8/YjtQA4mZdb7dGwotU2zaqYAml4VCIAnk46AJIycpi+0boPNUYjzkpBrrSnZis9K8TyrGYtW/QjeUc7F33aJV7V/Ikfl2Fhf9gz07Rx8iU4vQHC5xVK5/tZH3PI/iWm2X2F68rXYNvXphUxh2DxC6Zj5Bd9W9BF7+HclXTWH4srCIL/vA5f1odY0z+YKIv6UAfdbbYUjzlgSsufr1JZZVG8rbr1gJNf9O1MOlV2joeoHYU3+v05SIoq8t7csuw0WDsR4k/ccLP83wPAXBqRnp3LjC2R/Lr93E3rjxWLh6Dj0bc3brzlbftk5fHbzh39sfdC4d/Ju2zgL7tp+8mGWyqNycg2cCL2DsfSLyUyb2OinVyj9YPx3bDqSCxQUCpzr0mgFneNTqtmYOuq5uDbtZ4Pk3sFW23j7mBqcLb/fCIAIf5u5nUfrzxOfEpWwcaKgenGnuaPDdWnmBT3GieNptm52msOsE4/mrfsfmeT/nU4uqxg3/A58FsP+HsEGPL+QSsKnN1CNeNZAFIUR7SGTMjOCyaJ5+DYX7DvN4jPa9Tm3wwCWwPwtGYDANPnLcI4OdCUE9/zMyRFocwKg9wstp4yFcG7k4Lf5W2mPuPZN/mnu38uzHoUHDygeijUewJvEgvWv7T2urumZOYUdMnKyTC39H5Du4jAM/NgXp+CjbPTICsVNKbvgMYDbpyuIoz78zDD5u1DWTsBtnwOP7a74fanLQJ1Ro4BrpwmZ+fPqDCl+cpNco+W/8Bv43klb/uCHb7beJoPl988t5bPaFR4Y9EBPl55nNPxqTffoQTkGIxsPXWF1Kxcvl1/6qbb9/1pB52/2MzWU5fvQerurkKlVDeQ32gV4HLq/Vn6IP2oxV2lUav49pmGHL2UTP+WlbHTqPFy0nElLZumlT1wywvU+fXDdf3c2BBR8NQ6dN4+0rJy+V/XWjSt7Mmn2b1Bm8sw7Z8AZGjd2JsZRLTiia/qKg4q0x+qneo6f+g1u/L5P3uITNXQXbOd0OPjzKuUoopGK7cxtR6PyQuuj3wCdo4wrRlhmt2MMP5BbXUUzkoqRCw376bKTIJz21hx2BFPkhmh/YO+J9bACaBiExi07vo37c9XTT9/bA+vHwWdI9p9UwA4qfgTVNQ+53dzOfosDy935THvBCbbzQRjDulVfwLAiUzTdk0Gmn5mp8E3TTCmxqNWckCjg4qNr58mC1m5BjZFxFO3ohu/5hXnTw3ciwOQVSWUDYej6VLXxyowgim3E2GR4xs6bx8zo5/ALTuJgZp+zDA8SvyVq5zZO433z9Vl9JMPU9fPzeoYSRkFuWDDLbQPsHTtt7s/rxTnVlxNLwgAaRZVDisORbPl1GUmPF4Xu2uH6rtDlqUL205fQVGUQvfUUnjew+6C3edpVb1ciablXrudr9by4e3clTTKu+hvsHXZJDlqcde1rFaOl9pUNf8jWzD4Ifo1D+Drvg3NgTpfDR8XHOwKioh3RV7lyKVkZvwXaZ7DOk0pGAEt09GPXLSMyxkAQLzixqNZH7Iwt4icXa8ZHG71DX9sj+CtiGesgjRAZbWpeMugqDht9DUtDHkaHn7H1Nob2HIhlwTHKixShwHwut0faDByzlgBJTXW+ny/9eC5s2PZZz+E/to1Bcsv7oEzG+HPYaZ6cEu5FjmCjARQTP+EvPP6lscq7oUuy0OdBjNDKbf8JeYZ36LchTUoF/fCpf3ok03zfwepL5o29qln+nkpHFIumYI0YPRtYBrMJSej8H27xrQNpxn8215e/z28INmZpgetSeeDGTJnHwv3nOexb/5jlMU26dkGq0C7MSIeTV6/+C4aU0O5cod+omr4J3xy9TV+n/sTbP0KDLmcvZzG8z/vYs3RGOqqzvKkZiOq+AirdIWfT2T1keu3gDdeUyx6Mi6Vl37ZQ24RLdCvLUKNSy4o2bFslPfq3D0s2BnJoj0Xrnve4oq06C54MTGDCwk3/24AcvJKVO5WMXBxpGblMn3j6TtqUHk9KRYz7Z29cn92vZNALe65IG8XPuwZjK+bQ6FAXdPbhcWvtKCOr6vV8n1RCfyy7SwAqRT01zbmzXW9xtiEJ7LG0TN7EkeUKryV+zIJvX6Hh98FtR14VuW8Xxiv/x5OgDqOSuqi65rm5XZgWM5wthjroTj7sOBKVb6ds9C8fuiSM/SbsZM3059joyEEgG3GOrTP/hxDlukf6R+GNubtLyuuPJ89pvCJDi6C/b/B0T/zLsQIhxbDqYKAPtN3PNO3x5KRkckTms2m+6M6D7/1wrDyHT6zm84x/QD26waZ9wlWn+UNu8VcdG9iutdxq1FjJFhlCth451U9xBy0So76wi74sp71IDFGo6muPSkvCKVfhY0fE7L3bcD0EAVgRy6Oyaa62w0J3kzR/sjMv9Zz/OJVfA5OIydyO1CQG35Ns4S1utG8qllmPpVD3rjtgRf/BqC8KplJae+bHmT+Hs7UFUfYfCKe9/48wqvaZUy1+5Ge23uZ+tcDa47G0mPaVgb/tpfDF5OKzG2nFdH4bu2xWLadth4M5+Xf9hD25X9kXTlH6vRQMg8sIT61IFAnWzxsfG43nf36l0mMOVPo2DeSnp170+5Hkdf064+IKSiNmLPjHGMWHyzyOrMNRo7HJFN/wmq+XHvjNgN3XU4m/BzGyR+e5eOVx3nsmy033eXasftvNpZ/SmbB93o3HgRKAwnUwqYs65fsNCqqlHOirp8bA1tXsdouv6WwnUZFrtbZvFztX1Bcu0epxQWlvPnzBc8W0O5NGL6fjBc2MHXNKU7GpdJZXRCMchXTn8DHOU/ztvf3vJ37EiuMzZlheIT0Ll8wYVMSB5MKHgxScMwbuEXF+7nP0jrrS2YZujJKuxhtuilH/UFOPxLtK3JF58dnuX3Avzn1M3/ihLpawQWF541n3mmSqdX1vD7wx0BY8IxptaoW70fW5OOVxzmzbTEtNab6VAUVnF6Hat9sqqiizUX91/JPMLUS7xgzg336l9Gq8v7ZLRnEvk1/sX/nBvO2SwytOejYHOycTOmY2QUSo0xDpk5vAV/URYlYwZfrT8PGj+iYuYb6qtPmeuUg1QU0Si45WhdScaC35j8+VE3jRc0K3rJbiN0vYaAopMWfo5HqBDXVF6iuvsRbdgUPQAGqWFQYWen+TOGLCZ/LiDOD+czuO97V/sajGotBX1a/A+lX+WFTQSOvYd8u4o1fCrdgT8nMpTyJNFRZj3aXnHjFXJKRkpnDqiOxRMSmcGLJhzjH7sZ+6Qvsy58FDkjODwyZSfTUbMVVlU6zC78U7sJ3YhUcXmJ6f34XzH4MJeYQCWnZtPl4A8/8tOOGud4z1wTqUb9u4uMVpt+Dd5cd5vc951lzNJakjBy+t7j+7Fwjr87ZR0pWLl+utb7W25aRAP+MgvO7C63advoyHT7bWGQ//gsJ6fyy7SxXD6+GqO00vLqCciRZBdXrsXwoAuvqjqJY5qjXHI0t0ZIEo1Hhs9URN9/wLpM6amFTrhY56irlnNBpTYGzRTUv9Fo1FT0cqOCiZ8cZU+7t7Udqs3F3NuFXq7HTWIsB7UfCxg1FHZq4lEzAjfknFMb9uc3c/esjpT+TMp/Lq5NWUY4kUu3c+bRVA+adM3W/OK94s9++GZk5O/mPYC4pnlxQymO0eLY9rRS0YG+mNo1UFmH0JwFXPq+5gIjYVK4kJ1C7ih+bozLpyxT2PnwANnwAwF5jEKkpfrRb1MU0oIuFwzkFx/7iQi3q5/ZgoGYFH+Y8w4TOlUjwDKHXvEQaqU4QqIolWB3Ji9qV1jdAbQfGHNxVFv/wo8NZErWed7QbQAUvZo9mvbERbTVp/Nq3CswMNQ2X+ks3SDhr3k01/2m+zJyLo/ZR2qgP8pf+PY4ZA9hrDOJZram+/YxDXVzT0khHT5RSgf7a1QXnXTMO/8N/s0QfyazcLoW+q+E5w1ABv2a25p3MYBboPqC5+jiE9EU5uJAaSiQ1NJHEKB6F9iV8Lr/FfoCDfSanjH4EqGI5HelHbm44Wm3Bvzj/9GOssR9DvOJK06zpgIoqqmgeXv4iF3Y2xn3wX1at0n/I7sq3/A5Azsap9FR78YhmJ/77qkHjGWTFnyG/NrRJ/BKYsgSeXWJq12DILmi45xsCsx4BYw4nvn+Wf1ou5EpaNlfSsjlzOY1q5Z0xGhUycw1M/OsotXxdeKFVFXPuMKi8E3WvrOITux9YsrUN22rMNKcxNjmTsUsOsvxQQbDMyjVYB/nNn8LBhdBzOsaYw6iCOqFy9St8H4uyYbKp18OemdD5QzixEvr8Co6ezN12mkpXtvHanCRWjw41z0evKApD5uzl8MVkknV/8lren0xT9XFWGJtbHz/timlcgOAnwMv0IBuXnGm1SVJG9g3rnS2D//GYFDafiGPd8Xic9FrGhNW6teu8jj8PXOSbW2jId7dJjlrYlGXRd+vqBblhP3cH1o5qxx9DWjKgZWWqV3Dmw571GNCyMsm68vTIfp/Juf3Q2zvioi/6eTM2OYuzl9MYu+SQ1ZjX/ZpXRkFNfvOiy7jhrLejS10fejUqCJDPzjTlSn3Le/G692yezn7P6vhNAguCxuicl/ktN5Tns/9nOmZ6Dmfy6ssaB5i2S8zMRan2sHmfLcZgvj9gwNClYEaxq2pPDKhZY2xiXrb2WCyf5/YhOGsmfxpbE1m1L5ccagKwT6nBUmMbPsp9hr3GIA6pguib/Q5Ds4eTFjKAbOxYY2hE66yvmBbwBTlP/MJGYwiXFTfSFD37jdUB2JPkiqK2uI/5QbrXDPOiTuq9fJTbj0eyJ7PG0Jja6ihzkAZY6tCTC0oFmmdN442cV+mdNaHgeNu+xiHZNHjFC9pVHDUGmlfNzu3MRmNDjKg5HpOCgpoB2W8x0P4LksK+4RdVdwCSFQdez3mVebkdrL4H1k7EIa+xXHX1JXQqA7XV54k/uNpqs/BsP7IVDeVVyZy178eTmo18a/c1TmTif2Ur0xf8ycm8xm4aDKy8qOOqYiq9ectuIV/optNJs4/aFxeBIZck99o8lWX9O8GcXvDHiwUNAsE0eI7RlOuryVk0m6cQoIplm34Yqf+a2ihs/LI/5z5owIY9B5n491EUReFySjbvan9jTUp3vtR9h05l4GntRhbtKMg9Z+QYWH4oBj3ZDNL8gx257D6bYJUk1r8PlyPgpw6o/x7OF199St1xK/nrQOFhdxfvvUC7qRs4HpNMdq6RqEObC1aufgfO/gf/fQZA77hv+UX3McO1S5iy4ph5sw0RcRy+mMwY7XxeUy82L2+uLtgGMA0sNL0lbPwI1n9gXhyXcpMc9eE/YGoQnDNVqeQHaj83e8Zq59J4fkP27tjE9I2nzbnti4kZfLfxFIv2nDe1w1j/oamdRr5z202TAx3902regGO32QXwbpEctbApF/uCX8GnmlayWlfJ0xGAsHq+hNXzNS+/tnXtprceJjkjh9DPN1n1qTyfkM7Bi4V/xR+q6snsvPrufI46LXYaNZ/3acCpuFQOXigoxgyq4IyrvR07o6y75YTW8aZP00p8uiqC8ynevJf7onnd2cvp5q5ljfICusGokOwVgtuQrYycv4dlseVQR17hFfvGbMqcjRE1OWjQkUs2dtTycSEuJcs84EV+bj4+JavQP69ctPTOnkjLal4ci04mMT2Hf7cDtCf/gWTWJR1T52QDFXg0+0OcyCIBU1uA9GwD1adF8xiv8pXuO9NB/RpB8BOciU/h2I5/2ZFpGnFOQc1Huc/QSn0YR5XpGhcb2rEytQaQQWZePjMGL57MGsci/SSrtM7I7Uqk4suH6p8xoGatsTFqjEzWziBS8eF7QzcysGdnhjNrjsYyOf1xUnQa/Bo/yvbtOo4aA3lGa1G0bcxhrrEz/dTWgfni2u9wqBXKwj3nCTj0DbVzfYmz88AfU/elqXY/Wm0fEx8HF2P43u4LKqtieDz7AzLQA9bf+95y3Wn812sY/DpyUKlChqKzroJw9IK9sws+75lptf9I7RIaqk7hTQIx0QdRpreiQ/JhUMN4u18YmjOSlG0z6Z6yBy2F67EdoncBpvnd0/Pq3V/X/sEQ7d80Ux9nUM5o87bVVBfN7+OdahCbks25bD0PsYvqf42HinOgnKkfgaIorP3jJxbazebrheN45JHuOKblEJD/5xb2MaTFQ1Bn2PYtHVL+AuA17TIqH+nDqbgUqldwYc3ROFQYeUX7t1W6zyo+gIJyfjcqxQg/dzavyzn6D8mpWXg560m4pote4rX93XfNgLQ4mP8U/C/KHIzr+LnycuS/APyrf5vKmfNISMvBWa/l5d/2cPiiaYCcjmfX4nn4Zzi3DV74F5KjYVaY+fBK9U6onjU9YOQ/BFRRRTNGu4BPc58s9H3cCxKohU3V9XOjjq8rNX1cqOnjcvMdAN01gdrTSYenkw4Xey0JFn/U1xucwnLe7HyOFoOReDjqrNaVc9ajKWJEtZbVvKjv786SfRcK5QLyJyAp76KnnLMeBzsNGTkGluy7wAut6rE5NRrIxqjA6qOxQME5szGVMtSr6EaLql68seiA1bFjkjI5eqnoUbk8nXQEejmRmJ6Yt6Qg3ZZ9TJNxJhln1Cpwd9RxNS0bg1FhK8FkKDoUlYqDDSdTOzOXDmu8gRetznNe5cfgnFE8F3CZEVFtyTRq4KqpMV3HWhVYl9dCf7dSi4GBq5l5zvRP+cvcXnyZ+wSgcNxYieq1QthyLJMu6l08pd0IwK+GzqRjT2pWLv8evEQWOnJav0mjRv6wfSNJOPNy9kgUVLRQH6W/51F+j2/DObUXb9vNN6exSfp/HP2sDbszHmGwbhad7VTsVmrir7LuZxxurEbP7InoDVo6xV3mWfVpfFVXeUy9ne9yu/Oh3c/8YWhNb42pIVSKYg8H5uF1aiOZfMIz2e/wgnYlj2tMOTzavkVcShYXc5xpGGnqHqc4+/B2wqMM0fzNwJzRdFTvp6b6PI2ydoNFZ4FHNbtopn4F1zVJvAp8RU+yvRugiw03b/Nayuc0tqvDEkMbriR5A3BG8SFa8WShoT0A9f1caJy0ivEGU2M7ytdiWsWfmL3jPABn7Z8BA/BtEy7Y16BCdhSptfoQr1ThhNGfJ69+z5mkzrRQWYwg510XqrSBXx6HyE3mxemK6cHsVFwqKpWKo5eSqKwquKhD7h35wuUN1p9MYLz2V5i5Gho9b/UdqI05bFixkCfSF+JhHwZUNq9LTMsy5YLtHCD6IHT5gKTIfRx2eoiWimIOpvXdrf8GX9CsIPlKTS7s/JM+sds5zAu0VB82BWmAhv0gJZbcmWFWgVB1ao1pfAG9s7kB4jzdh/iqrlJNdYkcw6AS74p3MxKohU3Z22lYPqLNzTe0oNUU3ZfU+ZpAfT21fFzwdtXjrNdyOt5Ul2fZstTDooGbVq1icNuqRF5OM/cZBmhexdM8ROqLraqY69Cv9VBVL8A0BWjk5TQm/n2UppU9Cw0LWcfXtdDsYjqtml6NKnIpMYNv1p9Co1aRkWPgYmIGu84WfT4vJ12RY6pfj5ezHiedxpyey7jl5SR1XPjjCr0ijxS5X2htb1YeCaZPi4aUSzpu7jqkVsHrnWqYAzXAgYspLGk4m6u7f+eH3MfylqrYq9SknX8AHDvBWmNj5uR25KTiT7pFq/78PvWhdbzNk7wArDI2A2CHsTYNH/uYgz8f5bSxImPLhxOdriI2JZuG6lOk5iicUioyK7cLrqo0Ps7py1DtMuYbOpKNljNKQV1tZo6R5WdVnFLeREcOB5TquOrVbM4K5rxSgVNGf7xUSex2HUgr5xhW5TRAuaJmvxJEeE41Dhqr0uPxXtRzq0izg91QYWRdiIqqbpDScDDzvzrBfENHAHLda6Cp3p8e+wdSI6/rXJLiiJsqnfIq0/e31tCQL3N7M+Qxfzi3ifikNMrv/gRf1VV6a7bQW7OFDRFbmMfLLDQ8zDJDa7LR0lZ9gKlp8/E2WIx97R7A5XRT0PHE+vfMP9PUMtz96FySmUxTdQQ/5T7K+WOR9LII1F/8Mp9Og+pTr9HzVoFar8pBTzZO/wxhXkpFDhgepZvaVM2x31idr9z+h1EBNQquee0lsisEo3toKEYXX5LWfIKHKpknjgwDINAdntEEMc/QkQaqU3RaNwZlbTIbyj9Lh/PTSCnfmEYX38BgjGK2ozepeaMCNtSeNafpq9ye9NFsosbvC9EYsnheCw+rwwt6e+jdoE4POPwH2qSC/fJln9zAtAgXLh7cB9TAN+8+BKkvkmSDed0lUIsy58nGldgYEV+oC9e1OW1L7o52JKbn0KtRReztNGwc/TAatYoa75pmokq2aDlqWZ99dFIYOq2aQC8nfnq+CRXdHTgRm0JYPR/zNp3qePP3sNacjEth+sbT5gZJIZXc+ainqd/yRz2D6fuTafjOj5ab6ursNCrzubqF+HE6PpUsiweGZpU9UalUvNYxiJfbVeO3Hed4/5+j7I9KIPJyGiqV1bDigCnwDn24Om8uPkir6l7mkdGup5yznlNx1vVwJxV/8/sl+y5euwuNAz34qFcwvRv706FWBebuOGcO1D6u9tSr6MaYsFqkZOYwe9tZLqdmMWq7Dig841gNb1MpigEN7+YOLDKN9nZq6vm5oS6iVCMZZw5dMS3X2rugemUb0eeT+OqH6Xxh9x3bjXWIVHyYmNsfUAAV43NfsDpGHV9XkjNzuJCQgcGocIyC+vMqFVw5cN70nUw3PA5AtcsZPJQymCuZBelRUDPD8Cj1dLWpntftSkHNQveB/K9rLeLiUjCNdmPSoJI7beoH0HnnVJ7RrKOV+hAf5jzLO3ZzyEFLfMXOfHy2Ko46O/SVGkKlhmhTswjfuZgG6oKuYNqsBJzIJBVHsrFDg4GP7GbinXXN6GR1e3Jxm+k7aqC2bhwVbqxGVVU0rqp0GqhP8VbOy6w0NqXJ0e2WBT0MVJby2jR/En1b87LrU7RM+gd3VRoajKzUjaFKZixNtXZsNDagrvosRpWWY8YALiRk4O5ghxE1b+S8wir7R9i+MoBFQ57CaIQU4xyaqwseHqok7eJd7U4WGB7mC7tpuGaYcucdzk8DwCV+Lw9xiK0EE37qPL3Vm9htrEm9eFN7iaWGVszP7cAz+nVoDAW5bKsumU/+DGotqQ5+5Pch+Tk3jEbqEzRQn0G3+FleU9Q8qfNkcPYo825ZipaMrNxC3UrvNgnUosx5JNiHv4a1olp5Z6vlWvX1A/WM55sQnZRJ+5qmBmvXjrudnFHQcjTBYhSq/FboYArIYKoLs6RSqQj2dyPY340eDSrScsp6YpIz+fSJ+rjYm/6gW1TzYt6g5jzz005zv92q5ZwJ8HJkf1QCvRtX5MfNp82B+oMe9ejeoCC3p9OqzTnK/MZCIf7u5tGo8nk66ejdyJ8GldwJ9HIyP4jk++rpBnzw7zFz/Xk5Zx3ta1a1qiZ4pnkAf4dfIqWIfsefPhlCpzreuDnYme9HRQ8HyJvkyN/D1K7glfamFrwnYlNZe8x6IBiNWmXu/2tZ3eHmYGeue/d1syc6ydRArEo5Z3OQruvnypFriv3zSyJcHbSgVtM40IMPR48kKvUVvvhumymN7g5cTMygWWVPvnu2EU0+MA3D+niIH588UZ9Bv+4pckARPzd7Dpy3XmYqhSm6VCc6KZNzFoNu5LdgthwwBeDR+n7UrWj6PZpn6Mi8vJz20JyRputPsCeXTHycCiKlu5OOPoZhPGFcx6+5nclExxWsR24zoOH73G58YDcLgMHZr+PuUY5qiU05GWsK8D4q0+/PcWMlTioVGZczgOc0axllt5iO6v0cav0t2RtO00Vt6pL1p6El24x10WJgm7EuORdTeJXuQHdTETqQigNzcjtyGTfOKL5sMobwoscJdsbUIvJyGkEV8v9WVaxOqQzk8uqcfTzdrBKZxlo0Vx/nnMqfwBY90W/7BlTwuvd+qiTFkosWlUZjFXTrqc6SrHJi5O5nID9mnjX92GasSywezDN0RF2hDg5x+3hJW/B38JWhNwMrtsH5g/I4A8sNzfjD0IZ1xsZUJJ7vdF/xds5A5ugmc8BYFXuyyVTssFfloFflkplwHtxrFPn93y0SqEWZo1KprGbmyldUPXK+Wr6uNKnsed312RajUzUJ9GDb6StWQfpWqdUqlg5tSU6uQoCXo9W6FlW9qO3ryrG8wFLRw4Efnm2Mkpd2y8zxsw8Fci1/D+u69ZfaVGHYPOvZfDyddKjVKoLycqo/PNeYqCvppGXnElzRjY61vbHTqHl17j7AlKMe0TGIEH831hyNY+2xWIY9XJ3RnWvS6P01VsfWqFXmIG2VLosi6WoVrB+eQmtXKBSoXey15gZClteUYTHiV8MAd6LzuhxVLe9kXr5g8EOciU/j1bn7uJhoCqzzd5kiqat9Qbos50MH6NWoIo/W96Wcs6nNQD5HnQZ7Ow2BXo78V0SXY183B358rjEztkTSr3kAIxaEF97Iwq/bz/LxyuPmz0v2X2TN0VhzXHd3tOOjnsHmh5z8kp5r5T+keFkEapVKRZpzZSYn9bvu+Su46Bk8aALstWdDgherD9aBK8DKgtz8PEMHthjrkaT3JSnT9Hv/q6ETVdTR/G1owZv1/Vh+KIbxlwewx1iTHcY6xONe5Pk+cniDl+1WMDR+EFGKt3n5KWNF1G1GseoPVwy5CsdjCreePnM5jdlbz3IltwdbDcEc09biQKdH+fygPbuv6mkR3INO67wJ1sfyWsBFqkQuAEzF2vMNHXAkkwRc8KDg2FNz+rDY0BYFNV/kPgmXwJ7qENSZlyJfB2B1biNqnr6Kwf0ZwhLm85uhE9uNdQG4SHm6Z78PqBjjMIGNieVRY+Sj3GdMk/6oclFiI6CKBGohisWy7nrRkBZsPXWZjGwD7o46nK/ThSu/kZdl8BnSvhqOei2d63gXuc/N+BbRWA1M/2gHtanCqIWmxmFtgspZFefebJwGy8BTydOBsLo+hbZRXzMWdJcitrG81nLOOuztNIVa1iuKgr2d2jyO8tNNKzEiNKjIIj/LvvBPNLaeHa1Hw4r875rpB+21GsAUnOw0alpW82JfVAJzBjbnuZm7eLpZJQI9Hc19g6uVKwjULvZ2hFRyZ9Xrbfl2/SmrgT4sAzWYHpr+17UWf4Zfon/LylYB2nIbgPY1KjBnh6lO1zLH7+duT+e6PnSu61MwX/k1anq74ONmz6YT8eYAa8myZKJdjfI8ElxwnxsFeJiHxi2Kh5N1w8byrvZcKuIc+Rx1GgIquEPXKTTOzKG/UwS7ziZQvYIzno52/LL9HKAiSvGmZUUPc+lOIi68njMUgG+9HKnp7ULk5TT+Nra87rkADnp0IrzNy0T9ssdqeTzuaBs+yuvJp5m84vh19ibvWnTsVGpDjmkEwm8uNwRgZFVPvt1QiZOZ/njE25PfEe7r3F4Y0JCMEx0yp1JFFcMEx0XUD32WaX8WfsDNRI++RgfouI7f1+/iyNFA1h+PY2HMY+joYm68CdC5jjf7zycS4u/O5N6hLN1/kQ/+Pcavhi6kY48GI32cq1Kl0FnuLgnU4r5hmaNuWtmTpjfIQedbMPghPvj3KGMfqW1e5qjTMqRdtRvsVXw9G1bEwU6Dr7sDDSq5W627dizqa7k72uGk05CWbWBQm6poi6iTv5WW85bB1quI4AWmhwo/NwfzwBkPVfW67gNI/lSljjoNjQKsBySxt9OwYPBDfLY6wlxkn3HN0Jm/DWxORo4BZ72WA+M7o9OqzaUOUNBNz5KzXkvjQOtzWXb1yzekXbUbfpf57Ro61q5Ay2pebDt9he4N/Mx18z5uBQ3bfNzsi2wXUN/fjc51fYqcAtHXzZ7UzFxzsK5wzcAdozvXxMVeyyvtqxH25X951+vA+bwW9J7XBurrfF/5LBtFutrbMbF7Pav1Zy6n8d9JU/11sL9boeFTvV31OOq01PRxYWUR46brNGqWDW3FisPR/LLtLGF1fawGIxn2cHUuJWXQr7kpYL7YukqRgdqyaqOcs45co0Jieg69p2+3SIs91Su4cCw6mZ8v18ZR8wSnFT8MmEpAzl1JJwFXEhRXPqv4Jb+0aIbunxVkG4yFGmdWK+8M/pXxaxEIR3exIu8h0DJIg+nB8sfnC8YweKlNVebsOMfZK+ksNpjmD+iivfcTnkigFvcN7Q2Kvq8npJI7i4bcONdQklQqFV0tclSWuoX4MW9nFLWvaSRnue/rnWpw+GISfZpUKrR+weCHzKND3Yh1jvoG//gtbmeboOv/c6rv7878QQ9RrbxTkbM7PVTVi0VDWjJ5xTG2nLxMUAVnloUXDLahUavMJR751Q01vQseOK4tTs/XsVYFRnWqwedrTMW6ejtNkdsVZXDbqizee4GX25n6I6tUKma90JRDF0zjhOcHasuHE2e9lqaBnoVa3F9Ny6ZVdS9Ca3tz5nIqWTlGYpIzWfpqS+r6uXEpMYO3lx4iPdtAr0b+VvvW8XPlq6dNOchVI9uSazSyaM8Fcz9/r2sCtZ+7PTeSbbhJsYyFGhUKP9QFepl+f6pb3PMnGvuzeO8FBrWpwoutq+Dr5kAdP1dGdaqBSqUixiKHH1LJndFdapo/W86WB9C6ejnqVnSlVbVyPP+zaSjY/i0q8++h6EJVAJ6OOkZ0rM6QOftQUPONoReD2lThLScdPRtWpNs3W8xdDvPvy8qRbdgVeRVHvZbh8wuqhfJ/h5pW9kSnVRfZ/gJMDwfXurYrVv4c7/eSBGpx37hRY7Ky4O1HalPLx6XI4up8L7WpWuRyNwc7c1ewm3Gz6H5WVC403xWLftfXy3nna1Ht5uce27U2dIV1x2JZFn7JqhvctdRqFX+80oKzl9ML5dItt3mtQ3VzoI5PuX6R8LXefqQ2/wurZVX1oNdqaFLZ06qP+rWBcXLvYHpO20rnuj4s3muarKSihwOOOi0z+ptyYoqikG0woteaHhwqeTry28Brhs4sQn5piP4hDYv2nCct20CVcs5FbnOtznW8WX00lk+eCC5yfVGKKqkY0LIygNUD3wc96vFU00o0qORuFbTyH8q8nAseJnyKCHRuDnbmQD2jfxPs7TQYjQovtqpCBVc9L7etSmxKZqF6bBd7LWH1fOkW4sffeaOoVXR3YEArU8FzUAUXLqdeyTuv6YGqanlnqpZ3ZpvFnNxatcpckmFvp6FRgLu5O6W7ox1NAj3N7SgsS1DyXdtWxbItxb0igVrcN67Xv7qscNZreb5F5dva58nG/izae4FRnW69cYuzruDP3u4G9+z9HvUYPn8/XzwVcltpupkOtSow76Xm5gZv19M40JPGgTeuvrDMwV/bsvpmiuruBdYPL9cWNVcr78yedzuh06p5qmklFu+5wOuh1vdepVKZg3RxVK/gzM53QjkWnWwefjZfLZ+C0hadRm1uBDmuWx0+6xNi7mVwKwIsAnX7muV5qXVVWueVnNT1c2VQmyp4OJnaMNyoGslOo+b10BrEpmRSr2Lh0iBni/upzwt6arWKcd3qmJe/+2gdXmxVBaOiEPr5Zur4upq/n0oWDQ4t6+xr+riw/YwpUPte80BV3bvgAaeun6vV70mLquXMgXp055p0ruNtDtTXVk3kX5+ltOybTyxS0kpFoJ42bRpTp04lJiaGkJAQvvnmG5o1a2brZIky5u1HatPzu60Mbnt36pdLo8m9gnmpTVVqeBddPFwUtVpF40APTsen0qzK9XPCj4f40bmON/a3UaR8K1QqFS2rl1w932sdqvPN+lO8bdHO4E5U8nRk4uN18XDSFdkOID+HdavtIIrDWa8t8tiWOWpHvYbsdFOgLu+iv6WHA8scr2VQGtExiIYWDwUqlYp3Hq3DrRoRGnTddZaN/IqqGgFTTrdqXnfLzW8+jJO+4Fosc/6WdfY1LB70/K5pP1HBxZ7FQ1owfeNpnrymmqhXo4r8ffASj9TzoV/zAFQqFV893QAHO02RI46N7lyTZ2fupE1QOd57rE6RxeN3m80D9e+//86oUaP4/vvvad68OV9++SVdunQhIiKCChUq2Dp5ogyp7evKwfFditWtqqzSatS3PPSqpd8HP0SuUblpEC7pIH03jOpUgwEtK9+0eP529M8rAi5tLHsvWFb13GoO/q2wWsQkZ9KveQBqtYr3u9flzOW0Qg0bS9KNqleKcm23Rsucv+XwvjV9Ch5OiyqyblLZk5kDCj/sVPJ0ZO2odlbLujeoWGi7fK2DyrH33VA8nXTXfdC422z+H+3zzz9n0KBBvPDCC9SpU4fvv/8eR0dHfv75Z1snTZRBD1KQvhNajbpMBOFboVKpSjRIl3bDOwbh6aRj3qDmtKruxfCO18/NXqu8i57fBjY3d8V7rkVlxnere1cD0O0G6mtV8igI1Jbz11e3aAx3s0Z2d8rLWW+zIA02zlFnZ2ezd+9exo4da16mVqsJDQ1l+/btN9hTCCEeTKM61eD10CBUKhVzX3rI1sm5qT5NKrFwz4Xr9ma4Gcv6Z8uuYG4OdvzyYjMURcFRZ/PC4bvKpld3+fJlDAYD3t7WA0t4e3tz/HjhvndZWVlkZRU0GElJKR1zhQohxL1ky9zd7WpS2ZPVr7fFz73ofvg3Y6dRs+fdUIyKUqiIv12N8tfZ6/5SpsoJJ0+ejJubm/lVp86tN3YQQghhGzW8Xa47OuCtKOesp4LLvW/EVVrYNFCXK1cOjUZDbKz1WMCxsbH4+BTuSzp27FiSkpLMr6NHj96rpAohhBA2YdNArdPpaNy4MevWrTMvMxqNrFu3jhYtWhTaXq/X4+rqan65uNx+a1chhBCiLLF5DfyoUaPo378/TZo0oVmzZnz55ZekpaXxwgsv3HxnIYQQ4j5n80D91FNPER8fz7hx44iJiaFBgwasXLmyUAMzIYQQ4kFk80ANMGzYMIYNG2brZAghhBClTqkI1MVlNJqGz4uOjrZxSoQQQohblx+38uPYjZTpQJ3fWlzGBRdCCFEWxcbGEhAQcMNtVIpyk9nqS7Hc3Fz279+Pt7c36hKY4jAlJYU6depw9OhRaVF+G+S+FZ/cu+KR+1Z8cu+Kp6Tvm9FoJDY2loYNG6LV3jjPXKYDdUlLTk7Gzc2NpKQkXF2LN9zdg0juW/HJvSseuW/FJ/eueGx538rUyGRCCCHEg0YCtRBCCFGKSaC2oNfrGT9+PHr9gzNlXkmQ+1Z8cu+KR+5b8cm9Kx5b3jepoxZCCCFKMclRCyGEEKWYBGohhBCiFJNALYQQQpRiEqjzTJs2jcqVK2Nvb0/z5s3ZtWuXrZNU6m3evJlu3brh5+eHSqVi2bJltk5SmTB58mSaNm2Ki4sLFSpUoEePHkRERNg6WWXC9OnTqV+/vnmq2xYtWrBixQpbJ6vMmTJlCiqVipEjR9o6KaXehAkTUKlUVq9atWrd0zRIoAZ+//13Ro0axfjx49m3bx8hISF06dKFuLg4WyetVEtLSyMkJIRp06bZOillyqZNmxg6dCg7duxgzZo15OTk0LlzZ9LS0mydtFLP39+fKVOmsHfvXvbs2UOHDh3o3r07R44csXXSyozdu3fzww8/UL9+fVsnpcyoW7cu0dHR5teWLVvubQIUoTRr1kwZOnSo+bPBYFD8/PyUyZMn2zBVZQugLF261NbJKJPi4uIUQNm0aZOtk1ImeXh4KDNmzLB1MsqElJQUJSgoSFmzZo3Srl07ZcSIEbZOUqk3fvx4JSQkxKZpeOBz1NnZ2ezdu5fQ0FDzMrVaTWhoKNu3b7dhysSDIikpCQBPT08bp6RsMRgMLFiwgLS0NFq0aGHr5JQJQ4cO5dFHH7X6fydu7uTJk/j5+VG1alX69etHVFTUPT1/mZ49qyRcvnwZg8GAt7e31XJvb2+OHz9uo1SJB4XRaGTkyJG0atWKevXq2To5ZcKhQ4do0aIFmZmZODs7s3TpUurUqWPrZJV6CxYsYN++fezevdvWSSlTmjdvzuzZs6lZsybR0dFMnDiRNm3acPjw4Xs2qckDH6iFsKWhQ4dy+PDhe1/nVYbVrFmT8PBwkpKSWLx4Mf3792fTpk0SrG/g/PnzjBgxgjVr1mBvb2/r5JQpXbt2Nb+vX78+zZs3JzAwkIULFzJw4MB7koYHPlCXK1cOjUZjnts6X2xsLD4+PjZKlXgQDBs2jH/++YfNmzfj7+9v6+SUGTqdjurVqwPQuHFjdu/ezVdffcUPP/xg45SVXnv37iUuLo5GjRqZlxkMBjZv3sy3335LVlYWGo3GhiksO9zd3alRowanTp26Z+d84OuodTodjRs3Zt26deZlRqORdevWSb2XuCsURWHYsGEsXbqU9evXU6VKFVsnqUwzGo1kZWXZOhmlWseOHTl06BDh4eHmV5MmTejXrx/h4eESpG9Damoqp0+fxtfX956d84HPUQOMGjWK/v3706RJE5o1a8aXX35JWloaL7zwgq2TVqqlpqZaPVVGRkYSHh6Op6cnAQEBNkxZ6TZ06FDmzZvHn3/+iYuLCzExMQC4ubnh4OBg49SVbmPHjqVr164EBASQkpLCvHnz2LhxI6tWrbJ10ko1FxeXQm0gnJyc8PLykrYRNzF69Gi6detGYGAgly5dYvz48Wg0Gvr27XvP0iCBGnjqqaeIj49n3LhxxMTE0KBBA1auXFmogZmwtmfPHh5++GHz51GjRgHQv39/Zs+ebaNUlX7Tp08HoH379lbLZ82axYABA+59gsqQuLg4nn/+eaKjo3Fzc6N+/fqsWrWKTp062Tpp4j514cIF+vbty5UrVyhfvjytW7dmx44dlC9f/p6lQWbPEkIIIUqxB76OWgghhCjNJFALIYQQpZgEaiGEEKIUk0AthBBClGISqIUQQohSTAK1EEIIUYpJoBZCCCFKMQnUQgghRCkmgVoIccdUKhXLli2zdTKEuC9JoBaijBswYAAqlarQKywszNZJE0KUABnrW4j7QFhYGLNmzbJaptfrbZQaIURJkhy1EPcBvV6Pj4+P1cvDwwMwFUtPnz6drl274uDgQNWqVVm8eLHV/ocOHaJDhw44ODjg5eXF4MGDSU1Ntdrm559/pm7duuj1enx9fRk2bJjV+suXL9OzZ08cHR0JCgrir7/+Mq9LSEigX79+lC9fHgcHB4KCggo9WAghiiaBWogHwHvvvUfv3r05cOAA/fr14+mnn+bYsWMApKWl0aVLFzw8PNi9ezeLFi1i7dq1VoF4+vTpDB06lMGDB3Po0CH++usvqlevbnWOiRMn0qdPHw4ePMgjjzxCv379uHr1qvn8R48eZcWKFRw7dozp06dTrly5e3cDhCjLFCFEmda/f39Fo9EoTk5OVq8PP/xQURRFAZQhQ4ZY7dO8eXPllVdeURRFUX788UfFw8NDSU1NNa//999/FbVarcTExCiKoih+fn7KO++8c900AMq7775r/pyamqoAyooVKxRFUZRu3bopL7zwQslcsBAPGKmjFuI+8PDDD5vnuc7n6elpft+iRQurdS1atCA8PByAY8eOERISgpOTk3l9q1atMBqNREREoFKpuHTpEh07drxhGurXr29+7+TkhKurK3FxcQC88sor9O7dm3379tG5c2d69OhBy5Yti3WtQjxoJFALcR9wcnIqVBRdUhwcHG5pOzs7O6vPKpUKo9EIQNeuXTl37hzLly9nzZo1dOzYkaFDh/Lpp5+WeHqFuN9IHbUQD4AdO3YU+ly7dm0AateuzYEDB0hLSzOv37p1K2q1mpo1a+Li4kLlypVZt27dHaWhfPny9O/fnzlz5vDll1/y448/3tHxhHhQSI5aiPtAVlYWMTExVsu0Wq25wdaiRYto0qQJrVu3Zu7cuezatYuZM2cC0K9fP8aPH0///v2ZMGEC8fHxvPbaazz33HN4e3sDMGHCBIYMGUKFChXo2rUrKSkpbN26lddee+2W0jdu3DgaN25M3bp1ycrK4p9//jE/KAghbkwCtRD3gZUrV+Lr62u1rGbNmhw/fhwwtchesGABr776Kr6+vsyfP586deoA4OjoyKpVqxgxYgRNmzbF0dGR3r178/nnn5uP1b9/fzIzM/niiy8YPXo05cqV44knnrjl9Ol0OsaOHcvZs2dxcHCgTZs2LFiwoASuXIj7n0pRFMXWiRBC3D0qlYqlS5fSo0cPWydFCFEMUkcthBBClGISqIUQQohSTOqohbjPSe2WEGWb5KiFEEKIUkwCtRBCCFGKSaAWQgghSjEJ1EIIIUQpJoFaCCGEKMUkUAshhBClmARqIYQQohSTQC2EEEKUYhKohRBCiFLs/+aOHLuivM8OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy values\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:44:31.538162Z",
     "iopub.status.busy": "2025-06-18T13:44:31.537817Z",
     "iopub.status.idle": "2025-06-18T13:44:31.544466Z",
     "shell.execute_reply": "2025-06-18T13:44:31.543552Z",
     "shell.execute_reply.started": "2025-06-18T13:44:31.538133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# this function will classify the subject of a given text using the trained model\n",
    "# It takes the text as input and returns the predicted subject as a string.\n",
    "def classify_subject(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    # print(predicted_label)\n",
    "    # Return the classified result\n",
    "    # \"Maths\": 0, \"Chemistry\": 1,\"Physics\":2,\"Biology\":3\n",
    "    return (\n",
    "    \"Maths\" if predicted_label == 0 else\n",
    "    \"Chemistry\" if predicted_label == 1 else\n",
    "    \"Physics\" if predicted_label == 2 else\n",
    "    \"Biology\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:48:36.502035Z",
     "iopub.status.busy": "2025-06-18T13:48:36.501122Z",
     "iopub.status.idle": "2025-06-18T13:48:36.691847Z",
     "shell.execute_reply": "2025-06-18T13:48:36.690990Z",
     "shell.execute_reply.started": "2025-06-18T13:48:36.501984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n",
      "Chemistry\n",
      "Maths\n",
      "Biology\n"
     ]
    }
   ],
   "source": [
    "#HERE we will test the model on some sample texts to see how well it classifies the subjects\n",
    "# You can change the texts to test the model on different inputs.\n",
    "text_1 = (\n",
    "    \"How the gravitational constant will change if a brass plate is introduced between two bodies?\"\n",
    ")\n",
    "text_2=(\n",
    "    \"\"\"A ketone has molar mass 86 Which of the following cannot be IUPAC name of this ketone? what is its \n",
    "       periodic number?\n",
    "     \"\"\"\n",
    ")\n",
    "text_3=(\n",
    "    \"The equation of a line is y=mx+c\"\n",
    ")\n",
    "text_4=(\n",
    "    \"The human body has billions and trillions of cells. Tissues are clusters of cells.\"\n",
    ")\n",
    "print(classify_subject(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_subject(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_subject(\n",
    "    text_3, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_subject(\n",
    "    text_4, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T13:08:35.248392Z",
     "iopub.status.busy": "2025-06-18T13:08:35.248036Z",
     "iopub.status.idle": "2025-06-18T13:42:56.335018Z",
     "shell.execute_reply": "2025-06-18T13:42:56.334101Z",
     "shell.execute_reply.started": "2025-06-18T13:08:35.248360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 91.05%\n",
      "Validation accuracy: 90.49%\n",
      "Test accuracy: 89.99%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the entire dataset\n",
    "# This will give us the accuracy of the model on the training, validation, and test datasets\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is **91.05%** on training , **90.49%** for validation , **89.99%** for testing. So it has improved from before\n",
    "hence we have fine-tuned it for classification . For a text based classification Fine-tuning transformers is the best option as we are working on language. \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 1736879,
     "datasetId": 957852,
     "isSourceIdPinned": false,
     "sourceId": 1700219,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30788,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
