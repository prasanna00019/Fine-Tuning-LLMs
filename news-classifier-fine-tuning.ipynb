{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Classification with GPT-2 Fine-Tuning\n",
    "\n",
    "This project demonstrates how to fine-tune a GPT-2 model for news article classification using the AG News dataset. The workflow covers data preparation, model adaptation, training, evaluation, and inference, all implemented in PyTorch.\n",
    "\n",
    "## Project Workflow\n",
    "\n",
    "1. **Data Preparation**\n",
    "    - Load AG News dataset splits (`train`, `test`) from Hugging Face Datasets.\n",
    "    - Split the training set into training and validation sets (85%/15%).\n",
    "    - Save splits as CSV files for reproducibility.\n",
    "\n",
    "2. **Dataset & DataLoader**\n",
    "    - Implement a custom `NewsDataset` class for tokenization and padding.\n",
    "    - Use PyTorch `DataLoader` for batching and shuffling.\n",
    "\n",
    "3. **Model Architecture**\n",
    "    - Define a GPT-2-like transformer model from scratch, including:\n",
    "      - Multi-head self-attention\n",
    "      - Layer normalization\n",
    "      - Feed-forward layers\n",
    "      - Positional and token embeddings\n",
    "    - Adapt the output head for classification (4 news categories).\n",
    "\n",
    "4. **Pretrained Weights**\n",
    "    - Download and load pretrained GPT-2 weights (compatible with Hugging Face GPT-2 checkpoints).\n",
    "    - Freeze most model layers, unfreeze the last few transformer blocks and output head for fine-tuning.\n",
    "\n",
    "5. **Training & Evaluation**\n",
    "    - Train only the last transformer blocks and classification head.\n",
    "    - Track and plot training/validation loss and accuracy.\n",
    "    - Save and reload the fine-tuned model.\n",
    "\n",
    "6. **Inference**\n",
    "    - Provide a function to classify new news texts.\n",
    "    - Example predictions are shown for sample news snippets.\n",
    "\n",
    "## Key Files & Functions\n",
    "\n",
    "- **Data Loading:** `pd.read_parquet`, `random_split`, CSV export\n",
    "- **Model:** `GPTModel`, `TransformerBlock`, `MultiHeadAttention`\n",
    "- **Training:** `train_classifier_simple`, `calc_loss_batch`, `calc_accuracy_loader`\n",
    "- **Evaluation:** Accuracy and loss metrics, plotting with matplotlib\n",
    "- **Inference:** `classify_news` function for single-text prediction\n",
    "\n",
    "## Usage\n",
    "\n",
    "- Run the notebook cells sequentially to reproduce the workflow.\n",
    "- Modify the `classify_news` function to test your own news headlines or articles.\n",
    "- Adjust hyperparameters (learning rate, batch size, number of epochs) as needed.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.x\n",
    "- PyTorch\n",
    "- pandas, numpy, matplotlib\n",
    "- tiktoken\n",
    "- tqdm\n",
    "- TensorFlow (for loading GPT-2 checkpoints)\n",
    "- requests\n",
    "\n",
    "## Notes\n",
    "\n",
    "- The model is adapted for 4-class classification (`World`, `Sports`, `Business`, `Sci/Tech`).\n",
    "- Only the last few transformer blocks and the classification head are fine-tuned for efficiency.\n",
    "- The workflow is fully reproducible and modular for further experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "**Explore the notebook to see the full implementation and results!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:24.836248Z",
     "iopub.status.busy": "2025-06-18T16:38:24.836091Z",
     "iopub.status.idle": "2025-06-18T16:38:28.828750Z",
     "shell.execute_reply": "2025-06-18T16:38:28.828032Z",
     "shell.execute_reply.started": "2025-06-18T16:38:24.836234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train_df = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:47.568522Z",
     "iopub.status.busy": "2025-06-18T16:38:47.568220Z",
     "iopub.status.idle": "2025-06-18T16:38:48.208275Z",
     "shell.execute_reply": "2025-06-18T16:38:48.207714Z",
     "shell.execute_reply.started": "2025-06-18T16:38:47.568500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     Fears for T N pension after talks Unions repre...      2\n",
      "1     The Race is On: Second Private Team Sets Launc...      3\n",
      "2     Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
      "3     Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
      "4     Calif. Aims to Limit Farm-Related Smog (AP) AP...      3\n",
      "...                                                 ...    ...\n",
      "7595  Around the world Ukrainian presidential candid...      0\n",
      "7596  Void is filled with Clement With the supply of...      1\n",
      "7597  Martinez leaves bitter Like Roger Clemens did ...      1\n",
      "7598  5 of arthritis patients in Singapore take Bext...      2\n",
      "7599  EBay gets into rentals EBay plans to buy the a...      2\n",
      "\n",
      "[7600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(train_df)\n",
    "test_df=pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:48.210076Z",
     "iopub.status.busy": "2025-06-18T16:38:48.209763Z",
     "iopub.status.idle": "2025-06-18T16:38:48.213704Z",
     "shell.execute_reply": "2025-06-18T16:38:48.213039Z",
     "shell.execute_reply.started": "2025-06-18T16:38:48.210053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels={\n",
    "    0:\"World\",\n",
    "    1:\"Sports\",\n",
    "    2:\"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:48.214510Z",
     "iopub.status.busy": "2025-06-18T16:38:48.214292Z",
     "iopub.status.idle": "2025-06-18T16:38:48.241943Z",
     "shell.execute_reply": "2025-06-18T16:38:48.241389Z",
     "shell.execute_reply.started": "2025-06-18T16:38:48.214492Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2    30000\n",
      "3    30000\n",
      "1    30000\n",
      "0    30000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"label\"].value_counts()) \n",
    "# so we have a balanced dataset . no need to balance it . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:48.242957Z",
     "iopub.status.busy": "2025-06-18T16:38:48.242718Z",
     "iopub.status.idle": "2025-06-18T16:38:48.278991Z",
     "shell.execute_reply": "2025-06-18T16:38:48.278179Z",
     "shell.execute_reply.started": "2025-06-18T16:38:48.242941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''' 85% for training , 15% for validation  / we dont have a validation set from the imported dataset .\n",
    "so we create a function to split train dataset into train and validation '''\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # random shuffle the df\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    # Split the df\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    return train_df, validation_df\n",
    "\n",
    "train_df, validation_df = random_split(train_df, 0.85, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:48.281040Z",
     "iopub.status.busy": "2025-06-18T16:38:48.280848Z",
     "iopub.status.idle": "2025-06-18T16:38:48.284895Z",
     "shell.execute_reply": "2025-06-18T16:38:48.284404Z",
     "shell.execute_reply.started": "2025-06-18T16:38:48.281025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102000\n",
      "18000\n",
      "7600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:48.285607Z",
     "iopub.status.busy": "2025-06-18T16:38:48.285436Z",
     "iopub.status.idle": "2025-06-18T16:38:49.188791Z",
     "shell.execute_reply": "2025-06-18T16:38:49.188260Z",
     "shell.execute_reply.started": "2025-06-18T16:38:48.285593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#save these data to the csv files\n",
    "train_df.to_csv(\"news_train.csv\", index=None)\n",
    "validation_df.to_csv(\"news_validation.csv\", index=None)\n",
    "test_df.to_csv(\"news_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:49.189727Z",
     "iopub.status.busy": "2025-06-18T16:38:49.189454Z",
     "iopub.status.idle": "2025-06-18T16:38:53.294610Z",
     "shell.execute_reply": "2025-06-18T16:38:53.294089Z",
     "shell.execute_reply.started": "2025-06-18T16:38:49.189701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:53.295664Z",
     "iopub.status.busy": "2025-06-18T16:38:53.295273Z",
     "iopub.status.idle": "2025-06-18T16:38:59.835173Z",
     "shell.execute_reply": "2025-06-18T16:38:59.834346Z",
     "shell.execute_reply.started": "2025-06-18T16:38:53.295645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = NewsDataset(\n",
    "    csv_file=\"news_train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# print(train_dataset.max_length)\n",
    "val_dataset = NewsDataset(\n",
    "    csv_file=\"news_validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = NewsDataset(\n",
    "    csv_file=\"news_test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.836521Z",
     "iopub.status.busy": "2025-06-18T16:38:59.836248Z",
     "iopub.status.idle": "2025-06-18T16:38:59.845580Z",
     "shell.execute_reply": "2025-06-18T16:38:59.844820Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.836502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.846832Z",
     "iopub.status.busy": "2025-06-18T16:38:59.846340Z",
     "iopub.status.idle": "2025-06-18T16:38:59.860439Z",
     "shell.execute_reply": "2025-06-18T16:38:59.859702Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.846813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.2,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.861580Z",
     "iopub.status.busy": "2025-06-18T16:38:59.861334Z",
     "iopub.status.idle": "2025-06-18T16:38:59.880060Z",
     "shell.execute_reply": "2025-06-18T16:38:59.879543Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.861565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.880922Z",
     "iopub.status.busy": "2025-06-18T16:38:59.880676Z",
     "iopub.status.idle": "2025-06-18T16:38:59.899604Z",
     "shell.execute_reply": "2025-06-18T16:38:59.898999Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.880894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.900978Z",
     "iopub.status.busy": "2025-06-18T16:38:59.900347Z",
     "iopub.status.idle": "2025-06-18T16:38:59.917752Z",
     "shell.execute_reply": "2025-06-18T16:38:59.917166Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.900957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:38:59.920844Z",
     "iopub.status.busy": "2025-06-18T16:38:59.920680Z",
     "iopub.status.idle": "2025-06-18T16:39:01.366339Z",
     "shell.execute_reply": "2025-06-18T16:39:01.365559Z",
     "shell.execute_reply.started": "2025-06-18T16:38:59.920832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:01.367457Z",
     "iopub.status.busy": "2025-06-18T16:39:01.367192Z",
     "iopub.status.idle": "2025-06-18T16:39:01.372932Z",
     "shell.execute_reply": "2025-06-18T16:39:01.372067Z",
     "shell.execute_reply.started": "2025-06-18T16:39:01.367431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:01.374001Z",
     "iopub.status.busy": "2025-06-18T16:39:01.373751Z",
     "iopub.status.idle": "2025-06-18T16:39:15.097952Z",
     "shell.execute_reply": "2025-06-18T16:39:15.097273Z",
     "shell.execute_reply.started": "2025-06-18T16:39:01.373981Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 16:39:02.880001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750264743.080068      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750264743.140599      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests  # Make sure requests is installed\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "def download_file(url, destination):\n",
    "    try:\n",
    "        # Send a GET request to download the file, disabling SSL verification\n",
    "        response = requests.get(url, stream=True, verify=False)\n",
    "\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Iterate over the file data in chunks\n",
    "                for chunk in response.iter_content(block_size):\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "                    file.write(chunk)  # Write the chunk to the file\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "        print(f\"Please check the URL: {url}\")\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:15.099023Z",
     "iopub.status.busy": "2025-06-18T16:39:15.098605Z",
     "iopub.status.idle": "2025-06-18T16:39:15.103031Z",
     "shell.execute_reply": "2025-06-18T16:39:15.102289Z",
     "shell.execute_reply.started": "2025-06-18T16:39:15.099004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:15.104103Z",
     "iopub.status.busy": "2025-06-18T16:39:15.103824Z",
     "iopub.status.idle": "2025-06-18T16:39:15.140687Z",
     "shell.execute_reply": "2025-06-18T16:39:15.140048Z",
     "shell.execute_reply.started": "2025-06-18T16:39:15.104075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:15.141806Z",
     "iopub.status.busy": "2025-06-18T16:39:15.141595Z",
     "iopub.status.idle": "2025-06-18T16:39:15.161461Z",
     "shell.execute_reply": "2025-06-18T16:39:15.160912Z",
     "shell.execute_reply.started": "2025-06-18T16:39:15.141790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "# !pip install tiktoken\n",
    "import tiktoken\n",
    "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:15.162314Z",
     "iopub.status.busy": "2025-06-18T16:39:15.162124Z",
     "iopub.status.idle": "2025-06-18T16:39:15.175418Z",
     "shell.execute_reply": "2025-06-18T16:39:15.174799Z",
     "shell.execute_reply.started": "2025-06-18T16:39:15.162293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:15.176273Z",
     "iopub.status.busy": "2025-06-18T16:39:15.176052Z",
     "iopub.status.idle": "2025-06-18T16:39:58.827360Z",
     "shell.execute_reply": "2025-06-18T16:39:58.826791Z",
     "shell.execute_reply.started": "2025-06-18T16:39:15.176258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 155kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.21MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 217kiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:38<00:00, 12.8MiB/s] \n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 9.59MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.40MiB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.60MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:58.828328Z",
     "iopub.status.busy": "2025-06-18T16:39:58.828064Z",
     "iopub.status.idle": "2025-06-18T16:39:58.832499Z",
     "shell.execute_reply": "2025-06-18T16:39:58.831707Z",
     "shell.execute_reply.started": "2025-06-18T16:39:58.828305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:58.833447Z",
     "iopub.status.busy": "2025-06-18T16:39:58.833196Z",
     "iopub.status.idle": "2025-06-18T16:39:58.848562Z",
     "shell.execute_reply": "2025-06-18T16:39:58.848019Z",
     "shell.execute_reply.started": "2025-06-18T16:39:58.833428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 4\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:58.849392Z",
     "iopub.status.busy": "2025-06-18T16:39:58.849162Z",
     "iopub.status.idle": "2025-06-18T16:39:58.876449Z",
     "shell.execute_reply": "2025-06-18T16:39:58.875794Z",
     "shell.execute_reply.started": "2025-06-18T16:39:58.849352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.trf_blocks[-2].parameters():\n",
    "    param.requires_grad= True\n",
    "for param in model.trf_blocks[-3].parameters():\n",
    "    param.requires_grad=True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:58.877351Z",
     "iopub.status.busy": "2025-06-18T16:39:58.877138Z",
     "iopub.status.idle": "2025-06-18T16:39:58.894932Z",
     "shell.execute_reply": "2025-06-18T16:39:58.894411Z",
     "shell.execute_reply.started": "2025-06-18T16:39:58.877329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[10919,   318, 16901,    30]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"what is meditation?\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:58.895918Z",
     "iopub.status.busy": "2025-06-18T16:39:58.895684Z",
     "iopub.status.idle": "2025-06-18T16:39:59.035667Z",
     "shell.execute_reply": "2025-06-18T16:39:59.034948Z",
     "shell.execute_reply.started": "2025-06-18T16:39:58.895894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.6141,  1.2282,  0.3008, -0.5369],\n",
      "         [-1.8646,  5.9696,  2.7381, -0.5265],\n",
      "         [-2.5723,  4.0816,  2.1425, -0.6400],\n",
      "         [-4.8482,  6.3234,  3.1048,  0.4407]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:59.036665Z",
     "iopub.status.busy": "2025-06-18T16:39:59.036387Z",
     "iopub.status.idle": "2025-06-18T16:39:59.041779Z",
     "shell.execute_reply": "2025-06-18T16:39:59.041164Z",
     "shell.execute_reply.started": "2025-06-18T16:39:59.036644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    total_correct, total_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            if num_batches is not None and i >= num_batches:\n",
    "                break\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)[:, -1, :]  # Only last token logits\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            # Efficient batch accuracy\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    return total_correct / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:39:59.042808Z",
     "iopub.status.busy": "2025-06-18T16:39:59.042489Z",
     "iopub.status.idle": "2025-06-18T16:40:12.455475Z",
     "shell.execute_reply": "2025-06-18T16:40:12.454850Z",
     "shell.execute_reply.started": "2025-06-18T16:39:59.042710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training accuracy: 25.31%\n",
      "Validation accuracy: 24.38%\n",
      "Test accuracy: 28.44%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device) \n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:12.456259Z",
     "iopub.status.busy": "2025-06-18T16:40:12.456082Z",
     "iopub.status.idle": "2025-06-18T16:40:12.460572Z",
     "shell.execute_reply": "2025-06-18T16:40:12.459868Z",
     "shell.execute_reply.started": "2025-06-18T16:40:12.456245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:12.461390Z",
     "iopub.status.busy": "2025-06-18T16:40:12.461157Z",
     "iopub.status.idle": "2025-06-18T16:40:12.477955Z",
     "shell.execute_reply": "2025-06-18T16:40:12.477293Z",
     "shell.execute_reply.started": "2025-06-18T16:40:12.461354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:12.478991Z",
     "iopub.status.busy": "2025-06-18T16:40:12.478773Z",
     "iopub.status.idle": "2025-06-18T16:40:18.825147Z",
     "shell.execute_reply": "2025-06-18T16:40:18.824409Z",
     "shell.execute_reply.started": "2025-06-18T16:40:12.478970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.127\n",
      "Validation loss: 3.435\n",
      "Test loss: 3.308\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:18.826102Z",
     "iopub.status.busy": "2025-06-18T16:40:18.825919Z",
     "iopub.status.idle": "2025-06-18T16:40:18.833594Z",
     "shell.execute_reply": "2025-06-18T16:40:18.832843Z",
     "shell.execute_reply.started": "2025-06-18T16:40:18.826087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:18.834497Z",
     "iopub.status.busy": "2025-06-18T16:40:18.834211Z",
     "iopub.status.idle": "2025-06-18T16:40:18.854990Z",
     "shell.execute_reply": "2025-06-18T16:40:18.854244Z",
     "shell.execute_reply.started": "2025-06-18T16:40:18.834473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T16:40:18.855998Z",
     "iopub.status.busy": "2025-06-18T16:40:18.855752Z",
     "iopub.status.idle": "2025-06-18T18:34:48.716849Z",
     "shell.execute_reply": "2025-06-18T18:34:48.716212Z",
     "shell.execute_reply.started": "2025-06-18T16:40:18.855976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.107, Val loss 3.259\n",
      "Ep 1 (Step 000050): Train loss 1.440, Val loss 1.403\n",
      "Ep 1 (Step 000100): Train loss 1.402, Val loss 1.417\n",
      "Ep 1 (Step 000150): Train loss 1.383, Val loss 1.390\n",
      "Ep 1 (Step 000200): Train loss 1.380, Val loss 1.394\n",
      "Ep 1 (Step 000250): Train loss 1.378, Val loss 1.389\n",
      "Ep 1 (Step 000300): Train loss 1.361, Val loss 1.345\n",
      "Ep 1 (Step 000350): Train loss 1.283, Val loss 1.292\n",
      "Ep 1 (Step 000400): Train loss 1.303, Val loss 1.297\n",
      "Ep 1 (Step 000450): Train loss 1.179, Val loss 1.141\n",
      "Ep 1 (Step 000500): Train loss 1.049, Val loss 1.061\n",
      "Ep 1 (Step 000550): Train loss 0.987, Val loss 0.939\n",
      "Ep 1 (Step 000600): Train loss 0.786, Val loss 0.846\n",
      "Ep 1 (Step 000650): Train loss 0.708, Val loss 0.800\n",
      "Ep 1 (Step 000700): Train loss 0.644, Val loss 0.638\n",
      "Ep 1 (Step 000750): Train loss 0.621, Val loss 0.585\n",
      "Ep 1 (Step 000800): Train loss 0.641, Val loss 0.612\n",
      "Ep 1 (Step 000850): Train loss 0.464, Val loss 0.536\n",
      "Ep 1 (Step 000900): Train loss 0.535, Val loss 0.506\n",
      "Ep 1 (Step 000950): Train loss 0.515, Val loss 0.493\n",
      "Ep 1 (Step 001000): Train loss 0.281, Val loss 0.535\n",
      "Ep 1 (Step 001050): Train loss 0.606, Val loss 0.488\n",
      "Ep 1 (Step 001100): Train loss 0.424, Val loss 0.497\n",
      "Ep 1 (Step 001150): Train loss 0.478, Val loss 0.483\n",
      "Ep 1 (Step 001200): Train loss 0.384, Val loss 0.438\n",
      "Ep 1 (Step 001250): Train loss 0.377, Val loss 0.464\n",
      "Ep 1 (Step 001300): Train loss 0.416, Val loss 0.500\n",
      "Ep 1 (Step 001350): Train loss 0.541, Val loss 0.442\n",
      "Ep 1 (Step 001400): Train loss 0.313, Val loss 0.406\n",
      "Ep 1 (Step 001450): Train loss 0.359, Val loss 0.419\n",
      "Ep 1 (Step 001500): Train loss 0.350, Val loss 0.433\n",
      "Ep 1 (Step 001550): Train loss 0.316, Val loss 0.417\n",
      "Ep 1 (Step 001600): Train loss 0.336, Val loss 0.393\n",
      "Ep 1 (Step 001650): Train loss 0.338, Val loss 0.394\n",
      "Ep 1 (Step 001700): Train loss 0.305, Val loss 0.365\n",
      "Ep 1 (Step 001750): Train loss 0.288, Val loss 0.379\n",
      "Ep 1 (Step 001800): Train loss 0.365, Val loss 0.392\n",
      "Ep 1 (Step 001850): Train loss 0.285, Val loss 0.389\n",
      "Ep 1 (Step 001900): Train loss 0.315, Val loss 0.385\n",
      "Ep 1 (Step 001950): Train loss 0.322, Val loss 0.372\n",
      "Ep 1 (Step 002000): Train loss 0.281, Val loss 0.438\n",
      "Ep 1 (Step 002050): Train loss 0.332, Val loss 0.365\n",
      "Ep 1 (Step 002100): Train loss 0.173, Val loss 0.387\n",
      "Ep 1 (Step 002150): Train loss 0.390, Val loss 0.399\n",
      "Ep 1 (Step 002200): Train loss 0.309, Val loss 0.408\n",
      "Ep 1 (Step 002250): Train loss 0.269, Val loss 0.388\n",
      "Ep 1 (Step 002300): Train loss 0.317, Val loss 0.418\n",
      "Ep 1 (Step 002350): Train loss 0.261, Val loss 0.378\n",
      "Ep 1 (Step 002400): Train loss 0.274, Val loss 0.352\n",
      "Ep 1 (Step 002450): Train loss 0.322, Val loss 0.373\n",
      "Ep 1 (Step 002500): Train loss 0.338, Val loss 0.352\n",
      "Ep 1 (Step 002550): Train loss 0.310, Val loss 0.373\n",
      "Ep 1 (Step 002600): Train loss 0.257, Val loss 0.326\n",
      "Ep 1 (Step 002650): Train loss 0.278, Val loss 0.338\n",
      "Ep 1 (Step 002700): Train loss 0.206, Val loss 0.349\n",
      "Ep 1 (Step 002750): Train loss 0.300, Val loss 0.356\n",
      "Ep 1 (Step 002800): Train loss 0.329, Val loss 0.359\n",
      "Ep 1 (Step 002850): Train loss 0.187, Val loss 0.367\n",
      "Ep 1 (Step 002900): Train loss 0.324, Val loss 0.310\n",
      "Ep 1 (Step 002950): Train loss 0.394, Val loss 0.315\n",
      "Ep 1 (Step 003000): Train loss 0.445, Val loss 0.383\n",
      "Ep 1 (Step 003050): Train loss 0.255, Val loss 0.366\n",
      "Ep 1 (Step 003100): Train loss 0.236, Val loss 0.342\n",
      "Ep 1 (Step 003150): Train loss 0.302, Val loss 0.301\n",
      "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
      "Ep 2 (Step 003200): Train loss 0.347, Val loss 0.338\n",
      "Ep 2 (Step 003250): Train loss 0.200, Val loss 0.394\n",
      "Ep 2 (Step 003300): Train loss 0.259, Val loss 0.295\n",
      "Ep 2 (Step 003350): Train loss 0.179, Val loss 0.313\n",
      "Ep 2 (Step 003400): Train loss 0.444, Val loss 0.286\n",
      "Ep 2 (Step 003450): Train loss 0.277, Val loss 0.316\n",
      "Ep 2 (Step 003500): Train loss 0.237, Val loss 0.343\n",
      "Ep 2 (Step 003550): Train loss 0.332, Val loss 0.375\n",
      "Ep 2 (Step 003600): Train loss 0.242, Val loss 0.308\n",
      "Ep 2 (Step 003650): Train loss 0.313, Val loss 0.291\n",
      "Ep 2 (Step 003700): Train loss 0.306, Val loss 0.317\n",
      "Ep 2 (Step 003750): Train loss 0.282, Val loss 0.324\n",
      "Ep 2 (Step 003800): Train loss 0.244, Val loss 0.321\n",
      "Ep 2 (Step 003850): Train loss 0.220, Val loss 0.317\n",
      "Ep 2 (Step 003900): Train loss 0.290, Val loss 0.293\n",
      "Ep 2 (Step 003950): Train loss 0.298, Val loss 0.326\n",
      "Ep 2 (Step 004000): Train loss 0.317, Val loss 0.299\n",
      "Ep 2 (Step 004050): Train loss 0.250, Val loss 0.284\n",
      "Ep 2 (Step 004100): Train loss 0.293, Val loss 0.321\n",
      "Ep 2 (Step 004150): Train loss 0.262, Val loss 0.281\n",
      "Ep 2 (Step 004200): Train loss 0.267, Val loss 0.275\n",
      "Ep 2 (Step 004250): Train loss 0.213, Val loss 0.307\n",
      "Ep 2 (Step 004300): Train loss 0.264, Val loss 0.309\n",
      "Ep 2 (Step 004350): Train loss 0.215, Val loss 0.306\n",
      "Ep 2 (Step 004400): Train loss 0.226, Val loss 0.293\n",
      "Ep 2 (Step 004450): Train loss 0.271, Val loss 0.319\n",
      "Ep 2 (Step 004500): Train loss 0.251, Val loss 0.262\n",
      "Ep 2 (Step 004550): Train loss 0.336, Val loss 0.258\n",
      "Ep 2 (Step 004600): Train loss 0.167, Val loss 0.268\n",
      "Ep 2 (Step 004650): Train loss 0.221, Val loss 0.328\n",
      "Ep 2 (Step 004700): Train loss 0.279, Val loss 0.285\n",
      "Ep 2 (Step 004750): Train loss 0.186, Val loss 0.266\n",
      "Ep 2 (Step 004800): Train loss 0.224, Val loss 0.256\n",
      "Ep 2 (Step 004850): Train loss 0.262, Val loss 0.298\n",
      "Ep 2 (Step 004900): Train loss 0.291, Val loss 0.257\n",
      "Ep 2 (Step 004950): Train loss 0.208, Val loss 0.288\n",
      "Ep 2 (Step 005000): Train loss 0.390, Val loss 0.306\n",
      "Ep 2 (Step 005050): Train loss 0.206, Val loss 0.308\n",
      "Ep 2 (Step 005100): Train loss 0.262, Val loss 0.269\n",
      "Ep 2 (Step 005150): Train loss 0.234, Val loss 0.293\n",
      "Ep 2 (Step 005200): Train loss 0.265, Val loss 0.266\n",
      "Ep 2 (Step 005250): Train loss 0.182, Val loss 0.302\n",
      "Ep 2 (Step 005300): Train loss 0.226, Val loss 0.323\n",
      "Ep 2 (Step 005350): Train loss 0.214, Val loss 0.303\n",
      "Ep 2 (Step 005400): Train loss 0.247, Val loss 0.281\n",
      "Ep 2 (Step 005450): Train loss 0.170, Val loss 0.258\n",
      "Ep 2 (Step 005500): Train loss 0.208, Val loss 0.264\n",
      "Ep 2 (Step 005550): Train loss 0.245, Val loss 0.256\n",
      "Ep 2 (Step 005600): Train loss 0.169, Val loss 0.259\n",
      "Ep 2 (Step 005650): Train loss 0.363, Val loss 0.245\n",
      "Ep 2 (Step 005700): Train loss 0.216, Val loss 0.261\n",
      "Ep 2 (Step 005750): Train loss 0.175, Val loss 0.239\n",
      "Ep 2 (Step 005800): Train loss 0.216, Val loss 0.241\n",
      "Ep 2 (Step 005850): Train loss 0.223, Val loss 0.249\n",
      "Ep 2 (Step 005900): Train loss 0.271, Val loss 0.235\n",
      "Ep 2 (Step 005950): Train loss 0.230, Val loss 0.247\n",
      "Ep 2 (Step 006000): Train loss 0.329, Val loss 0.261\n",
      "Ep 2 (Step 006050): Train loss 0.213, Val loss 0.259\n",
      "Ep 2 (Step 006100): Train loss 0.208, Val loss 0.253\n",
      "Ep 2 (Step 006150): Train loss 0.260, Val loss 0.281\n",
      "Ep 2 (Step 006200): Train loss 0.236, Val loss 0.243\n",
      "Ep 2 (Step 006250): Train loss 0.191, Val loss 0.266\n",
      "Ep 2 (Step 006300): Train loss 0.211, Val loss 0.251\n",
      "Ep 2 (Step 006350): Train loss 0.366, Val loss 0.270\n",
      "Training accuracy: 91.25% | Validation accuracy: 91.25%\n",
      "Ep 3 (Step 006400): Train loss 0.282, Val loss 0.239\n",
      "Ep 3 (Step 006450): Train loss 0.236, Val loss 0.263\n",
      "Ep 3 (Step 006500): Train loss 0.207, Val loss 0.273\n",
      "Ep 3 (Step 006550): Train loss 0.148, Val loss 0.256\n",
      "Ep 3 (Step 006600): Train loss 0.277, Val loss 0.240\n",
      "Ep 3 (Step 006650): Train loss 0.321, Val loss 0.285\n",
      "Ep 3 (Step 006700): Train loss 0.261, Val loss 0.270\n",
      "Ep 3 (Step 006750): Train loss 0.325, Val loss 0.265\n",
      "Ep 3 (Step 006800): Train loss 0.173, Val loss 0.245\n",
      "Ep 3 (Step 006850): Train loss 0.253, Val loss 0.292\n",
      "Ep 3 (Step 006900): Train loss 0.205, Val loss 0.270\n",
      "Ep 3 (Step 006950): Train loss 0.193, Val loss 0.268\n",
      "Ep 3 (Step 007000): Train loss 0.160, Val loss 0.242\n",
      "Ep 3 (Step 007050): Train loss 0.151, Val loss 0.221\n",
      "Ep 3 (Step 007100): Train loss 0.226, Val loss 0.240\n",
      "Ep 3 (Step 007150): Train loss 0.191, Val loss 0.244\n",
      "Ep 3 (Step 007200): Train loss 0.208, Val loss 0.229\n",
      "Ep 3 (Step 007250): Train loss 0.146, Val loss 0.266\n",
      "Ep 3 (Step 007300): Train loss 0.151, Val loss 0.261\n",
      "Ep 3 (Step 007350): Train loss 0.261, Val loss 0.248\n",
      "Ep 3 (Step 007400): Train loss 0.206, Val loss 0.241\n",
      "Ep 3 (Step 007450): Train loss 0.183, Val loss 0.231\n",
      "Ep 3 (Step 007500): Train loss 0.210, Val loss 0.225\n",
      "Ep 3 (Step 007550): Train loss 0.178, Val loss 0.228\n",
      "Ep 3 (Step 007600): Train loss 0.147, Val loss 0.244\n",
      "Ep 3 (Step 007650): Train loss 0.265, Val loss 0.236\n",
      "Ep 3 (Step 007700): Train loss 0.231, Val loss 0.252\n",
      "Ep 3 (Step 007750): Train loss 0.170, Val loss 0.245\n",
      "Ep 3 (Step 007800): Train loss 0.213, Val loss 0.261\n",
      "Ep 3 (Step 007850): Train loss 0.157, Val loss 0.256\n",
      "Ep 3 (Step 007900): Train loss 0.267, Val loss 0.249\n",
      "Ep 3 (Step 007950): Train loss 0.173, Val loss 0.222\n",
      "Ep 3 (Step 008000): Train loss 0.227, Val loss 0.214\n",
      "Ep 3 (Step 008050): Train loss 0.309, Val loss 0.234\n",
      "Ep 3 (Step 008100): Train loss 0.110, Val loss 0.255\n",
      "Ep 3 (Step 008150): Train loss 0.168, Val loss 0.251\n",
      "Ep 3 (Step 008200): Train loss 0.207, Val loss 0.259\n",
      "Ep 3 (Step 008250): Train loss 0.208, Val loss 0.239\n",
      "Ep 3 (Step 008300): Train loss 0.265, Val loss 0.238\n",
      "Ep 3 (Step 008350): Train loss 0.214, Val loss 0.257\n",
      "Ep 3 (Step 008400): Train loss 0.159, Val loss 0.246\n",
      "Ep 3 (Step 008450): Train loss 0.217, Val loss 0.223\n",
      "Ep 3 (Step 008500): Train loss 0.180, Val loss 0.225\n",
      "Ep 3 (Step 008550): Train loss 0.237, Val loss 0.218\n",
      "Ep 3 (Step 008600): Train loss 0.288, Val loss 0.245\n",
      "Ep 3 (Step 008650): Train loss 0.148, Val loss 0.243\n",
      "Ep 3 (Step 008700): Train loss 0.270, Val loss 0.238\n",
      "Ep 3 (Step 008750): Train loss 0.167, Val loss 0.253\n",
      "Ep 3 (Step 008800): Train loss 0.172, Val loss 0.250\n",
      "Ep 3 (Step 008850): Train loss 0.147, Val loss 0.249\n",
      "Ep 3 (Step 008900): Train loss 0.286, Val loss 0.237\n",
      "Ep 3 (Step 008950): Train loss 0.149, Val loss 0.245\n",
      "Ep 3 (Step 009000): Train loss 0.188, Val loss 0.243\n",
      "Ep 3 (Step 009050): Train loss 0.148, Val loss 0.247\n",
      "Ep 3 (Step 009100): Train loss 0.185, Val loss 0.224\n",
      "Ep 3 (Step 009150): Train loss 0.109, Val loss 0.242\n",
      "Ep 3 (Step 009200): Train loss 0.151, Val loss 0.232\n",
      "Ep 3 (Step 009250): Train loss 0.135, Val loss 0.231\n",
      "Ep 3 (Step 009300): Train loss 0.137, Val loss 0.238\n",
      "Ep 3 (Step 009350): Train loss 0.151, Val loss 0.244\n",
      "Ep 3 (Step 009400): Train loss 0.249, Val loss 0.227\n",
      "Ep 3 (Step 009450): Train loss 0.300, Val loss 0.280\n",
      "Ep 3 (Step 009500): Train loss 0.185, Val loss 0.207\n",
      "Ep 3 (Step 009550): Train loss 0.137, Val loss 0.280\n",
      "Training accuracy: 95.62% | Validation accuracy: 93.12%\n",
      "Training completed in 114.50 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=9e-6, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 3\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:34:48.718124Z",
     "iopub.status.busy": "2025-06-18T18:34:48.717567Z",
     "iopub.status.idle": "2025-06-18T18:34:49.504736Z",
     "shell.execute_reply": "2025-06-18T18:34:49.504169Z",
     "shell.execute_reply.started": "2025-06-18T18:34:48.718105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"News_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:34:49.505868Z",
     "iopub.status.busy": "2025-06-18T18:34:49.505603Z",
     "iopub.status.idle": "2025-06-18T18:34:49.927745Z",
     "shell.execute_reply": "2025-06-18T18:34:49.927135Z",
     "shell.execute_reply.started": "2025-06-18T18:34:49.505846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"News_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:34:49.928684Z",
     "iopub.status.busy": "2025-06-18T18:34:49.928438Z",
     "iopub.status.idle": "2025-06-18T18:34:49.933864Z",
     "shell.execute_reply": "2025-06-18T18:34:49.933138Z",
     "shell.execute_reply.started": "2025-06-18T18:34:49.928668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:34:49.935123Z",
     "iopub.status.busy": "2025-06-18T18:34:49.934880Z",
     "iopub.status.idle": "2025-06-18T18:34:51.063072Z",
     "shell.execute_reply": "2025-06-18T18:34:51.062426Z",
     "shell.execute_reply.started": "2025-06-18T18:34:49.935104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:37:36.558598Z",
     "iopub.status.busy": "2025-06-18T18:37:36.558093Z",
     "iopub.status.idle": "2025-06-18T18:37:36.563306Z",
     "shell.execute_reply": "2025-06-18T18:37:36.562636Z",
     "shell.execute_reply.started": "2025-06-18T18:37:36.558575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_news(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    # print(predicted_label)\n",
    "    # Return the classified result\n",
    "    return labels[predicted_label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T19:12:59.418147Z",
     "iopub.status.busy": "2025-06-18T19:12:59.417443Z",
     "iopub.status.idle": "2025-06-18T19:12:59.507240Z",
     "shell.execute_reply": "2025-06-18T19:12:59.506695Z",
     "shell.execute_reply.started": "2025-06-18T19:12:59.418122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports\n",
      "Business\n",
      "Sci/Tech\n",
      "World\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"cricket lives in the heart and soul of every indian. stumps , bats and balls \"\n",
    ")\n",
    "text_2=(\n",
    "    \"ELON MUSK Looks Toward Commercial telephone market investment in reliance jio Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\"\n",
    ")\n",
    "text_3=(\n",
    "    \"The evolution of tesla cybertruck is amazing. the horse power of that car is amazing.\"\n",
    ")\n",
    "text_4=(\n",
    "    \"\"\"plane crash at ahmedabad airport causes shock to the nation. A bomb exploded during an republic Day parade in India's remote southeast friday, killing more than 100 people, including old age people, while a rocket attack during a \n",
    "    celebration at a garden in the hilly area of pathankot injured 155, the news reported\"\"\"\n",
    ")\n",
    "print(classify_news(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_news(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_news(\n",
    "    text_3, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "print(classify_news(\n",
    "    text_4, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T18:37:39.748693Z",
     "iopub.status.busy": "2025-06-18T18:37:39.748147Z",
     "iopub.status.idle": "2025-06-18T19:05:47.852172Z",
     "shell.execute_reply": "2025-06-18T19:05:47.851346Z",
     "shell.execute_reply.started": "2025-06-18T18:37:39.748672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 93.16%\n",
      "Validation accuracy: 92.86%\n",
      "Test accuracy: 92.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
